# This is a a prefilled template for `kwaak`
#
# Several assumptions and defaults have been filled in. For proper usage, please customize the values to your needs.
project_name = "{{ project_name }}"
language = "{{ language }}"

## If you are using OpenAI, set the api key here
{% if openai_api_key -%}
openai_api_key = "{{ openai_api_key}}"
{% else -%}
#openai_api_key = "env:OPENAI_API_KEY"
{% endif %}

## Optional: Connect kwaak to github to create PRs, search code, and automatically push to a  remote
{% if github_api_key -%}
github_api_key = "{{ github_api_key }}"
{% else -%}
#github_api_key = "env:GITHUB_TOKEN"
{% endif %}

## Optional: Connect kwaak to tavily to enable it to search the web
#tavily_api_key = "env:TAVILY_API_KEY"

## Commands the agent uses for tools
## Kwaak can use tests, coverage, and lints to verify generated code.
## At the moment, the format of the output does not matter.
[commands]
## Optional: Allows an agent to run tests. Recommended.
# Example: test = "cargo test --no-fail-fast --color=never"
#test = "<YOUR TEST COMMAND>"

## Optional: Allows an agent to run coverage. The coverage command should run the tests and output the coverage results to stdout.
# Example: coverage = "cargo llvm-cov --no-clean --summary-only"
#coverage = "<YOUR COVERAGE COMMAND>"

## Optional: Lint and fix command. This command is run after each completion cycle, before committing the code.
# Recommended to use, as it avoids the LLM getting distracted by linting issues
# Example: lint_and_fix = "cargo clippy --fix --allow-dirty --allow-staged && cargo fmt"
#lint_and_fix = "<YOUR LINT AND FIX COMMAND>"

## Git and GitHub configuration
#
## Kwaak can create and update PRs on Github, search github code, and interact with the git repository. This requires a github token.
## If you leave the token empty, kwaak will not create PRs.
[git]
main_branch = "{{ git.main_branch }}"
owner = "{{ git.owner }}"
repository = "{{ git.repository }}"

## Kwaak uses different LLMs for different tasks. As a rule of thumb, tasks that happen often (like indexing, summarizing) require a small, fast model
## and tasks that happen less often (like completion) can use a larger, more accurate model.
#
## You can overwrite the api key and base url per kind of task if needed.
[llm.indexing]
provider = "{{ llm.provider }}"
prompt_model = "{{ llm.indexing_model }}"
{% if llm.base_url -%}
base_url = "{{ llm.base_url }}"
{% endif -%}

[llm.query]
provider = "{{ llm.provider }}"
prompt_model = "{{ llm.query_model }}"
{% if llm.base_url -%}
base_url = "{{ llm.base_url }}"
{% endif -%}

[llm.embedding]
provider = "{{ llm.provider }}"
embedding_model = "{{ llm.embedding_model }}"
{% if llm.base_url -%}
base_url = "{{ llm.base_url }}"
{% endif -%}
{% if llm.vector_size -%}
vector_size = {{ llm.vector_size }}
{% endif -%}

## Docker configuration
## kwaak requires a Dockerfile for the tool execution environment.
## Besides the dependencies to run the code, there are several additional dependencies:
## - `git` for interacting with the codebase
## - `rg` (ripgrep) for searching the codebase
## - `fd` (fd) for effective file searching
##
## In the future, an executor is planned that does not have these dependencies, but for now, they are required.
##
## If your project already has a Dockerfile and you want to keep it clean, you can specify a different file to use.
[docker]
dockerfile = "Dockerfile"
