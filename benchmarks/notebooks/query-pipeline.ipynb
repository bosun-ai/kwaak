{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query pipeline evaluation example notebook\n",
    "\n",
    "This notebook serves as a usueable example to evaluate the Kwaak query pipeline. Evaluations are done with RAGAS and it uses itself as datasource.\n",
    "\n",
    "The intention of this notebook is that it can be modified and tailored for any repository to get a grasp of how the Kwaak rag performs on it.\n",
    "\n",
    "When generating ground truths, it's expected to not be fully correct. The idea is to have a human in the middle tailor it. The benefit is that it gives both a base to work from and an answer that aligns with the output format of the llm.\n",
    "\n",
    "Note: Runs questions only once. If you want volume it needs some tailoring.\n",
    "\n",
    "## How does it work\n",
    "* Generate a RAGAS compatible dataset with recorded ground truths for a set of questions\n",
    "* Review and modify the generated initial answers to establish a ground truth\n",
    "* This stores a /evals/ragas/base.json that will serve as future input\n",
    "* Make some changes to kwaak, run the eval step without recording ground truth, with the base file as input\n",
    "* /evals should then contain ragas/base.json and a json file for each evaluation\n",
    "* Do this as many times as desired, then use the provided analysis (or do it better than me) to make a comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial question generation\n",
    "\n",
    "In this step we will generate our ground truth based on our input questions. A widget is provided to verify and adjust the ground truths.\n",
    "\n",
    "You **must** confirm the ground truths before continuing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components.\",\n",
    "\"I'd like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan.\",\n",
    "\"There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective.\",\n",
    "\"How are tools used by an agent?\",\n",
    "\"How can I add a tool for an agent?\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/timonv/projects/kwaak/benchmarks/notebooks\n",
      "/Users/timonv/projects/kwaak\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "# Since by default the dir is in benchmarks/notebooks, set our working directory to the root of the project\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (0.2.14)\n",
      "Requirement already satisfied: numpy in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (2.2.3)\n",
      "Requirement already satisfied: datasets in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (3.4.0)\n",
      "Requirement already satisfied: tiktoken in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (0.9.0)\n",
      "Requirement already satisfied: langchain in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (0.3.20)\n",
      "Requirement already satisfied: langchain-core in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (0.3.45)\n",
      "Requirement already satisfied: langchain-community in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (0.3.19)\n",
      "Requirement already satisfied: langchain_openai in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (0.3.9)\n",
      "Requirement already satisfied: nest-asyncio in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (2.10.6)\n",
      "Requirement already satisfied: openai>1 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (1.66.3)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from openai>1->ragas) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from pydantic>=2->ragas) (2.27.2)\n",
      "Requirement already satisfied: filelock in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->ragas) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (0.29.3)\n",
      "Requirement already satisfied: packaging in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from datasets->ragas) (6.0.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain->ragas) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain->ragas) (0.3.15)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain->ragas) (2.0.39)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain-core->ragas) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain-community->ragas) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langchain-community->ragas) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from aiohttp->datasets->ragas) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from pandas->datasets->ragas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from pandas->datasets->ragas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/timonv/.cache/uv/archive-v0/xOW-9lxHq2JYk_6jjnnot/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install depenencies for the duration of the notebook\n",
    "# Might want to do this proper via uv later!%\n",
    "pip install ragas itertools pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-q \"Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components.\" -q \"I'd like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan.\" -q \"There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective.\" -q \"How are tools used by an agent?\" -q \"How can I add a tool for an agent?\"\n",
      "\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused import: `ValueEnum`\u001b[0m\n",
      "\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/cli.rs:3:32\u001b[0m\n",
      "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[38;5;12m3\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse clap::{Parser, Subcommand, ValueEnum};\u001b[0m\n",
      "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n",
      "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n",
      "\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: `#[warn(unused_imports)]` on by default\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m:\u001b[0m `kwaak` (lib) generated 1 warning (run `cargo fix --lib -p kwaak` to apply 1 suggestion)\n",
      "\u001b[1m\u001b[32m    Finished\u001b[0m `dev` profile [unoptimized + debuginfo] target(s) in 0.60s\n",
      "\u001b[1m\u001b[32m     Running\u001b[0m `target/debug/kwaak --allow-dirty eval ragas -q 'Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components.' -q 'I'\\''d like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan.' -q 'There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective.' -q 'How are tools used by an agent?' -q 'How can I add a tool for an agent?' --output=evals/ragas/base_raw.json -r`\n",
      "OpenTelemetry tracing enabled\n",
      "Generation evalutions for 5 questions\n"
     ]
    }
   ],
   "source": [
    "# Let's prep these for shell commands so they are double quoted and joined by a comma\n",
    "questions_for_shell = \" \".join([f'-q \"{q}\"' for q in questions])\n",
    "print(questions_for_shell)\n",
    "!RUSTRUST_LOG=debug cargo run --features evaluations --  --allow-dirty eval ragas $questions_for_shell --output=evals/ragas/base_raw.json -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "91b0b3c4-ec47-44df-95b5-d928a0bb0155",
       "rows": [
        [
         "0",
         "The context provided does not offer detailed information specific to the complete architecture of Kwaak or a high-level component diagram in a format such as Mermaid. Therefore, I cannot generate a diagram or a full architectural description based solely on the given context.\n\nHowever, based on the snippets retrieved, here are some relevant points about how Kwaak works and its components:\n\n1. **General Functionality**: \n   - Kwaak allows you to run autonomous AI agents locally to work on coding tasks such as documenting, testing, and improving code quality.\n   - It provides a terminal user interface (TUI) for interaction with the agents.\n\n2. **Backend and Frontend**:\n   - It has a lightweight frontend based on `ratatui` that communicates with a backend via commands, and a command pattern is used to handle backend functionalities asynchronously. [Reference: ARCHITECTURE.md]\n\n3. **Indexing**:\n   - Upon initial setup, it indexes the codebase using \"Swiftide\" for Retrieval-Augmented Generation (RAG). This indexing is stored using `duckdb` and is cached with `redb`. [Reference: README.md]\n\n4. **Execution Environment**:\n   - Kwaak uses Docker containers to create safe execution environments for agents to run code. This ensures that the agents' execution doesn't affect the local system environment. [Reference: README.md]\n\n5. **Feedback Loop and Sessions**:\n   - Agents operate in a session, usually involving continuous feedback with an LLM until their assigned task is completed.\n\nUnfortunately, the provided context does not contain enough specific details about the architecture to further elaborate with a high-level diagram illustrative of all components in Mermaid or any other format. Additionally, any graphical architecture diagrams referred to in the content (e.g., `architecture.svg`) are not included as text, and hence such visual information cannot be reproduced here.\n\nFor a more detailed exploration of the architecture diagram or component breakdown, a look at the referenced architecture image or further documentation beyond the provided context would be necessary.",
         "['Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '**Q:** I get a redb/duckdb error when starting, what is up?\\n\\n**A**: Possibly your index got corrupted, or you have another kwaak instance running on the same project. Try clearing the index with `kwaak clear-index` and restart kwaak. Note that this will require a reindexing of your codebase.', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## Latest updates on our blog :fire:\\n\\n- [Releasing kwaak with kwaak](https://bosun.ai/posts/releasing-kwaak-with-kwaak/)', '//! Builds various storage providers for kwaak\\n//!\\n//! Handled as statics to avoid multiple instances of the same storage provider\\n//!\\n//!\\n//! Currently there are 3 tables:\\n//! - project itself (indexing/retrieval) (uuid, path, chunk, embeddings)\\n//! - cache (for caching in indexing/retrieval) (uuid, path)\\n//! - runtime settings (for storing runtime settings) (key, value)\\n//!\\n//! Right now, these are relatively simple. Friendly reminder for future me and others to consider\\n//! a decent migration strategy if these tables change.\\n\\nuse std::sync::OnceLock;\\n\\nuse anyhow::{Context, Result};\\nuse swiftide::{indexing::EmbeddedField, integrations::duckdb::Duckdb};\\n\\nuse crate::repository::Repository;\\n\\nstatic DUCK_DB: OnceLock<Duckdb> = OnceLock::new();\\n\\n/// Retrieves a static duckdb\\n///\\n/// # Panics\\n///\\n/// Panics if it cannot setup duckdb\\npub fn get_duckdb(repository: &Repository) -> Duckdb {\\n    DUCK_DB\\n        .get_or_init(|| build_duckdb(repository).expect(\"Failed to build duckdb\"))\\n        .to_owned()\\n}\\n\\n// Probably should just be on the repository/config, cloned from there.\\n// This sucks in tests\\npub(crate) fn build_duckdb(repository: &Repository) -> Result<Duckdb> {\\n    let config = repository.config();\\n    let path = config.cache_dir().join(\"duck.db3\");\\n\\n    tracing::debug!(\"Building Duckdb: {}\", path.display());\\n\\n    let embedding_provider = config.embedding_provider();\\n\\n    let connection =\\n        duckdb::Connection::open(&path).context(\"Failed to open connection to duckdb\")?;\\n    Duckdb::builder()\\n        .connection(connection)\\n        .with_vector(\\n            EmbeddedField::Combined,\\n            embedding_provider.vector_size().try_into()?,\\n        )\\n        .table_name(normalize_table_name(&config.project_name))\\n        .cache_table(format!(\\n            \"cache_{}\",\\n            normalize_table_name(&config.project_name)\\n        ))\\n        .build()\\n        .context(\"Failed to build Duckdb\")\\n}\\n\\n// Is this enough?\\nfn normalize_table_name(name: &str) -> String {\\n    name.replace(\\'-\\', \"_\")\\n}', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '**Q:** Kwaak feels very slow\\n\\n**A:** Try increasing the resources available for docker. For docker desktop this is in Settings -> Resources -> Advanced. On MacOS, adding your terminal and/or kwaak to developer tools can also help.', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '[Crate]: https://crates.io/crates/kwaak\\n[Docs Badge]: https://img.shields.io/docsrs/kwaak?logo=rust&style=flat-square&logoColor=E05D44']",
         "The context provided does not offer detailed information specific to the complete architecture of Kwaak or a high-level component diagram in a format such as Mermaid. Therefore, I cannot generate a diagram or a full architectural description based solely on the given context.\n\nHowever, based on the snippets retrieved, here are some relevant points about how Kwaak works and its components:\n\n1. **General Functionality**: \n   - Kwaak allows you to run autonomous AI agents locally to work on coding tasks such as documenting, testing, and improving code quality.\n   - It provides a terminal user interface (TUI) for interaction with the agents.\n\n2. **Backend and Frontend**:\n   - It has a lightweight frontend based on `ratatui` that communicates with a backend via commands, and a command pattern is used to handle backend functionalities asynchronously. [Reference: ARCHITECTURE.md]\n\n3. **Indexing**:\n   - Upon initial setup, it indexes the codebase using \"Swiftide\" for Retrieval-Augmented Generation (RAG). This indexing is stored using `duckdb` and is cached with `redb`. [Reference: README.md]\n\n4. **Execution Environment**:\n   - Kwaak uses Docker containers to create safe execution environments for agents to run code. This ensures that the agents' execution doesn't affect the local system environment. [Reference: README.md]\n\n5. **Feedback Loop and Sessions**:\n   - Agents operate in a session, usually involving continuous feedback with an LLM until their assigned task is completed.\n\nUnfortunately, the provided context does not contain enough specific details about the architecture to further elaborate with a high-level diagram illustrative of all components in Mermaid or any other format. Additionally, any graphical architecture diagrams referred to in the content (e.g., `architecture.svg`) are not included as text, and hence such visual information cannot be reproduced here.\n\nFor a more detailed exploration of the architecture diagram or component breakdown, a look at the referenced architecture image or further documentation beyond the provided context would be necessary.",
         "Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components."
        ],
        [
         "1",
         "The provided context does not specifically explain how tools are used by an agent, in terms of their operational mechanism within a larger system. However, there is some information about the structure and functionality of tools in `Kwaak`.\n\n### Key Points from the Context:\n\n1. **Agent and Tools System**:\n   - Agents in Kwaak can operate a number of tools that help them execute tasks. The context refers to various tools such as those for running tests, checking code coverage, and interacting with shell commands. ([source code](./src/agent/tools/mod.rs), [README.md](./README.md))\n\n2. **Delegate Agent Tool**:\n   - Presents an example of how a tool is set up. The `DelegateAgent` tool delegates tasks to a particular agent. It uses an object called a `RunningAgent` that is assumed to be already configured ([source code](./src/agent/tools/delegate_agent.rs)).\n\n3. **Tool Configuration and Invocation**:\n   - Tools are configured and utilized within agents during certain tasks, e.g., running shell commands or reading files. Some parts of the code provide functionality for running commands with a sandboxed shell environment using Docker ([source code](./src/agent/tools/mod.rs)).\n\n4. **Initial Context and Configuration**:\n   - The system can utilize initial context and configuration to guide the tools. This context might describe how a project is set up or give an overview of the directory structure to help with the execution of tasks ([source code](./src/agent/agents/coding.rs)).\n\n5. **Session and Agent Management**:\n   - Session management indicates parallel operations with each session containing its own configuration of agents and tools ([ARCHITECTURE.md](./ARCHITECTURE.md)).\n\n### Leads for Further Information:\nThe retrieved context has snippets pointing toward various sections that could provide additional details, such as the specific role of each tool and how they are incorporated into an agent's workflow. These include files like `agents/mod.rs`, `session.rs`, and `agent/tools/mod.rs`.\n\nBecause the context does not fully explain the specifics of tool usage by agents, I recommend checking further documentation or additional sections of the source code not provided here for comprehensive understanding.",
         "['## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '## Additional information\\n\\nThis context is provided for an ai agent that has to accomplish the above. Additionally, the agent has access to the following tools:\\n{{available_tools}}', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', ' Agent::builder()\\n        .context(Arc::clone(&context) as Arc<dyn AgentContext>)\\n        .system_prompt(system_prompt)\\n        .tools(tools.to_vec())\\n        .before_all(move |agent| {\\n            let initial_context = initial_context.clone();\\n\\n            Box::pin(async move {\\n                agent.context()\\n                    .add_message(chat_completion::ChatMessage::new_user(initial_context))\\n                    .await;\\n\\n                let top_level_project_overview = agent.context().exec_cmd(&Command::shell(\"fd -iH -d2 -E \\'.git/*\\'\")).await?.output;\\n                agent.context().add_message(chat_completion::ChatMessage::new_user(format!(\"The following is a max depth 2, high level overview of the directory structure of the project: \\\\n ```{top_level_project_overview}```\"))).await;\\n\\n                Ok(())\\n            })\\n        })\\n        .on_new_message(move |_, message| {\\n            let command_responder = tx_2.clone();\\n            let message = message.clone();\\n\\n            Box::pin(async move {\\n                command_responder.agent_message(message);\\n\\n                Ok(())\\n            })\\n        })\\n        .before_completion(move |_, _| {\\n            let command_responder = tx_3.clone();\\n            Box::pin(async move {\\n                command_responder.update(\"running completions\");\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let command_responder = tx_4.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                command_responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .after_tool(tool_summarizer.summarize_hook())\\n        .after_each', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', ' {\\n    let query_pipeline = indexing::build_query_pipeline(repository, None)?;\\n    let mut tools = vec![\\n        tools::write_file(),\\n        tools::search_file(),\\n        tools::git(),\\n        tools::shell_command(),\\n        tools::search_code(),\\n        tools::fetch_url(),\\n        tools::ExplainCode::new(query_pipeline).boxed(),\\n    ];\\n\\n    // agent edit mode specific tools\\n    match repository.config().agent_edit_mode {\\n        AgentEditMode::Whole => {\\n            tools.push(tools::write_file());\\n            tools.push(tools::read_file());\\n        }\\n        AgentEditMode::Line => {\\n            tools.push(tools::read_file_with_line_numbers());\\n            tools.push(tools::replace_lines());\\n            tools.push(tools::add_lines());\\n        }\\n    }\\n\\n    // gitHub-related tools\\n    if let Some(github_session) = github_session {\\n        tools.push(tools::CreateOrUpdatePullRequest::new(github_session).boxed());\\n        tools.push(tools::GithubSearchCode::new(github_session).boxed());\\n    }\\n\\n    // web search tool\\n    if let Some(tavily_api_key) = &repository.config().tavily_api_key {\\n        let tavily = Tavily::builder(tavily_api_key.expose_secret()).build()?;\\n        tools.push(tools::SearchWeb::new(tavily, tavily_api_key.clone()).boxed());\\n    };\\n\\n    // test-related tools\\n    if let Some(test_command) = &repository.config().commands.test {\\n        tools.push(tools::RunTests::new(test_command).boxed());\\n    }\\n\\n    if let Some(coverage_command) = &repository.config().commands.coverage {\\n        tools.push(tools::RunCoverage::new(coverage_command).boxed());\\n    }\\n\\n    // reset file tool\\n    if let Some(env) = agent_env {\\n        tools.push(tools::ResetFile::new(&env.start_ref).boxed());\\n    }\\n\\n    tools.retain(|tool| {\\n        !repository\\n            .config()\\n            .disabled_tools()\\n            .iter()\\n            .any(|s| *s == tool.name().as_ref())\\n    });\\n\\n    Ok(tools)\\n}', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', '{{description}}\\n\\n---\\n\\n_This pull request was created by [kwaak](https://github.com/bosun-ai/kwaak), a free, open-source, autonomous coding agent tool. Pull requests are tracked in bosun-ai/kwaak#48_\\n\\n{% if messages | length > 0 -%}\\n<details>\\n<summary>Message History</summary>\\n\\n{% for message in messages -%}\\n<details>\\n  <summary>{{message.role}}</summary>\\n\\n```markdown\\n{{message.content}}\\n```\\n</details>\\n{% if message.role is containing(\"Assistant\") -%}', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'mod delegate_agent;\\nmod replace_lines;\\n\\npub use delegate_agent::DelegateAgent;\\npub use replace_lines::replace_lines;\\n\\nuse std::sync::Arc;\\nuse swiftide::traits::CommandError;\\n\\nuse anyhow::{Context as _, Result};\\nuse swiftide::{\\n    chat_completion::{errors::ToolError, ToolOutput},\\n    query::{search_strategies, states},\\n    traits::{AgentContext, Command},\\n};\\nuse swiftide_macros::{tool, Tool};\\nuse tavily::Tavily;\\nuse tokio::sync::Mutex;\\n\\nuse crate::{\\n    config::ApiKey,\\n    git::github::GithubSession,\\n    templates::Templates,\\n    util::{self, accept_non_zero_exit},\\n};\\n\\n#[allow(dead_code)]\\nstatic MAIN_BRANCH_CMD: &str = \"git remote show origin | sed -n \\'/HEAD branch/s/.*: //p\\'\";\\n\\n/// WARN: Experimental\\n#[tool(\\n    description = \"Run any shell command in the current project, use this if other tools are not enough.\",\\n    param(\\n        name = \"cmd\",\\n        description = \"The shell command, including any arguments if needed, to run\"\\n    )\\n)]\\npub async fn shell_command(context: &dyn AgentContext, cmd: &str) -> Result<ToolOutput, ToolError> {\\n    if util::is_git_branch_change(cmd) {\\n        return Ok(\\n            \"You cannot change branches, you are already on a branch created specifically for you.\"\\n                .into(),\\n        );\\n    }\\n    let output = accept_non_zero_exit(context.exec_cmd(&Command::Shell(cmd.into())).await)?;\\n    Ok(output.into())\\n}\\n\\n#[tool(\\n    description = \"Reads file content\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}\\n\\n// TODO: Better to have a single read_file tool with an optional line number flag', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '\\n\\n    if let Err(error) = app_result {\\n        ::tracing::error!(?error, \"Kwaak encountered an error\\\\n {error:#}\");\\n        eprintln!(\"Kwaak encountered an error\\\\n {error}\");\\n        std::process::exit(1);\\n    }\\n\\n    Ok(())\\n}\\n\\nasync fn test_tool(\\n    repository: &repository::Repository,\\n    tool_name: &str,\\n    tool_args: Option<&str>,\\n) -> Result<()> {\\n    let github_session = Arc::new(GithubSession::from_repository(&repository)?);\\n    let tool = available_tools(repository, Some(&github_session), None)?\\n        .into_iter()\\n        .find(|tool| tool.name() == tool_name)\\n        .context(\"Tool not found\")?;\\n\\n    let mut executor = DockerExecutor::default();\\n    let dockerfile = &repository.config().docker.dockerfile;\\n\\n    println!(\\n        \"Starting executor with dockerfile: {}\",\\n        dockerfile.display()\\n    );\\n    let running_executor = executor\\n        .with_context_path(&repository.config().docker.context)\\n        .with_image_name(repository.config().project_name.to_lowercase())\\n        .with_dockerfile(dockerfile)\\n        .to_owned()\\n        .start()\\n        .await?;\\n\\n    let agent_context = DefaultContext::from_executor(running_executor);\\n\\n    println!(\"Invoking tool: {tool_name}\");\\n    let output = tool\\n        .invoke(&agent_context as &dyn AgentContext, tool_args)\\n        .await?;\\n\\n    println!(\"{output}\");\\n\\n    Ok(())\\n}\\n\\n#[instrument(skip_all)]', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', '\\n\\n    /// Optional: Use github for code search, creating pull requests, and automatic pushing to\\n    /// remotes\\n    #[serde(default)]\\n    pub github_api_key: Option<ApiKey>,\\n\\n    /// Required if using `OpenAI`\\n    #[serde(default)]\\n    pub openai_api_key: Option<ApiKey>,\\n\\n    /// Required if using \\'Anthropic\\'\\n    #[serde(default)]\\n    pub anthropic_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Open Router`\\n    #[serde(default)]\\n    pub open_router_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Azure OpenAI`\\n    #[serde(default)]\\n    pub azure_openai_api_key: Option<ApiKey>,\\n\\n    #[serde(default)]\\n    pub tool_executor: SupportedToolExecutors,\\n\\n    /// A list of tool name and whether it is enabled or disabled\\n    ///\\n    /// This allows the user to disable tools that are not needed for their workflow. Or enable\\n    /// tools that are disabled by default\\n    #[serde(default)]\\n    pub tools: Tools,\\n\\n    /// By default the agent stops if the last message was its own and there are no new\\n    /// completions.\\n    ///\\n    /// When endless mode is enabled, the agent will keep running until it either cannot complete,\\n    /// did complete or was manually stopped.\\n    ///\\n    /// In addition, the agent is instructed that it cannot ask for feedback, but should try to\\n    /// complete its task instead.\\n    ///\\n    /// When running without a TUI, the agent will always run in endless mode.\\n    ///\\n    /// WARN: There currently is _no_ limit for endless mode\\n    #[serde(default)]\\n    pub endless_mode: bool,\\n\\n    /// OpenTelemetry tracing feature toggle\\n    #[serde(default = \"default_otel_enabled\")]\\n    pub otel_enabled: bool,\\n\\n    /// How the agent will edit files, defaults to whole\\n    #[serde(default)]\\n    pub agent_edit_mode: AgentEditMode,\\n\\n    /// Additional constraints / instructions for the agent\\n    ///\\n    /// These are passes to the agent in the system prompt and are rendered in a list. If you\\n    /// intend to use more complicated instructions, consider adding a file to read in the\\n']",
         "The provided context does not specifically explain how tools are used by an agent, in terms of their operational mechanism within a larger system. However, there is some information about the structure and functionality of tools in `Kwaak`.\n\n### Key Points from the Context:\n\n1. **Agent and Tools System**:\n   - Agents in Kwaak can operate a number of tools that help them execute tasks. The context refers to various tools such as those for running tests, checking code coverage, and interacting with shell commands. ([source code](./src/agent/tools/mod.rs), [README.md](./README.md))\n\n2. **Delegate Agent Tool**:\n   - Presents an example of how a tool is set up. The `DelegateAgent` tool delegates tasks to a particular agent. It uses an object called a `RunningAgent` that is assumed to be already configured ([source code](./src/agent/tools/delegate_agent.rs)).\n\n3. **Tool Configuration and Invocation**:\n   - Tools are configured and utilized within agents during certain tasks, e.g., running shell commands or reading files. Some parts of the code provide functionality for running commands with a sandboxed shell environment using Docker ([source code](./src/agent/tools/mod.rs)).\n\n4. **Initial Context and Configuration**:\n   - The system can utilize initial context and configuration to guide the tools. This context might describe how a project is set up or give an overview of the directory structure to help with the execution of tasks ([source code](./src/agent/agents/coding.rs)).\n\n5. **Session and Agent Management**:\n   - Session management indicates parallel operations with each session containing its own configuration of agents and tools ([ARCHITECTURE.md](./ARCHITECTURE.md)).\n\n### Leads for Further Information:\nThe retrieved context has snippets pointing toward various sections that could provide additional details, such as the specific role of each tool and how they are incorporated into an agent's workflow. These include files like `agents/mod.rs`, `session.rs`, and `agent/tools/mod.rs`.\n\nBecause the context does not fully explain the specifics of tool usage by agents, I recommend checking further documentation or additional sections of the source code not provided here for comprehensive understanding.",
         "How are tools used by an agent?"
        ],
        [
         "2",
         "To configure a session in a file such that users can add their own custom agents in Kwaak, follow this detailed step-by-step plan based on the given context:\n\n1. **Understanding the Session Concept**: \n   - Sessions in Kwaak are used to represent an ongoing agent interaction. They are more general than a simple chat and may be utilized for non-chat interactions in the future (Reference: _ARCHITECTURE.md_).\n\n2. **Configure Session Lifecycle**:\n   - When a session is created via a new chat or agent, a Docker container is initialized, the environment is configured, and an agent is started (Reference: _ARCHITECTURE.md_).\n\n3. **Use `kwaak.toml` for Configuration**:\n   - Create a `kwaak.toml` file which will include the session configurations. This configuration file is pivotal to adjusting agent settings and tool configurations (Reference: _README.md_).\n\n4. **Session Configuration Parameters**:\n   - Make sure to include necessary configurations in the `kwaak.toml` file. These configurations include, but are not limited to:\n     - `SupportedAgentConfigurations` for defining agent architectures (e.g., `Coding`, `PlanAct`).\n     - Tool executors configurations such as `Docker` or `Local`.\n\n5. **Custom Agent Definitions**:\n   - Users can create custom agents by defining them in the `kwaak.toml` configuration file. Support for custom tools can also be configured here.\n   - Example from the context suggests the use of agent constraints, tool lists, and edit modes to customize agent behavior (`config.rs`).\n\n6. **Onboarding and Setup**:\n   - Utilize Kwaak’s onboarding module to guide users through setting up their configurations with the configuration file being generated during this process. This accommodates user-specific setups (Reference: _onboarding/mod.rs_).\n\n7. **Use Environment Variables for Customization**:\n   - Provide flexibility for users to override configurations via environment variables. This helps accommodate different setups for diverse contributor environments (Reference: _README.md_).\n\n8. **Testing and Validating Configurations**:\n   - Use Docker to manage test environments and validate the agent setups to ensure they perform as intended (Reference: _benchmarks/swe/README.md_).\n\nBy following these steps, you can configure sessions in a file, allowing users to add their custom agents. The core idea rests on leveraging `kwaak.toml` for flexible and customizable agent configurations as well as providing an onboarding flow to support end-user interaction with the configuration process. \n\nIf you need more detailed steps for specific configurations, please consult the full documentation or context for additional guidance.",
         "['### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '### Session Lifecycle\\n\\n1. **Creation**: When a user starts a new chat or creates a new agent, a new session is created with a unique UUID.\\n2. **Initialization**: The session sets up a Docker container, generates initial context using RAG, and configures the environment.\\n3. **Agent Execution**: The session starts an agent (e.g., coding agent or plan-and-act agent) which interacts with the LLM.\\n4. **Message Handling**: Sessions maintain communication channels for handling messages, including potential agent swaps.\\n5. **Termination**: When a chat is closed or when Kwaak exits, the associated session is stopped.', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '    /// repository instead.\\n    #[serde(default)]\\n    pub agent_custom_constraints: Option<Vec<String>>,\\n\\n    #[serde(default)]\\n    pub ui: UIConfig,\\n\\n    /// Number of completions before the agent summarizes the conversation.\\n    /// This is used to steer the agent to focus on the current task. If this value is too small\\n    /// the agent will have clear loss of context when performing tasks. If this value is too large\\n    /// the agent will not have focus and not understand what is relevant and important.\\n    ///\\n    /// Additionally, summarizing the conversation will reduce the context window which can be\\n    /// beneficial for APIs with stringent limits on context tokens.\\n    ///\\n    /// Defaults to 10.\\n    #[serde(default = \"default_num_completions_for_summary\")]\\n    pub num_completions_for_summary: usize,\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(default)]\\npub struct UIConfig {\\n    pub hide_header: bool,\\n}\\n\\nfn default_otel_enabled() -> bool {\\n    false\\n}\\n\\nfn default_num_completions_for_summary() -> usize {\\n    10\\n}\\n\\n/// Agent session configurations supported by Kwaak\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\npub enum SupportedAgentConfigurations {\\n    /// Single looping agent that has all tools available\\n    #[default]\\n    #[serde(alias = \"V1\")]\\n    Coding,\\n    /// A two stage agent, starting with a planning agent that delegates to the coding\\n    /// agent\\n    PlanAct,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum SupportedToolExecutors {\\n    #[default]\\n    Docker,\\n    Local,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default, strum_macros::EnumIs)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum AgentEditMode {\\n    #[default]\\n    Whole,\\n    Line,\\n    // i.e. udiff, llm reviewed, etc\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize)]', \"### Configuration\\n\\nKwaak supports configuring different Large Language Models (LLMs) for distinct tasks like indexing, querying, and embedding to optimize performance and accuracy. Be sure to tailor the configurations to fit the scope and blend of the tasks you're tackling.\", \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', 'use std::sync::{Arc, Mutex};\\n\\nuse anyhow::{Context as _, Result};\\nuse derive_builder::Builder;\\nuse swiftide::{\\n    agents::tools::local_executor::LocalExecutor,\\n    chat_completion::{ParamSpec, Tool, ToolSpec},\\n    traits::{SimplePrompt, ToolExecutor},\\n};\\nuse swiftide_docker_executor::DockerExecutor;\\nuse tavily::Tavily;\\nuse tokio::sync::mpsc::UnboundedSender;\\nuse tokio_util::{sync::CancellationToken, task::AbortOnDropHandle};\\nuse uuid::Uuid;\\n\\nuse crate::{\\n    agent::{tools::DelegateAgent, util},\\n    commands::Responder,\\n    config::{self, AgentEditMode, SupportedToolExecutors},\\n    git::github::GithubSession,\\n    indexing,\\n    repository::Repository,\\n};\\n\\nuse super::{\\n    agents,\\n    env_setup::{self, AgentEnvironment, EnvSetup},\\n    running_agent::RunningAgent,\\n    tools,\\n};\\n\\n/// Session represents the abstract state of an ongoing agent interaction (i.e. in a chat)\\n///\\n/// Consider the implementation \\'emergent architecture\\' (an excuse for an isolated mess)\\n///\\n/// Some future ideas:\\n///     - Session configuration from a file\\n///     - A registry pattern for agents, so you could in theory run multiple concurrent\\n#[derive(Clone, Builder)]\\n#[builder(build_fn(private), setter(into))]\\npub struct Session {\\n    pub session_id: Uuid,\\n    pub repository: Arc<Repository>,\\n    pub default_responder: Arc<dyn Responder>,\\n    pub initial_query: String,\\n\\n    /// Handle to send messages to the running session\\n    running_session_tx: UnboundedSender<SessionMessage>,\\n}\\n\\n/// Messages that can be send from i.e. a tool to an active session\\n#[derive(Clone)]\\npub enum SessionMessage {\\n    SwapAgent(RunningAgent),\\n}\\n\\nimpl std::fmt::Debug for SessionMessage {\\n    fn fmt(&self, f: &mut std::fmt::Formatter<\\'_>) -> std::fmt::Result {\\n        match self {\\n            Self::SwapAgent(_) => f.debug_tuple(\"SwapAgent\").finish(),\\n        }\\n    }\\n}', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '#### Backoff Configuration\\n\\nKwaak uses the exponential backoff strategy to handle retries. Currently, only\\nOpenAI, OpenRouter, and Anthropic calls will make use of the backoff parameters.\\nYou can configure the backoff settings in the `kwaak.toml` file under a\\n`[backoff]` section. These settings are optional, and default to the following\\nvalues:\\n\\n- `initial_interval_sec`: Defaults to 15 seconds. This sets the initial waiting time between retries.\\n- `multiplier`: Defaults to 2.0. This factor multiplies the interval on each retry attempt.\\n- `randomization_factor`: Defaults to 0.05. Introduces randomness to avoid retry storms.\\n- `max_elapsed_time_sec`: Defaults to 120 seconds. This total time all attempts are allowed.\\n\\nExample Configuration:\\n\\n```toml\\n[backoff]\\ninitial_interval_sec = 15\\nmultiplier = 2.0\\nrandomization_factor = 0.05\\nmax_elapsed_time_sec = 120\\n```', '- **`git.auto_commit_disabled`**: Opt-out of automatic commits after each chat completion.\\n- **`tools`**: A list of tool names to enable or disable.\\n  Example:\\n\\n```toml\\n[tools]\\nshell_command = false\\nsearch_code = true\\n```\\n\\nPossible values: `\"shell_command\"`, `\"read_file\"`,\\n`\"read_file_with_line_numbers\"`, `\"write_file\"`, `\"search_file\"`, `\"git\"`,\\n`\"reset_file\"`, `\"search_code\"`, `\"explain_code\"`,\\n`\"create_or_update_pull_request\"`, `\"run_tests\"`, `\"run_coverage\"`,\\n`\"search_web\"`, `\"github_search_code\"`, `\"fetch_url\"`, `\"add_lines\"`,\\n`\"replace_lines\"`\\n\\n- **`ui.hide_header`**: Optionally hide the top header in the UI. Defaults to `false`.\\n- **`num_completions_for_summary`**: Number of completions before the agent summarizes the conversation. Defaults to 10;\\n- **`git.agent_user_name`**: Name which the kwaak agent will make commands with.\\n  Defaults to \"kwaak\"`\\n- **`git.agent_user_email`**: Email which the kwaak agent will make commits\\n  with. Defaults to \"kwaak@bosun.ai\"\\n\\n<!-- ROADMAP -->', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '\\n\\n    /// Optional: Use github for code search, creating pull requests, and automatic pushing to\\n    /// remotes\\n    #[serde(default)]\\n    pub github_api_key: Option<ApiKey>,\\n\\n    /// Required if using `OpenAI`\\n    #[serde(default)]\\n    pub openai_api_key: Option<ApiKey>,\\n\\n    /// Required if using \\'Anthropic\\'\\n    #[serde(default)]\\n    pub anthropic_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Open Router`\\n    #[serde(default)]\\n    pub open_router_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Azure OpenAI`\\n    #[serde(default)]\\n    pub azure_openai_api_key: Option<ApiKey>,\\n\\n    #[serde(default)]\\n    pub tool_executor: SupportedToolExecutors,\\n\\n    /// A list of tool name and whether it is enabled or disabled\\n    ///\\n    /// This allows the user to disable tools that are not needed for their workflow. Or enable\\n    /// tools that are disabled by default\\n    #[serde(default)]\\n    pub tools: Tools,\\n\\n    /// By default the agent stops if the last message was its own and there are no new\\n    /// completions.\\n    ///\\n    /// When endless mode is enabled, the agent will keep running until it either cannot complete,\\n    /// did complete or was manually stopped.\\n    ///\\n    /// In addition, the agent is instructed that it cannot ask for feedback, but should try to\\n    /// complete its task instead.\\n    ///\\n    /// When running without a TUI, the agent will always run in endless mode.\\n    ///\\n    /// WARN: There currently is _no_ limit for endless mode\\n    #[serde(default)]\\n    pub endless_mode: bool,\\n\\n    /// OpenTelemetry tracing feature toggle\\n    #[serde(default = \"default_otel_enabled\")]\\n    pub otel_enabled: bool,\\n\\n    /// How the agent will edit files, defaults to whole\\n    #[serde(default)]\\n    pub agent_edit_mode: AgentEditMode,\\n\\n    /// Additional constraints / instructions for the agent\\n    ///\\n    /// These are passes to the agent in the system prompt and are rendered in a list. If you\\n    /// intend to use more complicated instructions, consider adding a file to read in the\\n', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;']",
         "To configure a session in a file such that users can add their own custom agents in Kwaak, follow this detailed step-by-step plan based on the given context:\n\n1. **Understanding the Session Concept**: \n   - Sessions in Kwaak are used to represent an ongoing agent interaction. They are more general than a simple chat and may be utilized for non-chat interactions in the future (Reference: _ARCHITECTURE.md_).\n\n2. **Configure Session Lifecycle**:\n   - When a session is created via a new chat or agent, a Docker container is initialized, the environment is configured, and an agent is started (Reference: _ARCHITECTURE.md_).\n\n3. **Use `kwaak.toml` for Configuration**:\n   - Create a `kwaak.toml` file which will include the session configurations. This configuration file is pivotal to adjusting agent settings and tool configurations (Reference: _README.md_).\n\n4. **Session Configuration Parameters**:\n   - Make sure to include necessary configurations in the `kwaak.toml` file. These configurations include, but are not limited to:\n     - `SupportedAgentConfigurations` for defining agent architectures (e.g., `Coding`, `PlanAct`).\n     - Tool executors configurations such as `Docker` or `Local`.\n\n5. **Custom Agent Definitions**:\n   - Users can create custom agents by defining them in the `kwaak.toml` configuration file. Support for custom tools can also be configured here.\n   - Example from the context suggests the use of agent constraints, tool lists, and edit modes to customize agent behavior (`config.rs`).\n\n6. **Onboarding and Setup**:\n   - Utilize Kwaak’s onboarding module to guide users through setting up their configurations with the configuration file being generated during this process. This accommodates user-specific setups (Reference: _onboarding/mod.rs_).\n\n7. **Use Environment Variables for Customization**:\n   - Provide flexibility for users to override configurations via environment variables. This helps accommodate different setups for diverse contributor environments (Reference: _README.md_).\n\n8. **Testing and Validating Configurations**:\n   - Use Docker to manage test environments and validate the agent setups to ensure they perform as intended (Reference: _benchmarks/swe/README.md_).\n\nBy following these steps, you can configure sessions in a file, allowing users to add their custom agents. The core idea rests on leveraging `kwaak.toml` for flexible and customizable agent configurations as well as providing an onboarding flow to support end-user interaction with the configuration process. \n\nIf you need more detailed steps for specific configurations, please consult the full documentation or context for additional guidance.",
         "I'd like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan."
        ],
        [
         "3",
         "The provided context does not contain sufficient information to fully explain how channels work within the app from a user's perspective. It mentions that commands include a \"channel to feed back responses\" into, but it does not elaborate further on how these channels interact, relate, or are utilized from a user's perspective. Additionally, there is no detailed description or explanation about user interaction with these channels within the retrieved content. Therefore, the question cannot be answered based on the current context. \n\nIf further details are needed, exploring the files or code sections mentioning \"channels\" specifically within the `commands` or `frontend` modules might be a good starting point, as these modules seem to deal with command patterns and user interaction.",
         "['# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', 'pub struct App<\\'a> {\\n    pub splash: splash::Splash<\\'a>,\\n    pub has_indexed_on_boot: bool,\\n    // /// The chat input\\n    // pub input: String,\\n    pub text_input: TextArea<\\'a>,\\n\\n    /// All known chats\\n    pub chats: Vec<Chat>,\\n\\n    /// UUID of the current chat\\n    pub current_chat_uuid: uuid::Uuid,\\n\\n    /// Holds the sender of UI events for later cloning if needed\\n    pub ui_tx: mpsc::UnboundedSender<UIEvent>,\\n\\n    /// Receives UI events (key presses, commands, etc)\\n    pub ui_rx: mpsc::UnboundedReceiver<UIEvent>,\\n\\n    /// Sends commands to the backend\\n    pub command_tx: Option<mpsc::UnboundedSender<CommandEvent>>,\\n\\n    /// Responds to commands from the backend\\n    /// And maps them to ui events\\n    pub command_responder: AppCommandResponder,\\n\\n    /// Mode the app is in, manages the which layout is rendered and if it should quit\\n    pub mode: AppMode,\\n\\n    /// Tracks the current selected state in the UI\\n    pub chats_state: ListState,\\n\\n    /// Tab names\\n    pub tab_names: Vec<&\\'static str>,\\n\\n    /// Index of selected tab\\n    pub selected_tab: usize,\\n\\n    /// States when viewing logs\\n    pub log_state: TuiWidgetState,\\n\\n    /// Commands that relate to boot, and not a chat\\n    pub boot_uuid: Uuid,\\n\\n    /// Skip indexing on boot\\n    pub skip_indexing: bool,\\n\\n    /// Override the working directory if it is not \".\"\\n    pub workdir: PathBuf,\\n\\n    /// Hack to get line wrapping on input into the textarea\\n    pub input_width: Option<u16>,\\n\\n    /// Max lines we can render in the chat messages\\n    pub chat_messages_max_lines: u16,\\n\\n    /// User configuration for the UI\\n    pub ui_config: UIConfig,\\n\\n    /// Informs the user if there is an update available\\n    pub update_available: Option<update_informer::Version>,\\n}\\n\\n#[derive(Debug, Clone, Copy, Default, PartialEq)]\\npub enum AppMode {\\n    #[default]\\n    Chat,\\n    Logs,\\n    Quit,\\n}', 'use std::collections::HashSet;\\n\\nuse ratatui::widgets::ScrollbarState;\\n\\nuse crate::{chat_message::ChatMessage, repository::Repository};\\n\\n#[derive(Debug, Clone)]\\npub struct Chat {\\n    /// Display name of the chat\\n    pub name: String,\\n    /// Identifier used to match responses\\n    pub uuid: uuid::Uuid,\\n    pub branch_name: Option<String>,\\n    pub messages: Vec<ChatMessage>,\\n    pub state: ChatState,\\n    pub new_message_count: usize,\\n    pub completed_tool_call_ids: HashSet<String>,\\n\\n    // Scrolling is per chat\\n    // but handled in the ui\\n    pub vertical_scroll_state: ScrollbarState,\\n    pub vertical_scroll: usize,\\n    pub num_lines: usize,\\n\\n    // Whether to auto-tail the chat on new messages\\n    pub auto_tail: bool,\\n\\n    pub repository: Option<Repository>,\\n}\\n\\nimpl Chat {\\n    pub fn add_message(&mut self, message: ChatMessage) {\\n        if !message.role().is_user() {\\n            self.new_message_count += 1;\\n        }\\n\\n        // If it\\'s a completed tool call, just register it is done and do not add the message\\n        // The state is updated when rendering on the initial tool call\\n        if message.role().is_tool() {\\n            let Some(tool_call) = message.maybe_completed_tool_call() else {\\n                tracing::error!(\\n                    \"Received a tool message without a tool call ID: {:?}\",\\n                    message\\n                );\\n                return;\\n            };\\n\\n            self.completed_tool_call_ids\\n                .insert(tool_call.id().to_string());\\n\\n            return;\\n        }\\n        self.messages.push(message);\\n    }\\n\\n    pub fn transition(&mut self, state: ChatState) {\\n        self.state = state;\\n    }\\n\\n    #[must_use]\\n    pub fn is_loading(&self) -> bool {\\n        matches!(\\n            self.state,\\n            ChatState::Loading | ChatState::LoadingWithMessage(_)\\n        )\\n    }\\n\\n    #[must_use]\\n    pub fn is_tool_call_completed(&self, tool_call_id: &str) -> bool {\\n        self.completed_tool_call_ids.contains(tool_call_id)\\n    }\\n}', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', 'mod chat_list_widget;\\nmod chat_messages_widget;\\nmod help_section_widget;\\nmod input_bar_widget;\\nmod message_formatting;\\nmod on_key;\\nmod ui;\\n\\npub use on_key::on_key;\\npub use ui::ui;', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '**Q:** I get a redb/duckdb error when starting, what is up?\\n\\n**A**: Possibly your index got corrupted, or you have another kwaak instance running on the same project. Try clearing the index with `kwaak clear-index` and restart kwaak. Note that this will require a reindexing of your codebase.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', 'use kwaak::commands::Command;\\nuse kwaak::frontend::{ui, UIEvent, UserInputCommand};\\nuse kwaak::test_utils::{setup_integration, IntegrationContext};\\nuse kwaak::{assert_agent_responded, assert_command_done};\\n\\n#[test_log::test(tokio::test(flavor = \"multi_thread\"))]\\nasync fn retry_chat() {\\n    let IntegrationContext {\\n        mut app,\\n        uuid,\\n        mut terminal,\\n\\n        handler_guard,\\n        repository_guard: _repository_guard,\\n        ..\\n    } = setup_integration().await.unwrap();\\n\\n    // First, let\\'s start a noop agent so an environment is running\\n    app.dispatch_command(\\n        uuid,\\n        Command::Chat {\\n            message: \"hello\".to_string(),\\n        },\\n    );\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"before_retry\", terminal.backend());\\n\\n    // Let\\'s retry the chat\\n    app.send_ui_event(UIEvent::UserInputCommand(uuid, UserInputCommand::Retry));\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    // It should now show 2 messages\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"after_retry\", terminal.backend());\\n\\n    // Force dropping it, for some reason it\\'s not being dropped\\n    drop(handler_guard);\\n}', '[Crate]: https://crates.io/crates/kwaak\\n[Docs Badge]: https://img.shields.io/docsrs/kwaak?logo=rust&style=flat-square&logoColor=E05D44', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\"]",
         "The provided context does not contain sufficient information to fully explain how channels work within the app from a user's perspective. It mentions that commands include a \"channel to feed back responses\" into, but it does not elaborate further on how these channels interact, relate, or are utilized from a user's perspective. Additionally, there is no detailed description or explanation about user interaction with these channels within the retrieved content. Therefore, the question cannot be answered based on the current context. \n\nIf further details are needed, exploring the files or code sections mentioning \"channels\" specifically within the `commands` or `frontend` modules might be a good starting point, as these modules seem to deal with command patterns and user interaction.",
         "There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective."
        ],
        [
         "4",
         "The provided context does not contain specific instructions on how to add a tool for an agent in Kwaak. However, the context does provide some relevant information about existing tools and how they might be structured.\n\nFor example, Kwaak's tools are implemented using traits such as `Tool` from the `swiftide` library, and typically involve defining specific functionalities and parameters as shown in the `DelegateAgent` and `RunTests` implementations.\n\nHere are some details you might consider when adding a new tool based on the context:\n\n1. **Define Tool Struct**: Create a new struct for your tool, implementing necessary fields and methods. Reference existing tools like `DelegateAgent` and `RunTests` as examples.\n\n2. **Implement the Tool Trait**: Use the `Tool` trait to define the behavior of your tool, including how it should be invoked and what parameters it expects.\n\n3. **Provide Description**: Ensure that your tool has a clear description and parameter annotations, as shown in the snippets, to help users understand the tool's purpose and usage.\n\n4. **Use Context**: Make use of the `AgentContext` to interact with the current session or execution environment.\n\n5. **Command Execution**: If your tool requires executing commands (like running tests or shell commands), see how commands are handled and executed in existing tools (e.g., `RunTests`, `shell_command`).\n\nUnfortunately, further specific steps or files required to add a tool aren't available in the context. You might find more concrete guidance in the source code files and the tool trait implementations like those mentioned above.",
         "['//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '{{description}}\\n\\n---\\n\\n_This pull request was created by [kwaak](https://github.com/bosun-ai/kwaak), a free, open-source, autonomous coding agent tool. Pull requests are tracked in bosun-ai/kwaak#48_\\n\\n{% if messages | length > 0 -%}\\n<details>\\n<summary>Message History</summary>\\n\\n{% for message in messages -%}\\n<details>\\n  <summary>{{message.role}}</summary>\\n\\n```markdown\\n{{message.content}}\\n```\\n</details>\\n{% if message.role is containing(\"Assistant\") -%}', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', ' Agent::builder()\\n        .context(Arc::clone(&context) as Arc<dyn AgentContext>)\\n        .system_prompt(system_prompt)\\n        .tools(tools.to_vec())\\n        .before_all(move |agent| {\\n            let initial_context = initial_context.clone();\\n\\n            Box::pin(async move {\\n                agent.context()\\n                    .add_message(chat_completion::ChatMessage::new_user(initial_context))\\n                    .await;\\n\\n                let top_level_project_overview = agent.context().exec_cmd(&Command::shell(\"fd -iH -d2 -E \\'.git/*\\'\")).await?.output;\\n                agent.context().add_message(chat_completion::ChatMessage::new_user(format!(\"The following is a max depth 2, high level overview of the directory structure of the project: \\\\n ```{top_level_project_overview}```\"))).await;\\n\\n                Ok(())\\n            })\\n        })\\n        .on_new_message(move |_, message| {\\n            let command_responder = tx_2.clone();\\n            let message = message.clone();\\n\\n            Box::pin(async move {\\n                command_responder.agent_message(message);\\n\\n                Ok(())\\n            })\\n        })\\n        .before_completion(move |_, _| {\\n            let command_responder = tx_3.clone();\\n            Box::pin(async move {\\n                command_responder.update(\"running completions\");\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let command_responder = tx_4.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                command_responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .after_tool(tool_summarizer.summarize_hook())\\n        .after_each', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', '\\n#[tool(\\n    description = \"Reads file content, including line numbers. You MUST use this tool to retrieve line numbers before making an edit with edit_file\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file_with_line_numbers(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    let lines = output\\n        .output\\n        .lines()\\n        .enumerate()\\n        .map(|(i, l)| format!(\"{line_num}|{l}\", line_num = i + 1));\\n\\n    Ok(lines.collect::<Vec<_>>().join(\"\\\\n\").into())\\n}\\n\\n#[tool(\\n    description = \"Write to a file. You MUST ALWAYS include the full file content, including what you did not change, as it overwrites the full file. Only make changes that pertain to your task.\",\\n    param(name = \"file_name\", description = \"Full path of the file\"),\\n    param(name = \"content\", description = \"FULL Content to write to the file\")\\n)]\\npub async fn write_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n    content: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::WriteFile(file_name.into(), content.into());\\n\\n    context.exec_cmd(&cmd).await?;\\n\\n    let success_message = format!(\"File written successfully to {file_name}\");\\n\\n    Ok(success_message.into())\\n}\\n\\n#[tool(\\n    description = \"Searches for a file inside the current project, leave the argument empty to list all files. Uses `find`.\",\\n    param(name = \"file_name\", description = \"Partial or full name of the file\")\\n)]\\npub async fn search_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::Shell(format!(\"fd -E \\'.git/*\\' -iH --full-path \\'{file_name}\\'\"));\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', 'mod delegate_agent;\\nmod replace_lines;\\n\\npub use delegate_agent::DelegateAgent;\\npub use replace_lines::replace_lines;\\n\\nuse std::sync::Arc;\\nuse swiftide::traits::CommandError;\\n\\nuse anyhow::{Context as _, Result};\\nuse swiftide::{\\n    chat_completion::{errors::ToolError, ToolOutput},\\n    query::{search_strategies, states},\\n    traits::{AgentContext, Command},\\n};\\nuse swiftide_macros::{tool, Tool};\\nuse tavily::Tavily;\\nuse tokio::sync::Mutex;\\n\\nuse crate::{\\n    config::ApiKey,\\n    git::github::GithubSession,\\n    templates::Templates,\\n    util::{self, accept_non_zero_exit},\\n};\\n\\n#[allow(dead_code)]\\nstatic MAIN_BRANCH_CMD: &str = \"git remote show origin | sed -n \\'/HEAD branch/s/.*: //p\\'\";\\n\\n/// WARN: Experimental\\n#[tool(\\n    description = \"Run any shell command in the current project, use this if other tools are not enough.\",\\n    param(\\n        name = \"cmd\",\\n        description = \"The shell command, including any arguments if needed, to run\"\\n    )\\n)]\\npub async fn shell_command(context: &dyn AgentContext, cmd: &str) -> Result<ToolOutput, ToolError> {\\n    if util::is_git_branch_change(cmd) {\\n        return Ok(\\n            \"You cannot change branches, you are already on a branch created specifically for you.\"\\n                .into(),\\n        );\\n    }\\n    let output = accept_non_zero_exit(context.exec_cmd(&Command::Shell(cmd.into())).await)?;\\n    Ok(output.into())\\n}\\n\\n#[tool(\\n    description = \"Reads file content\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}\\n\\n// TODO: Better to have a single read_file tool with an optional line number flag', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions']",
         "The provided context does not contain specific instructions on how to add a tool for an agent in Kwaak. However, the context does provide some relevant information about existing tools and how they might be structured.\n\nFor example, Kwaak's tools are implemented using traits such as `Tool` from the `swiftide` library, and typically involve defining specific functionalities and parameters as shown in the `DelegateAgent` and `RunTests` implementations.\n\nHere are some details you might consider when adding a new tool based on the context:\n\n1. **Define Tool Struct**: Create a new struct for your tool, implementing necessary fields and methods. Reference existing tools like `DelegateAgent` and `RunTests` as examples.\n\n2. **Implement the Tool Trait**: Use the `Tool` trait to define the behavior of your tool, including how it should be invoked and what parameters it expects.\n\n3. **Provide Description**: Ensure that your tool has a clear description and parameter annotations, as shown in the snippets, to help users understand the tool's purpose and usage.\n\n4. **Use Context**: Make use of the `AgentContext` to interact with the current session or execution environment.\n\n5. **Command Execution**: If your tool requires executing commands (like running tests or shell commands), see how commands are handled and executed in existing tools (e.g., `RunTests`, `shell_command`).\n\nUnfortunately, further specific steps or files required to add a tool aren't available in the context. You might find more concrete guidance in the source code files and the tool trait implementations like those mentioned above.",
         "How can I add a tool for an agent?"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The context provided does not offer detailed i...</td>\n",
       "      <td>[Kwaak is free and open-source. You can bring ...</td>\n",
       "      <td>The context provided does not offer detailed i...</td>\n",
       "      <td>Explain kwaak works and explain the architectu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The provided context does not specifically exp...</td>\n",
       "      <td>[## How is Kwaak different from other tools?\\n...</td>\n",
       "      <td>The provided context does not specifically exp...</td>\n",
       "      <td>How are tools used by an agent?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To configure a session in a file such that use...</td>\n",
       "      <td>[### Session Management\\n\\nKwaak supports runn...</td>\n",
       "      <td>To configure a session in a file such that use...</td>\n",
       "      <td>I'd like to be able to configure a session in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The provided context does not contain sufficie...</td>\n",
       "      <td>[# Architecture\\n\\nKwaak has a lightweight, ra...</td>\n",
       "      <td>The provided context does not contain sufficie...</td>\n",
       "      <td>There are multiple uses of channels in the app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>[//! Agents defines various agents that can be...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>How can I add a tool for an agent?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  The context provided does not offer detailed i...   \n",
       "1  The provided context does not specifically exp...   \n",
       "2  To configure a session in a file such that use...   \n",
       "3  The provided context does not contain sufficie...   \n",
       "4  The provided context does not contain specific...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Kwaak is free and open-source. You can bring ...   \n",
       "1  [## How is Kwaak different from other tools?\\n...   \n",
       "2  [### Session Management\\n\\nKwaak supports runn...   \n",
       "3  [# Architecture\\n\\nKwaak has a lightweight, ra...   \n",
       "4  [//! Agents defines various agents that can be...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The context provided does not offer detailed i...   \n",
       "1  The provided context does not specifically exp...   \n",
       "2  To configure a session in a file such that use...   \n",
       "3  The provided context does not contain sufficie...   \n",
       "4  The provided context does not contain specific...   \n",
       "\n",
       "                                            question  \n",
       "0  Explain kwaak works and explain the architectu...  \n",
       "1                    How are tools used by an agent?  \n",
       "2  I'd like to be able to configure a session in ...  \n",
       "3  There are multiple uses of channels in the app...  \n",
       "4                 How can I add a tool for an agent?  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "\n",
    "pd_raw = pd.read_json(\"evals/ragas/base_raw.json\")\n",
    "pd_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3a80320b094e5a89ecd8ad2192a6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Question 1: Explain kwaak works and explain the architecture. Include a mermaid diagram of all th…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8691c6c9000e45d59f3ef85db353ae61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='The context provided does not offer detailed information specific to the complete architecture…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f975fbd8df44f5aa8874cd2da3d343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Question 2: How are tools used by an agent?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b84c0dec347476fb7d6532d5048bf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"The provided context does not specifically explain how tools are used by an agent, in terms of…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf60caa7a4246b7906de3636dc01d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"Question 3: I'd like to be able to configure a session in a file, such that users can add their o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a879c39e5a114bd482a970f74995000c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='To configure a session in a file such that users can add their own custom agents in Kwaak, fol…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e8e9c62ad944b0957c4c19eab64e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Question 4: There are multiple uses of channels in the app. Explore how the channels work, intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaf7cb3579a4d7db5d1f45593f11865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='The provided context does not contain sufficient information to fully explain how channels wor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c749a755ec440daca1b9319d015abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Question 5: How can I add a tool for an agent?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18e1a027f44f65a4a608544c1f52f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value=\"The provided context does not contain specific instructions on how to add a tool for an agent …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ff1d5f06cf49509bac5a0cfb2bb44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Confirm Ground Truths', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c21a4ed61e4927b16d5789d9cc04e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Ground truths updated and saved successfully!')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a Textarea widget for each ground truth\n",
    "textareas = [widgets.Textarea(value=ground_truth.replace('\\\\n', '\\n'), layout=widgets.Layout(width='100%', height='200px')) for ground_truth in pd_raw[\"ground_truth\"]]\n",
    "pd_base = pd_raw.copy()\n",
    "base_file = \"evals/ragas/base.json\"\n",
    "\n",
    "# Display the Textarea widgets with truncated questions as labels\n",
    "for i, textarea in enumerate(textareas):\n",
    "    question_label = pd_raw[\"question\"][i][:100] + \"...\" if len(pd_raw[\"question\"][i]) > 100 else pd_raw[\"question\"][i]\n",
    "    display(widgets.Label(f\"Question {i+1}: {question_label}\"))\n",
    "    display(textarea)\n",
    "\n",
    "# Function to get the updated ground truths\n",
    "def get_updated_ground_truths():\n",
    "    return [textarea.value for textarea in textareas]\n",
    "\n",
    "# Button to save the updated ground truths\n",
    "save_button = widgets.Button(description=\"Confirm Ground Truths\")\n",
    "display(save_button)\n",
    "\n",
    "def on_save_button_clicked(b):\n",
    "    updated_ground_truths = get_updated_ground_truths()\n",
    "\n",
    "    pd_base = pd_raw.copy()\n",
    "    # Update the dataframe with the new ground truths\n",
    "    columns = pd.Series(updated_ground_truths, name=\"ground_truth\")\n",
    "    pd_base.update(columns)\n",
    "    \n",
    "    # Save the updated dataframe back to the JSON file\n",
    "    pd_base.to_json(base_file, orient='records')\n",
    "    display(widgets.Label(\"Ground truths updated and saved successfully!\"))\n",
    "\n",
    "save_button.on_click(on_save_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "38b6e15a-3691-4854-b057-6ef080f548e6",
       "rows": [
        [
         "0",
         "The context provided does not offer detailed information specific to the complete architecture of Kwaak or a high-level component diagram in a format such as Mermaid. Therefore, I cannot generate a diagram or a full architectural description based solely on the given context.\n\nHowever, based on the snippets retrieved, here are some relevant points about how Kwaak works and its components:\n\n1. **General Functionality**: \n   - Kwaak allows you to run autonomous AI agents locally to work on coding tasks such as documenting, testing, and improving code quality.\n   - It provides a terminal user interface (TUI) for interaction with the agents.\n\n2. **Backend and Frontend**:\n   - It has a lightweight frontend based on `ratatui` that communicates with a backend via commands, and a command pattern is used to handle backend functionalities asynchronously. [Reference: ARCHITECTURE.md]\n\n3. **Indexing**:\n   - Upon initial setup, it indexes the codebase using \"Swiftide\" for Retrieval-Augmented Generation (RAG). This indexing is stored using `duckdb` and is cached with `redb`. [Reference: README.md]\n\n4. **Execution Environment**:\n   - Kwaak uses Docker containers to create safe execution environments for agents to run code. This ensures that the agents' execution doesn't affect the local system environment. [Reference: README.md]\n\n5. **Feedback Loop and Sessions**:\n   - Agents operate in a session, usually involving continuous feedback with an LLM until their assigned task is completed.\n\nUnfortunately, the provided context does not contain enough specific details about the architecture to further elaborate with a high-level diagram illustrative of all components in Mermaid or any other format. Additionally, any graphical architecture diagrams referred to in the content (e.g., `architecture.svg`) are not included as text, and hence such visual information cannot be reproduced here.\n\nFor a more detailed exploration of the architecture diagram or component breakdown, a look at the referenced architecture image or further documentation beyond the provided context would be necessary.",
         "['Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '**Q:** I get a redb/duckdb error when starting, what is up?\\n\\n**A**: Possibly your index got corrupted, or you have another kwaak instance running on the same project. Try clearing the index with `kwaak clear-index` and restart kwaak. Note that this will require a reindexing of your codebase.', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## Latest updates on our blog :fire:\\n\\n- [Releasing kwaak with kwaak](https://bosun.ai/posts/releasing-kwaak-with-kwaak/)', '//! Builds various storage providers for kwaak\\n//!\\n//! Handled as statics to avoid multiple instances of the same storage provider\\n//!\\n//!\\n//! Currently there are 3 tables:\\n//! - project itself (indexing/retrieval) (uuid, path, chunk, embeddings)\\n//! - cache (for caching in indexing/retrieval) (uuid, path)\\n//! - runtime settings (for storing runtime settings) (key, value)\\n//!\\n//! Right now, these are relatively simple. Friendly reminder for future me and others to consider\\n//! a decent migration strategy if these tables change.\\n\\nuse std::sync::OnceLock;\\n\\nuse anyhow::{Context, Result};\\nuse swiftide::{indexing::EmbeddedField, integrations::duckdb::Duckdb};\\n\\nuse crate::repository::Repository;\\n\\nstatic DUCK_DB: OnceLock<Duckdb> = OnceLock::new();\\n\\n/// Retrieves a static duckdb\\n///\\n/// # Panics\\n///\\n/// Panics if it cannot setup duckdb\\npub fn get_duckdb(repository: &Repository) -> Duckdb {\\n    DUCK_DB\\n        .get_or_init(|| build_duckdb(repository).expect(\"Failed to build duckdb\"))\\n        .to_owned()\\n}\\n\\n// Probably should just be on the repository/config, cloned from there.\\n// This sucks in tests\\npub(crate) fn build_duckdb(repository: &Repository) -> Result<Duckdb> {\\n    let config = repository.config();\\n    let path = config.cache_dir().join(\"duck.db3\");\\n\\n    tracing::debug!(\"Building Duckdb: {}\", path.display());\\n\\n    let embedding_provider = config.embedding_provider();\\n\\n    let connection =\\n        duckdb::Connection::open(&path).context(\"Failed to open connection to duckdb\")?;\\n    Duckdb::builder()\\n        .connection(connection)\\n        .with_vector(\\n            EmbeddedField::Combined,\\n            embedding_provider.vector_size().try_into()?,\\n        )\\n        .table_name(normalize_table_name(&config.project_name))\\n        .cache_table(format!(\\n            \"cache_{}\",\\n            normalize_table_name(&config.project_name)\\n        ))\\n        .build()\\n        .context(\"Failed to build Duckdb\")\\n}\\n\\n// Is this enough?\\nfn normalize_table_name(name: &str) -> String {\\n    name.replace(\\'-\\', \"_\")\\n}', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '**Q:** Kwaak feels very slow\\n\\n**A:** Try increasing the resources available for docker. For docker desktop this is in Settings -> Resources -> Advanced. On MacOS, adding your terminal and/or kwaak to developer tools can also help.', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '[Crate]: https://crates.io/crates/kwaak\\n[Docs Badge]: https://img.shields.io/docsrs/kwaak?logo=rust&style=flat-square&logoColor=E05D44']",
         "The context provided does not offer detailed information specific to the complete architecture of Kwaak or a high-level component diagram in a format such as Mermaid. Therefore, I cannot generate a diagram or a full architectural description based solely on the given context.\n\nHowever, based on the snippets retrieved, here are some relevant points about how Kwaak works and its components:\n\n1. **General Functionality**: \n   - Kwaak allows you to run autonomous AI agents locally to work on coding tasks such as documenting, testing, and improving code quality.\n   - It provides a terminal user interface (TUI) for interaction with the agents.\n\n2. **Backend and Frontend**:\n   - It has a lightweight frontend based on `ratatui` that communicates with a backend via commands, and a command pattern is used to handle backend functionalities asynchronously. [Reference: ARCHITECTURE.md]\n\n3. **Indexing**:\n   - Upon initial setup, it indexes the codebase using \"Swiftide\" for Retrieval-Augmented Generation (RAG). This indexing is stored using `duckdb` and is cached with `redb`. [Reference: README.md]\n\n4. **Execution Environment**:\n   - Kwaak uses Docker containers to create safe execution environments for agents to run code. This ensures that the agents' execution doesn't affect the local system environment. [Reference: README.md]\n\n5. **Feedback Loop and Sessions**:\n   - Agents operate in a session, usually involving continuous feedback with an LLM until their assigned task is completed.\n\nUnfortunately, the provided context does not contain enough specific details about the architecture to further elaborate with a high-level diagram illustrative of all components in Mermaid or any other format. Additionally, any graphical architecture diagrams referred to in the content (e.g., `architecture.svg`) are not included as text, and hence such visual information cannot be reproduced here.\n\nFor a more detailed exploration of the architecture diagram or component breakdown, a look at the referenced architecture image or further documentation beyond the provided context would be necessary.",
         "Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components."
        ],
        [
         "1",
         "The provided context does not specifically explain how tools are used by an agent, in terms of their operational mechanism within a larger system. However, there is some information about the structure and functionality of tools in `Kwaak`.\n\n### Key Points from the Context:\n\n1. **Agent and Tools System**:\n   - Agents in Kwaak can operate a number of tools that help them execute tasks. The context refers to various tools such as those for running tests, checking code coverage, and interacting with shell commands. ([source code](./src/agent/tools/mod.rs), [README.md](./README.md))\n\n2. **Delegate Agent Tool**:\n   - Presents an example of how a tool is set up. The `DelegateAgent` tool delegates tasks to a particular agent. It uses an object called a `RunningAgent` that is assumed to be already configured ([source code](./src/agent/tools/delegate_agent.rs)).\n\n3. **Tool Configuration and Invocation**:\n   - Tools are configured and utilized within agents during certain tasks, e.g., running shell commands or reading files. Some parts of the code provide functionality for running commands with a sandboxed shell environment using Docker ([source code](./src/agent/tools/mod.rs)).\n\n4. **Initial Context and Configuration**:\n   - The system can utilize initial context and configuration to guide the tools. This context might describe how a project is set up or give an overview of the directory structure to help with the execution of tasks ([source code](./src/agent/agents/coding.rs)).\n\n5. **Session and Agent Management**:\n   - Session management indicates parallel operations with each session containing its own configuration of agents and tools ([ARCHITECTURE.md](./ARCHITECTURE.md)).\n\n### Leads for Further Information:\nThe retrieved context has snippets pointing toward various sections that could provide additional details, such as the specific role of each tool and how they are incorporated into an agent's workflow. These include files like `agents/mod.rs`, `session.rs`, and `agent/tools/mod.rs`.\n\nBecause the context does not fully explain the specifics of tool usage by agents, I recommend checking further documentation or additional sections of the source code not provided here for comprehensive understanding.",
         "['## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '## Additional information\\n\\nThis context is provided for an ai agent that has to accomplish the above. Additionally, the agent has access to the following tools:\\n{{available_tools}}', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', ' Agent::builder()\\n        .context(Arc::clone(&context) as Arc<dyn AgentContext>)\\n        .system_prompt(system_prompt)\\n        .tools(tools.to_vec())\\n        .before_all(move |agent| {\\n            let initial_context = initial_context.clone();\\n\\n            Box::pin(async move {\\n                agent.context()\\n                    .add_message(chat_completion::ChatMessage::new_user(initial_context))\\n                    .await;\\n\\n                let top_level_project_overview = agent.context().exec_cmd(&Command::shell(\"fd -iH -d2 -E \\'.git/*\\'\")).await?.output;\\n                agent.context().add_message(chat_completion::ChatMessage::new_user(format!(\"The following is a max depth 2, high level overview of the directory structure of the project: \\\\n ```{top_level_project_overview}```\"))).await;\\n\\n                Ok(())\\n            })\\n        })\\n        .on_new_message(move |_, message| {\\n            let command_responder = tx_2.clone();\\n            let message = message.clone();\\n\\n            Box::pin(async move {\\n                command_responder.agent_message(message);\\n\\n                Ok(())\\n            })\\n        })\\n        .before_completion(move |_, _| {\\n            let command_responder = tx_3.clone();\\n            Box::pin(async move {\\n                command_responder.update(\"running completions\");\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let command_responder = tx_4.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                command_responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .after_tool(tool_summarizer.summarize_hook())\\n        .after_each', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', ' {\\n    let query_pipeline = indexing::build_query_pipeline(repository, None)?;\\n    let mut tools = vec![\\n        tools::write_file(),\\n        tools::search_file(),\\n        tools::git(),\\n        tools::shell_command(),\\n        tools::search_code(),\\n        tools::fetch_url(),\\n        tools::ExplainCode::new(query_pipeline).boxed(),\\n    ];\\n\\n    // agent edit mode specific tools\\n    match repository.config().agent_edit_mode {\\n        AgentEditMode::Whole => {\\n            tools.push(tools::write_file());\\n            tools.push(tools::read_file());\\n        }\\n        AgentEditMode::Line => {\\n            tools.push(tools::read_file_with_line_numbers());\\n            tools.push(tools::replace_lines());\\n            tools.push(tools::add_lines());\\n        }\\n    }\\n\\n    // gitHub-related tools\\n    if let Some(github_session) = github_session {\\n        tools.push(tools::CreateOrUpdatePullRequest::new(github_session).boxed());\\n        tools.push(tools::GithubSearchCode::new(github_session).boxed());\\n    }\\n\\n    // web search tool\\n    if let Some(tavily_api_key) = &repository.config().tavily_api_key {\\n        let tavily = Tavily::builder(tavily_api_key.expose_secret()).build()?;\\n        tools.push(tools::SearchWeb::new(tavily, tavily_api_key.clone()).boxed());\\n    };\\n\\n    // test-related tools\\n    if let Some(test_command) = &repository.config().commands.test {\\n        tools.push(tools::RunTests::new(test_command).boxed());\\n    }\\n\\n    if let Some(coverage_command) = &repository.config().commands.coverage {\\n        tools.push(tools::RunCoverage::new(coverage_command).boxed());\\n    }\\n\\n    // reset file tool\\n    if let Some(env) = agent_env {\\n        tools.push(tools::ResetFile::new(&env.start_ref).boxed());\\n    }\\n\\n    tools.retain(|tool| {\\n        !repository\\n            .config()\\n            .disabled_tools()\\n            .iter()\\n            .any(|s| *s == tool.name().as_ref())\\n    });\\n\\n    Ok(tools)\\n}', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', '{{description}}\\n\\n---\\n\\n_This pull request was created by [kwaak](https://github.com/bosun-ai/kwaak), a free, open-source, autonomous coding agent tool. Pull requests are tracked in bosun-ai/kwaak#48_\\n\\n{% if messages | length > 0 -%}\\n<details>\\n<summary>Message History</summary>\\n\\n{% for message in messages -%}\\n<details>\\n  <summary>{{message.role}}</summary>\\n\\n```markdown\\n{{message.content}}\\n```\\n</details>\\n{% if message.role is containing(\"Assistant\") -%}', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'mod delegate_agent;\\nmod replace_lines;\\n\\npub use delegate_agent::DelegateAgent;\\npub use replace_lines::replace_lines;\\n\\nuse std::sync::Arc;\\nuse swiftide::traits::CommandError;\\n\\nuse anyhow::{Context as _, Result};\\nuse swiftide::{\\n    chat_completion::{errors::ToolError, ToolOutput},\\n    query::{search_strategies, states},\\n    traits::{AgentContext, Command},\\n};\\nuse swiftide_macros::{tool, Tool};\\nuse tavily::Tavily;\\nuse tokio::sync::Mutex;\\n\\nuse crate::{\\n    config::ApiKey,\\n    git::github::GithubSession,\\n    templates::Templates,\\n    util::{self, accept_non_zero_exit},\\n};\\n\\n#[allow(dead_code)]\\nstatic MAIN_BRANCH_CMD: &str = \"git remote show origin | sed -n \\'/HEAD branch/s/.*: //p\\'\";\\n\\n/// WARN: Experimental\\n#[tool(\\n    description = \"Run any shell command in the current project, use this if other tools are not enough.\",\\n    param(\\n        name = \"cmd\",\\n        description = \"The shell command, including any arguments if needed, to run\"\\n    )\\n)]\\npub async fn shell_command(context: &dyn AgentContext, cmd: &str) -> Result<ToolOutput, ToolError> {\\n    if util::is_git_branch_change(cmd) {\\n        return Ok(\\n            \"You cannot change branches, you are already on a branch created specifically for you.\"\\n                .into(),\\n        );\\n    }\\n    let output = accept_non_zero_exit(context.exec_cmd(&Command::Shell(cmd.into())).await)?;\\n    Ok(output.into())\\n}\\n\\n#[tool(\\n    description = \"Reads file content\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}\\n\\n// TODO: Better to have a single read_file tool with an optional line number flag', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '\\n\\n    if let Err(error) = app_result {\\n        ::tracing::error!(?error, \"Kwaak encountered an error\\\\n {error:#}\");\\n        eprintln!(\"Kwaak encountered an error\\\\n {error}\");\\n        std::process::exit(1);\\n    }\\n\\n    Ok(())\\n}\\n\\nasync fn test_tool(\\n    repository: &repository::Repository,\\n    tool_name: &str,\\n    tool_args: Option<&str>,\\n) -> Result<()> {\\n    let github_session = Arc::new(GithubSession::from_repository(&repository)?);\\n    let tool = available_tools(repository, Some(&github_session), None)?\\n        .into_iter()\\n        .find(|tool| tool.name() == tool_name)\\n        .context(\"Tool not found\")?;\\n\\n    let mut executor = DockerExecutor::default();\\n    let dockerfile = &repository.config().docker.dockerfile;\\n\\n    println!(\\n        \"Starting executor with dockerfile: {}\",\\n        dockerfile.display()\\n    );\\n    let running_executor = executor\\n        .with_context_path(&repository.config().docker.context)\\n        .with_image_name(repository.config().project_name.to_lowercase())\\n        .with_dockerfile(dockerfile)\\n        .to_owned()\\n        .start()\\n        .await?;\\n\\n    let agent_context = DefaultContext::from_executor(running_executor);\\n\\n    println!(\"Invoking tool: {tool_name}\");\\n    let output = tool\\n        .invoke(&agent_context as &dyn AgentContext, tool_args)\\n        .await?;\\n\\n    println!(\"{output}\");\\n\\n    Ok(())\\n}\\n\\n#[instrument(skip_all)]', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', '\\n\\n    /// Optional: Use github for code search, creating pull requests, and automatic pushing to\\n    /// remotes\\n    #[serde(default)]\\n    pub github_api_key: Option<ApiKey>,\\n\\n    /// Required if using `OpenAI`\\n    #[serde(default)]\\n    pub openai_api_key: Option<ApiKey>,\\n\\n    /// Required if using \\'Anthropic\\'\\n    #[serde(default)]\\n    pub anthropic_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Open Router`\\n    #[serde(default)]\\n    pub open_router_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Azure OpenAI`\\n    #[serde(default)]\\n    pub azure_openai_api_key: Option<ApiKey>,\\n\\n    #[serde(default)]\\n    pub tool_executor: SupportedToolExecutors,\\n\\n    /// A list of tool name and whether it is enabled or disabled\\n    ///\\n    /// This allows the user to disable tools that are not needed for their workflow. Or enable\\n    /// tools that are disabled by default\\n    #[serde(default)]\\n    pub tools: Tools,\\n\\n    /// By default the agent stops if the last message was its own and there are no new\\n    /// completions.\\n    ///\\n    /// When endless mode is enabled, the agent will keep running until it either cannot complete,\\n    /// did complete or was manually stopped.\\n    ///\\n    /// In addition, the agent is instructed that it cannot ask for feedback, but should try to\\n    /// complete its task instead.\\n    ///\\n    /// When running without a TUI, the agent will always run in endless mode.\\n    ///\\n    /// WARN: There currently is _no_ limit for endless mode\\n    #[serde(default)]\\n    pub endless_mode: bool,\\n\\n    /// OpenTelemetry tracing feature toggle\\n    #[serde(default = \"default_otel_enabled\")]\\n    pub otel_enabled: bool,\\n\\n    /// How the agent will edit files, defaults to whole\\n    #[serde(default)]\\n    pub agent_edit_mode: AgentEditMode,\\n\\n    /// Additional constraints / instructions for the agent\\n    ///\\n    /// These are passes to the agent in the system prompt and are rendered in a list. If you\\n    /// intend to use more complicated instructions, consider adding a file to read in the\\n']",
         "The provided context does not specifically explain how tools are used by an agent, in terms of their operational mechanism within a larger system. However, there is some information about the structure and functionality of tools in `Kwaak`.\n\n### Key Points from the Context:\n\n1. **Agent and Tools System**:\n   - Agents in Kwaak can operate a number of tools that help them execute tasks. The context refers to various tools such as those for running tests, checking code coverage, and interacting with shell commands. ([source code](./src/agent/tools/mod.rs), [README.md](./README.md))\n\n2. **Delegate Agent Tool**:\n   - Presents an example of how a tool is set up. The `DelegateAgent` tool delegates tasks to a particular agent. It uses an object called a `RunningAgent` that is assumed to be already configured ([source code](./src/agent/tools/delegate_agent.rs)).\n\n3. **Tool Configuration and Invocation**:\n   - Tools are configured and utilized within agents during certain tasks, e.g., running shell commands or reading files. Some parts of the code provide functionality for running commands with a sandboxed shell environment using Docker ([source code](./src/agent/tools/mod.rs)).\n\n4. **Initial Context and Configuration**:\n   - The system can utilize initial context and configuration to guide the tools. This context might describe how a project is set up or give an overview of the directory structure to help with the execution of tasks ([source code](./src/agent/agents/coding.rs)).\n\n5. **Session and Agent Management**:\n   - Session management indicates parallel operations with each session containing its own configuration of agents and tools ([ARCHITECTURE.md](./ARCHITECTURE.md)).\n\n### Leads for Further Information:\nThe retrieved context has snippets pointing toward various sections that could provide additional details, such as the specific role of each tool and how they are incorporated into an agent's workflow. These include files like `agents/mod.rs`, `session.rs`, and `agent/tools/mod.rs`.\n\nBecause the context does not fully explain the specifics of tool usage by agents, I recommend checking further documentation or additional sections of the source code not provided here for comprehensive understanding.",
         "How are tools used by an agent?"
        ],
        [
         "2",
         "To configure a session in a file such that users can add their own custom agents in Kwaak, follow this detailed step-by-step plan based on the given context:\n\n1. **Understanding the Session Concept**: \n   - Sessions in Kwaak are used to represent an ongoing agent interaction. They are more general than a simple chat and may be utilized for non-chat interactions in the future (Reference: _ARCHITECTURE.md_).\n\n2. **Configure Session Lifecycle**:\n   - When a session is created via a new chat or agent, a Docker container is initialized, the environment is configured, and an agent is started (Reference: _ARCHITECTURE.md_).\n\n3. **Use `kwaak.toml` for Configuration**:\n   - Create a `kwaak.toml` file which will include the session configurations. This configuration file is pivotal to adjusting agent settings and tool configurations (Reference: _README.md_).\n\n4. **Session Configuration Parameters**:\n   - Make sure to include necessary configurations in the `kwaak.toml` file. These configurations include, but are not limited to:\n     - `SupportedAgentConfigurations` for defining agent architectures (e.g., `Coding`, `PlanAct`).\n     - Tool executors configurations such as `Docker` or `Local`.\n\n5. **Custom Agent Definitions**:\n   - Users can create custom agents by defining them in the `kwaak.toml` configuration file. Support for custom tools can also be configured here.\n   - Example from the context suggests the use of agent constraints, tool lists, and edit modes to customize agent behavior (`config.rs`).\n\n6. **Onboarding and Setup**:\n   - Utilize Kwaak’s onboarding module to guide users through setting up their configurations with the configuration file being generated during this process. This accommodates user-specific setups (Reference: _onboarding/mod.rs_).\n\n7. **Use Environment Variables for Customization**:\n   - Provide flexibility for users to override configurations via environment variables. This helps accommodate different setups for diverse contributor environments (Reference: _README.md_).\n\n8. **Testing and Validating Configurations**:\n   - Use Docker to manage test environments and validate the agent setups to ensure they perform as intended (Reference: _benchmarks/swe/README.md_).\n\nBy following these steps, you can configure sessions in a file, allowing users to add their custom agents. The core idea rests on leveraging `kwaak.toml` for flexible and customizable agent configurations as well as providing an onboarding flow to support end-user interaction with the configuration process. \n\nIf you need more detailed steps for specific configurations, please consult the full documentation or context for additional guidance.",
         "['### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '### Session Lifecycle\\n\\n1. **Creation**: When a user starts a new chat or creates a new agent, a new session is created with a unique UUID.\\n2. **Initialization**: The session sets up a Docker container, generates initial context using RAG, and configures the environment.\\n3. **Agent Execution**: The session starts an agent (e.g., coding agent or plan-and-act agent) which interacts with the LLM.\\n4. **Message Handling**: Sessions maintain communication channels for handling messages, including potential agent swaps.\\n5. **Termination**: When a chat is closed or when Kwaak exits, the associated session is stopped.', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '    /// repository instead.\\n    #[serde(default)]\\n    pub agent_custom_constraints: Option<Vec<String>>,\\n\\n    #[serde(default)]\\n    pub ui: UIConfig,\\n\\n    /// Number of completions before the agent summarizes the conversation.\\n    /// This is used to steer the agent to focus on the current task. If this value is too small\\n    /// the agent will have clear loss of context when performing tasks. If this value is too large\\n    /// the agent will not have focus and not understand what is relevant and important.\\n    ///\\n    /// Additionally, summarizing the conversation will reduce the context window which can be\\n    /// beneficial for APIs with stringent limits on context tokens.\\n    ///\\n    /// Defaults to 10.\\n    #[serde(default = \"default_num_completions_for_summary\")]\\n    pub num_completions_for_summary: usize,\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(default)]\\npub struct UIConfig {\\n    pub hide_header: bool,\\n}\\n\\nfn default_otel_enabled() -> bool {\\n    false\\n}\\n\\nfn default_num_completions_for_summary() -> usize {\\n    10\\n}\\n\\n/// Agent session configurations supported by Kwaak\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\npub enum SupportedAgentConfigurations {\\n    /// Single looping agent that has all tools available\\n    #[default]\\n    #[serde(alias = \"V1\")]\\n    Coding,\\n    /// A two stage agent, starting with a planning agent that delegates to the coding\\n    /// agent\\n    PlanAct,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum SupportedToolExecutors {\\n    #[default]\\n    Docker,\\n    Local,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default, strum_macros::EnumIs)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum AgentEditMode {\\n    #[default]\\n    Whole,\\n    Line,\\n    // i.e. udiff, llm reviewed, etc\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize)]', \"### Configuration\\n\\nKwaak supports configuring different Large Language Models (LLMs) for distinct tasks like indexing, querying, and embedding to optimize performance and accuracy. Be sure to tailor the configurations to fit the scope and blend of the tasks you're tackling.\", \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', 'use std::sync::{Arc, Mutex};\\n\\nuse anyhow::{Context as _, Result};\\nuse derive_builder::Builder;\\nuse swiftide::{\\n    agents::tools::local_executor::LocalExecutor,\\n    chat_completion::{ParamSpec, Tool, ToolSpec},\\n    traits::{SimplePrompt, ToolExecutor},\\n};\\nuse swiftide_docker_executor::DockerExecutor;\\nuse tavily::Tavily;\\nuse tokio::sync::mpsc::UnboundedSender;\\nuse tokio_util::{sync::CancellationToken, task::AbortOnDropHandle};\\nuse uuid::Uuid;\\n\\nuse crate::{\\n    agent::{tools::DelegateAgent, util},\\n    commands::Responder,\\n    config::{self, AgentEditMode, SupportedToolExecutors},\\n    git::github::GithubSession,\\n    indexing,\\n    repository::Repository,\\n};\\n\\nuse super::{\\n    agents,\\n    env_setup::{self, AgentEnvironment, EnvSetup},\\n    running_agent::RunningAgent,\\n    tools,\\n};\\n\\n/// Session represents the abstract state of an ongoing agent interaction (i.e. in a chat)\\n///\\n/// Consider the implementation \\'emergent architecture\\' (an excuse for an isolated mess)\\n///\\n/// Some future ideas:\\n///     - Session configuration from a file\\n///     - A registry pattern for agents, so you could in theory run multiple concurrent\\n#[derive(Clone, Builder)]\\n#[builder(build_fn(private), setter(into))]\\npub struct Session {\\n    pub session_id: Uuid,\\n    pub repository: Arc<Repository>,\\n    pub default_responder: Arc<dyn Responder>,\\n    pub initial_query: String,\\n\\n    /// Handle to send messages to the running session\\n    running_session_tx: UnboundedSender<SessionMessage>,\\n}\\n\\n/// Messages that can be send from i.e. a tool to an active session\\n#[derive(Clone)]\\npub enum SessionMessage {\\n    SwapAgent(RunningAgent),\\n}\\n\\nimpl std::fmt::Debug for SessionMessage {\\n    fn fmt(&self, f: &mut std::fmt::Formatter<\\'_>) -> std::fmt::Result {\\n        match self {\\n            Self::SwapAgent(_) => f.debug_tuple(\"SwapAgent\").finish(),\\n        }\\n    }\\n}', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '#### Backoff Configuration\\n\\nKwaak uses the exponential backoff strategy to handle retries. Currently, only\\nOpenAI, OpenRouter, and Anthropic calls will make use of the backoff parameters.\\nYou can configure the backoff settings in the `kwaak.toml` file under a\\n`[backoff]` section. These settings are optional, and default to the following\\nvalues:\\n\\n- `initial_interval_sec`: Defaults to 15 seconds. This sets the initial waiting time between retries.\\n- `multiplier`: Defaults to 2.0. This factor multiplies the interval on each retry attempt.\\n- `randomization_factor`: Defaults to 0.05. Introduces randomness to avoid retry storms.\\n- `max_elapsed_time_sec`: Defaults to 120 seconds. This total time all attempts are allowed.\\n\\nExample Configuration:\\n\\n```toml\\n[backoff]\\ninitial_interval_sec = 15\\nmultiplier = 2.0\\nrandomization_factor = 0.05\\nmax_elapsed_time_sec = 120\\n```', '- **`git.auto_commit_disabled`**: Opt-out of automatic commits after each chat completion.\\n- **`tools`**: A list of tool names to enable or disable.\\n  Example:\\n\\n```toml\\n[tools]\\nshell_command = false\\nsearch_code = true\\n```\\n\\nPossible values: `\"shell_command\"`, `\"read_file\"`,\\n`\"read_file_with_line_numbers\"`, `\"write_file\"`, `\"search_file\"`, `\"git\"`,\\n`\"reset_file\"`, `\"search_code\"`, `\"explain_code\"`,\\n`\"create_or_update_pull_request\"`, `\"run_tests\"`, `\"run_coverage\"`,\\n`\"search_web\"`, `\"github_search_code\"`, `\"fetch_url\"`, `\"add_lines\"`,\\n`\"replace_lines\"`\\n\\n- **`ui.hide_header`**: Optionally hide the top header in the UI. Defaults to `false`.\\n- **`num_completions_for_summary`**: Number of completions before the agent summarizes the conversation. Defaults to 10;\\n- **`git.agent_user_name`**: Name which the kwaak agent will make commands with.\\n  Defaults to \"kwaak\"`\\n- **`git.agent_user_email`**: Email which the kwaak agent will make commits\\n  with. Defaults to \"kwaak@bosun.ai\"\\n\\n<!-- ROADMAP -->', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '\\n\\n    /// Optional: Use github for code search, creating pull requests, and automatic pushing to\\n    /// remotes\\n    #[serde(default)]\\n    pub github_api_key: Option<ApiKey>,\\n\\n    /// Required if using `OpenAI`\\n    #[serde(default)]\\n    pub openai_api_key: Option<ApiKey>,\\n\\n    /// Required if using \\'Anthropic\\'\\n    #[serde(default)]\\n    pub anthropic_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Open Router`\\n    #[serde(default)]\\n    pub open_router_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Azure OpenAI`\\n    #[serde(default)]\\n    pub azure_openai_api_key: Option<ApiKey>,\\n\\n    #[serde(default)]\\n    pub tool_executor: SupportedToolExecutors,\\n\\n    /// A list of tool name and whether it is enabled or disabled\\n    ///\\n    /// This allows the user to disable tools that are not needed for their workflow. Or enable\\n    /// tools that are disabled by default\\n    #[serde(default)]\\n    pub tools: Tools,\\n\\n    /// By default the agent stops if the last message was its own and there are no new\\n    /// completions.\\n    ///\\n    /// When endless mode is enabled, the agent will keep running until it either cannot complete,\\n    /// did complete or was manually stopped.\\n    ///\\n    /// In addition, the agent is instructed that it cannot ask for feedback, but should try to\\n    /// complete its task instead.\\n    ///\\n    /// When running without a TUI, the agent will always run in endless mode.\\n    ///\\n    /// WARN: There currently is _no_ limit for endless mode\\n    #[serde(default)]\\n    pub endless_mode: bool,\\n\\n    /// OpenTelemetry tracing feature toggle\\n    #[serde(default = \"default_otel_enabled\")]\\n    pub otel_enabled: bool,\\n\\n    /// How the agent will edit files, defaults to whole\\n    #[serde(default)]\\n    pub agent_edit_mode: AgentEditMode,\\n\\n    /// Additional constraints / instructions for the agent\\n    ///\\n    /// These are passes to the agent in the system prompt and are rendered in a list. If you\\n    /// intend to use more complicated instructions, consider adding a file to read in the\\n', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;']",
         "To configure a session in a file such that users can add their own custom agents in Kwaak, follow this detailed step-by-step plan based on the given context:\n\n1. **Understanding the Session Concept**: \n   - Sessions in Kwaak are used to represent an ongoing agent interaction. They are more general than a simple chat and may be utilized for non-chat interactions in the future (Reference: _ARCHITECTURE.md_).\n\n2. **Configure Session Lifecycle**:\n   - When a session is created via a new chat or agent, a Docker container is initialized, the environment is configured, and an agent is started (Reference: _ARCHITECTURE.md_).\n\n3. **Use `kwaak.toml` for Configuration**:\n   - Create a `kwaak.toml` file which will include the session configurations. This configuration file is pivotal to adjusting agent settings and tool configurations (Reference: _README.md_).\n\n4. **Session Configuration Parameters**:\n   - Make sure to include necessary configurations in the `kwaak.toml` file. These configurations include, but are not limited to:\n     - `SupportedAgentConfigurations` for defining agent architectures (e.g., `Coding`, `PlanAct`).\n     - Tool executors configurations such as `Docker` or `Local`.\n\n5. **Custom Agent Definitions**:\n   - Users can create custom agents by defining them in the `kwaak.toml` configuration file. Support for custom tools can also be configured here.\n   - Example from the context suggests the use of agent constraints, tool lists, and edit modes to customize agent behavior (`config.rs`).\n\n6. **Onboarding and Setup**:\n   - Utilize Kwaak’s onboarding module to guide users through setting up their configurations with the configuration file being generated during this process. This accommodates user-specific setups (Reference: _onboarding/mod.rs_).\n\n7. **Use Environment Variables for Customization**:\n   - Provide flexibility for users to override configurations via environment variables. This helps accommodate different setups for diverse contributor environments (Reference: _README.md_).\n\n8. **Testing and Validating Configurations**:\n   - Use Docker to manage test environments and validate the agent setups to ensure they perform as intended (Reference: _benchmarks/swe/README.md_).\n\nBy following these steps, you can configure sessions in a file, allowing users to add their custom agents. The core idea rests on leveraging `kwaak.toml` for flexible and customizable agent configurations as well as providing an onboarding flow to support end-user interaction with the configuration process. \n\nIf you need more detailed steps for specific configurations, please consult the full documentation or context for additional guidance.",
         "I'd like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan."
        ],
        [
         "3",
         "The provided context does not contain sufficient information to fully explain how channels work within the app from a user's perspective. It mentions that commands include a \"channel to feed back responses\" into, but it does not elaborate further on how these channels interact, relate, or are utilized from a user's perspective. Additionally, there is no detailed description or explanation about user interaction with these channels within the retrieved content. Therefore, the question cannot be answered based on the current context. \n\nIf further details are needed, exploring the files or code sections mentioning \"channels\" specifically within the `commands` or `frontend` modules might be a good starting point, as these modules seem to deal with command patterns and user interaction.",
         "['# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', 'pub struct App<\\'a> {\\n    pub splash: splash::Splash<\\'a>,\\n    pub has_indexed_on_boot: bool,\\n    // /// The chat input\\n    // pub input: String,\\n    pub text_input: TextArea<\\'a>,\\n\\n    /// All known chats\\n    pub chats: Vec<Chat>,\\n\\n    /// UUID of the current chat\\n    pub current_chat_uuid: uuid::Uuid,\\n\\n    /// Holds the sender of UI events for later cloning if needed\\n    pub ui_tx: mpsc::UnboundedSender<UIEvent>,\\n\\n    /// Receives UI events (key presses, commands, etc)\\n    pub ui_rx: mpsc::UnboundedReceiver<UIEvent>,\\n\\n    /// Sends commands to the backend\\n    pub command_tx: Option<mpsc::UnboundedSender<CommandEvent>>,\\n\\n    /// Responds to commands from the backend\\n    /// And maps them to ui events\\n    pub command_responder: AppCommandResponder,\\n\\n    /// Mode the app is in, manages the which layout is rendered and if it should quit\\n    pub mode: AppMode,\\n\\n    /// Tracks the current selected state in the UI\\n    pub chats_state: ListState,\\n\\n    /// Tab names\\n    pub tab_names: Vec<&\\'static str>,\\n\\n    /// Index of selected tab\\n    pub selected_tab: usize,\\n\\n    /// States when viewing logs\\n    pub log_state: TuiWidgetState,\\n\\n    /// Commands that relate to boot, and not a chat\\n    pub boot_uuid: Uuid,\\n\\n    /// Skip indexing on boot\\n    pub skip_indexing: bool,\\n\\n    /// Override the working directory if it is not \".\"\\n    pub workdir: PathBuf,\\n\\n    /// Hack to get line wrapping on input into the textarea\\n    pub input_width: Option<u16>,\\n\\n    /// Max lines we can render in the chat messages\\n    pub chat_messages_max_lines: u16,\\n\\n    /// User configuration for the UI\\n    pub ui_config: UIConfig,\\n\\n    /// Informs the user if there is an update available\\n    pub update_available: Option<update_informer::Version>,\\n}\\n\\n#[derive(Debug, Clone, Copy, Default, PartialEq)]\\npub enum AppMode {\\n    #[default]\\n    Chat,\\n    Logs,\\n    Quit,\\n}', 'use std::collections::HashSet;\\n\\nuse ratatui::widgets::ScrollbarState;\\n\\nuse crate::{chat_message::ChatMessage, repository::Repository};\\n\\n#[derive(Debug, Clone)]\\npub struct Chat {\\n    /// Display name of the chat\\n    pub name: String,\\n    /// Identifier used to match responses\\n    pub uuid: uuid::Uuid,\\n    pub branch_name: Option<String>,\\n    pub messages: Vec<ChatMessage>,\\n    pub state: ChatState,\\n    pub new_message_count: usize,\\n    pub completed_tool_call_ids: HashSet<String>,\\n\\n    // Scrolling is per chat\\n    // but handled in the ui\\n    pub vertical_scroll_state: ScrollbarState,\\n    pub vertical_scroll: usize,\\n    pub num_lines: usize,\\n\\n    // Whether to auto-tail the chat on new messages\\n    pub auto_tail: bool,\\n\\n    pub repository: Option<Repository>,\\n}\\n\\nimpl Chat {\\n    pub fn add_message(&mut self, message: ChatMessage) {\\n        if !message.role().is_user() {\\n            self.new_message_count += 1;\\n        }\\n\\n        // If it\\'s a completed tool call, just register it is done and do not add the message\\n        // The state is updated when rendering on the initial tool call\\n        if message.role().is_tool() {\\n            let Some(tool_call) = message.maybe_completed_tool_call() else {\\n                tracing::error!(\\n                    \"Received a tool message without a tool call ID: {:?}\",\\n                    message\\n                );\\n                return;\\n            };\\n\\n            self.completed_tool_call_ids\\n                .insert(tool_call.id().to_string());\\n\\n            return;\\n        }\\n        self.messages.push(message);\\n    }\\n\\n    pub fn transition(&mut self, state: ChatState) {\\n        self.state = state;\\n    }\\n\\n    #[must_use]\\n    pub fn is_loading(&self) -> bool {\\n        matches!(\\n            self.state,\\n            ChatState::Loading | ChatState::LoadingWithMessage(_)\\n        )\\n    }\\n\\n    #[must_use]\\n    pub fn is_tool_call_completed(&self, tool_call_id: &str) -> bool {\\n        self.completed_tool_call_ids.contains(tool_call_id)\\n    }\\n}', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', 'mod chat_list_widget;\\nmod chat_messages_widget;\\nmod help_section_widget;\\nmod input_bar_widget;\\nmod message_formatting;\\nmod on_key;\\nmod ui;\\n\\npub use on_key::on_key;\\npub use ui::ui;', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '**Q:** I get a redb/duckdb error when starting, what is up?\\n\\n**A**: Possibly your index got corrupted, or you have another kwaak instance running on the same project. Try clearing the index with `kwaak clear-index` and restart kwaak. Note that this will require a reindexing of your codebase.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', 'use kwaak::commands::Command;\\nuse kwaak::frontend::{ui, UIEvent, UserInputCommand};\\nuse kwaak::test_utils::{setup_integration, IntegrationContext};\\nuse kwaak::{assert_agent_responded, assert_command_done};\\n\\n#[test_log::test(tokio::test(flavor = \"multi_thread\"))]\\nasync fn retry_chat() {\\n    let IntegrationContext {\\n        mut app,\\n        uuid,\\n        mut terminal,\\n\\n        handler_guard,\\n        repository_guard: _repository_guard,\\n        ..\\n    } = setup_integration().await.unwrap();\\n\\n    // First, let\\'s start a noop agent so an environment is running\\n    app.dispatch_command(\\n        uuid,\\n        Command::Chat {\\n            message: \"hello\".to_string(),\\n        },\\n    );\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"before_retry\", terminal.backend());\\n\\n    // Let\\'s retry the chat\\n    app.send_ui_event(UIEvent::UserInputCommand(uuid, UserInputCommand::Retry));\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    // It should now show 2 messages\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"after_retry\", terminal.backend());\\n\\n    // Force dropping it, for some reason it\\'s not being dropped\\n    drop(handler_guard);\\n}', '[Crate]: https://crates.io/crates/kwaak\\n[Docs Badge]: https://img.shields.io/docsrs/kwaak?logo=rust&style=flat-square&logoColor=E05D44', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\"]",
         "The provided context does not contain sufficient information to fully explain how channels work within the app from a user's perspective. It mentions that commands include a \"channel to feed back responses\" into, but it does not elaborate further on how these channels interact, relate, or are utilized from a user's perspective. Additionally, there is no detailed description or explanation about user interaction with these channels within the retrieved content. Therefore, the question cannot be answered based on the current context. \n\nIf further details are needed, exploring the files or code sections mentioning \"channels\" specifically within the `commands` or `frontend` modules might be a good starting point, as these modules seem to deal with command patterns and user interaction.",
         "There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective."
        ],
        [
         "4",
         "The provided context does not contain specific instructions on how to add a tool for an agent in Kwaak. However, the context does provide some relevant information about existing tools and how they might be structured.\n\nFor example, Kwaak's tools are implemented using traits such as `Tool` from the `swiftide` library, and typically involve defining specific functionalities and parameters as shown in the `DelegateAgent` and `RunTests` implementations.\n\nHere are some details you might consider when adding a new tool based on the context:\n\n1. **Define Tool Struct**: Create a new struct for your tool, implementing necessary fields and methods. Reference existing tools like `DelegateAgent` and `RunTests` as examples.\n\n2. **Implement the Tool Trait**: Use the `Tool` trait to define the behavior of your tool, including how it should be invoked and what parameters it expects.\n\n3. **Provide Description**: Ensure that your tool has a clear description and parameter annotations, as shown in the snippets, to help users understand the tool's purpose and usage.\n\n4. **Use Context**: Make use of the `AgentContext` to interact with the current session or execution environment.\n\n5. **Command Execution**: If your tool requires executing commands (like running tests or shell commands), see how commands are handled and executed in existing tools (e.g., `RunTests`, `shell_command`).\n\nUnfortunately, further specific steps or files required to add a tool aren't available in the context. You might find more concrete guidance in the source code files and the tool trait implementations like those mentioned above.",
         "['//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '{{description}}\\n\\n---\\n\\n_This pull request was created by [kwaak](https://github.com/bosun-ai/kwaak), a free, open-source, autonomous coding agent tool. Pull requests are tracked in bosun-ai/kwaak#48_\\n\\n{% if messages | length > 0 -%}\\n<details>\\n<summary>Message History</summary>\\n\\n{% for message in messages -%}\\n<details>\\n  <summary>{{message.role}}</summary>\\n\\n```markdown\\n{{message.content}}\\n```\\n</details>\\n{% if message.role is containing(\"Assistant\") -%}', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', ' Agent::builder()\\n        .context(Arc::clone(&context) as Arc<dyn AgentContext>)\\n        .system_prompt(system_prompt)\\n        .tools(tools.to_vec())\\n        .before_all(move |agent| {\\n            let initial_context = initial_context.clone();\\n\\n            Box::pin(async move {\\n                agent.context()\\n                    .add_message(chat_completion::ChatMessage::new_user(initial_context))\\n                    .await;\\n\\n                let top_level_project_overview = agent.context().exec_cmd(&Command::shell(\"fd -iH -d2 -E \\'.git/*\\'\")).await?.output;\\n                agent.context().add_message(chat_completion::ChatMessage::new_user(format!(\"The following is a max depth 2, high level overview of the directory structure of the project: \\\\n ```{top_level_project_overview}```\"))).await;\\n\\n                Ok(())\\n            })\\n        })\\n        .on_new_message(move |_, message| {\\n            let command_responder = tx_2.clone();\\n            let message = message.clone();\\n\\n            Box::pin(async move {\\n                command_responder.agent_message(message);\\n\\n                Ok(())\\n            })\\n        })\\n        .before_completion(move |_, _| {\\n            let command_responder = tx_3.clone();\\n            Box::pin(async move {\\n                command_responder.update(\"running completions\");\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let command_responder = tx_4.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                command_responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .after_tool(tool_summarizer.summarize_hook())\\n        .after_each', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', '\\n#[tool(\\n    description = \"Reads file content, including line numbers. You MUST use this tool to retrieve line numbers before making an edit with edit_file\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file_with_line_numbers(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    let lines = output\\n        .output\\n        .lines()\\n        .enumerate()\\n        .map(|(i, l)| format!(\"{line_num}|{l}\", line_num = i + 1));\\n\\n    Ok(lines.collect::<Vec<_>>().join(\"\\\\n\").into())\\n}\\n\\n#[tool(\\n    description = \"Write to a file. You MUST ALWAYS include the full file content, including what you did not change, as it overwrites the full file. Only make changes that pertain to your task.\",\\n    param(name = \"file_name\", description = \"Full path of the file\"),\\n    param(name = \"content\", description = \"FULL Content to write to the file\")\\n)]\\npub async fn write_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n    content: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::WriteFile(file_name.into(), content.into());\\n\\n    context.exec_cmd(&cmd).await?;\\n\\n    let success_message = format!(\"File written successfully to {file_name}\");\\n\\n    Ok(success_message.into())\\n}\\n\\n#[tool(\\n    description = \"Searches for a file inside the current project, leave the argument empty to list all files. Uses `find`.\",\\n    param(name = \"file_name\", description = \"Partial or full name of the file\")\\n)]\\npub async fn search_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::Shell(format!(\"fd -E \\'.git/*\\' -iH --full-path \\'{file_name}\\'\"));\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', 'mod delegate_agent;\\nmod replace_lines;\\n\\npub use delegate_agent::DelegateAgent;\\npub use replace_lines::replace_lines;\\n\\nuse std::sync::Arc;\\nuse swiftide::traits::CommandError;\\n\\nuse anyhow::{Context as _, Result};\\nuse swiftide::{\\n    chat_completion::{errors::ToolError, ToolOutput},\\n    query::{search_strategies, states},\\n    traits::{AgentContext, Command},\\n};\\nuse swiftide_macros::{tool, Tool};\\nuse tavily::Tavily;\\nuse tokio::sync::Mutex;\\n\\nuse crate::{\\n    config::ApiKey,\\n    git::github::GithubSession,\\n    templates::Templates,\\n    util::{self, accept_non_zero_exit},\\n};\\n\\n#[allow(dead_code)]\\nstatic MAIN_BRANCH_CMD: &str = \"git remote show origin | sed -n \\'/HEAD branch/s/.*: //p\\'\";\\n\\n/// WARN: Experimental\\n#[tool(\\n    description = \"Run any shell command in the current project, use this if other tools are not enough.\",\\n    param(\\n        name = \"cmd\",\\n        description = \"The shell command, including any arguments if needed, to run\"\\n    )\\n)]\\npub async fn shell_command(context: &dyn AgentContext, cmd: &str) -> Result<ToolOutput, ToolError> {\\n    if util::is_git_branch_change(cmd) {\\n        return Ok(\\n            \"You cannot change branches, you are already on a branch created specifically for you.\"\\n                .into(),\\n        );\\n    }\\n    let output = accept_non_zero_exit(context.exec_cmd(&Command::Shell(cmd.into())).await)?;\\n    Ok(output.into())\\n}\\n\\n#[tool(\\n    description = \"Reads file content\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}\\n\\n// TODO: Better to have a single read_file tool with an optional line number flag', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions']",
         "The provided context does not contain specific instructions on how to add a tool for an agent in Kwaak. However, the context does provide some relevant information about existing tools and how they might be structured.\n\nFor example, Kwaak's tools are implemented using traits such as `Tool` from the `swiftide` library, and typically involve defining specific functionalities and parameters as shown in the `DelegateAgent` and `RunTests` implementations.\n\nHere are some details you might consider when adding a new tool based on the context:\n\n1. **Define Tool Struct**: Create a new struct for your tool, implementing necessary fields and methods. Reference existing tools like `DelegateAgent` and `RunTests` as examples.\n\n2. **Implement the Tool Trait**: Use the `Tool` trait to define the behavior of your tool, including how it should be invoked and what parameters it expects.\n\n3. **Provide Description**: Ensure that your tool has a clear description and parameter annotations, as shown in the snippets, to help users understand the tool's purpose and usage.\n\n4. **Use Context**: Make use of the `AgentContext` to interact with the current session or execution environment.\n\n5. **Command Execution**: If your tool requires executing commands (like running tests or shell commands), see how commands are handled and executed in existing tools (e.g., `RunTests`, `shell_command`).\n\nUnfortunately, further specific steps or files required to add a tool aren't available in the context. You might find more concrete guidance in the source code files and the tool trait implementations like those mentioned above.",
         "How can I add a tool for an agent?"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The context provided does not offer detailed i...</td>\n",
       "      <td>[Kwaak is free and open-source. You can bring ...</td>\n",
       "      <td>The context provided does not offer detailed i...</td>\n",
       "      <td>Explain kwaak works and explain the architectu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The provided context does not specifically exp...</td>\n",
       "      <td>[## How is Kwaak different from other tools?\\n...</td>\n",
       "      <td>The provided context does not specifically exp...</td>\n",
       "      <td>How are tools used by an agent?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To configure a session in a file such that use...</td>\n",
       "      <td>[### Session Management\\n\\nKwaak supports runn...</td>\n",
       "      <td>To configure a session in a file such that use...</td>\n",
       "      <td>I'd like to be able to configure a session in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The provided context does not contain sufficie...</td>\n",
       "      <td>[# Architecture\\n\\nKwaak has a lightweight, ra...</td>\n",
       "      <td>The provided context does not contain sufficie...</td>\n",
       "      <td>There are multiple uses of channels in the app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>[//! Agents defines various agents that can be...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>How can I add a tool for an agent?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  The context provided does not offer detailed i...   \n",
       "1  The provided context does not specifically exp...   \n",
       "2  To configure a session in a file such that use...   \n",
       "3  The provided context does not contain sufficie...   \n",
       "4  The provided context does not contain specific...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Kwaak is free and open-source. You can bring ...   \n",
       "1  [## How is Kwaak different from other tools?\\n...   \n",
       "2  [### Session Management\\n\\nKwaak supports runn...   \n",
       "3  [# Architecture\\n\\nKwaak has a lightweight, ra...   \n",
       "4  [//! Agents defines various agents that can be...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The context provided does not offer detailed i...   \n",
       "1  The provided context does not specifically exp...   \n",
       "2  To configure a session in a file such that use...   \n",
       "3  The provided context does not contain sufficie...   \n",
       "4  The provided context does not contain specific...   \n",
       "\n",
       "                                            question  \n",
       "0  Explain kwaak works and explain the architectu...  \n",
       "1                    How are tools used by an agent?  \n",
       "2  I'd like to be able to configure a session in ...  \n",
       "3  There are multiple uses of channels in the app...  \n",
       "4                 How can I add a tool for an agent?  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature evaluation\n",
    "\n",
    "We use Rust features to evaluate combinations of features to evaluate the result. This is straightforward and allows checking individual and combinations of multiple features quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "features = [\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'default',\n",
       "  'features': ['default'],\n",
       "  'output_file': 'evals/ragas/default.json'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "# Wtf python, why is this not built in?\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) → () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "# Now we prep an easy to use list of dicts with the { name, features, output_file }\n",
    "evals = []\n",
    "for i, combination in enumerate(list(powerset(features))):\n",
    "    if len(combination) == 0:\n",
    "        continue\n",
    "    evals.append({  \"name\": \"_\".join(combination),\n",
    "                    \"features\": list(combination),\n",
    "                    \"output_file\": f\"evals/ragas/{'_'.join(combination)}.json\"})\n",
    "    \n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d428f4fa6374405a8a7a5d0104322494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Running evaluation: default, input from evals/ragas/base.json outputting to evals/ragas/default.j…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RUST_LOG=debug cargo run --features=evaluations,default --  --allow-dirty '\n",
      " 'eval ragas -i evals/ragas/base.json --output=evals/ragas/default.json')\n",
      "['\\x1b[0m\\x1b[1m\\x1b[33mwarning\\x1b[0m\\x1b[0m\\x1b[1m: unused import: `ValueEnum`\\x1b[0m', '\\x1b[0m \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[38;5;12m--> \\x1b[0m\\x1b[0msrc/cli.rs:3:32\\x1b[0m', '\\x1b[0m  \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[38;5;12m|\\x1b[0m', '\\x1b[0m\\x1b[1m\\x1b[38;5;12m3\\x1b[0m\\x1b[0m \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[38;5;12m|\\x1b[0m\\x1b[0m \\x1b[0m\\x1b[0muse clap::{Parser, Subcommand, ValueEnum};\\x1b[0m', '\\x1b[0m  \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[38;5;12m|\\x1b[0m\\x1b[0m                                \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[33m^^^^^^^^^\\x1b[0m', '\\x1b[0m  \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[38;5;12m|\\x1b[0m', '\\x1b[0m  \\x1b[0m\\x1b[0m\\x1b[1m\\x1b[38;5;12m= \\x1b[0m\\x1b[0m\\x1b[1mnote\\x1b[0m\\x1b[0m: `#[warn(unused_imports)]` on by default\\x1b[0m', '', '\\x1b[1m\\x1b[33mwarning\\x1b[0m\\x1b[1m:\\x1b[0m `kwaak` (lib) generated 1 warning (run `cargo fix --lib -p kwaak` to apply 1 suggestion)', '\\x1b[1m\\x1b[32m    Finished\\x1b[0m `dev` profile [unoptimized + debuginfo] target(s) in 0.61s', '\\x1b[1m\\x1b[32m     Running\\x1b[0m `target/debug/kwaak --allow-dirty eval ragas -i evals/ragas/base.json --output=evals/ragas/default.json`', 'OpenTelemetry tracing enabled', 'Reading dataset from file: evals/ragas/base.json']\n"
     ]
    }
   ],
   "source": [
    "# Now for each eval, we will run kwaak with the given features, with the base.json as input, and output to the output file\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "base_file  = \"evals/ragas/base.json\"\n",
    "\n",
    "for eval in evals:\n",
    "    display(widgets.Label(f\"Running evaluation: {eval['name']}, input from {base_file} outputting to {eval['output_file']}\"))\n",
    "    features = \",\".join(eval[\"features\"])\n",
    "    output_file = eval[\"output_file\"]\n",
    "    cmd = f\"RUST_LOG=debug cargo run --features=evaluations,{features} --  --allow-dirty eval ragas -i {base_file} --output={output_file}\"\n",
    "    pprint(cmd)\n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "features",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "95dab472-1792-487d-9803-2ebd5c16000a",
       "rows": [
        [
         "0",
         "The provided context does not contain specific instructions or steps on how to add a tool for an agent in the Kwaak system. The context mentions tools in several different snippets, such as in the code example of `DelegateAgent` in `delegate_agent.rs`, which is a tool that delegates a task to an agent, and in `tool_evaluation_agent.rs`, where tools are part of an agent's functionalities. However, there are no explicit instructions on how to add a new tool.\n\nHere are some leads from the context that could guide further exploration:\n\n1. **Tool Interface and Implementation**: Snippets from files like `delegate_agent.rs` and `tool_evaluation_agent.rs` describe tools that appear to implement the `Tool` trait from `swiftide::chat_completion`. Implementing this trait might be a necessary step in creating a new tool.\n\n2. **Tool Registration**: In `tool_evaluation_agent.rs`, tools seem to be passed into an `Agent::builder()` via a `tools` parameter, indicating a possible mechanism for associating tools with agents.\n\n3. **Agent Configuration**: Since agents and their configurations might be part of the `Session` and `RunningAgent` structures mentioned in the context, looking into how configurations are specified in these entities might provide insights.\n\n4. **Documentation**: The configuration section of the README mentions various aspects like command configuration and agent configuration, which might hold relevant details on adding new functionalities or tools.\n\nIf more detailed information is needed, reviewing the source code and documentation related to these components would be necessary, especially around where tools are defined and associated with agents in the Kwaak framework.",
         "['Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '{{description}}\\n\\n---\\n\\n_This pull request was created by [kwaak](https://github.com/bosun-ai/kwaak), a free, open-source, autonomous coding agent tool. Pull requests are tracked in bosun-ai/kwaak#48_\\n\\n{% if messages | length > 0 -%}\\n<details>\\n<summary>Message History</summary>\\n\\n{% for message in messages -%}\\n<details>\\n  <summary>{{message.role}}</summary>\\n\\n```markdown\\n{{message.content}}\\n```\\n</details>\\n{% if message.role is containing(\"Assistant\") -%}', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '# Kwaak SWE-Bench Runner\\n\\nA Python package for running and evaluating the Kwaak agent against the SWE-bench dataset, a benchmark for evaluating LLMs on real-world software engineering tasks.', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.']",
         "The provided context does not contain specific instructions on how to add a tool for an agent in Kwaak. However, the context does provide some relevant information about existing tools and how they might be structured.\n\nFor example, Kwaak's tools are implemented using traits such as `Tool` from the `swiftide` library, and typically involve defining specific functionalities and parameters as shown in the `DelegateAgent` and `RunTests` implementations.\n\nHere are some details you might consider when adding a new tool based on the context:\n\n1. **Define Tool Struct**: Create a new struct for your tool, implementing necessary fields and methods. Reference existing tools like `DelegateAgent` and `RunTests` as examples.\n\n2. **Implement the Tool Trait**: Use the `Tool` trait to define the behavior of your tool, including how it should be invoked and what parameters it expects.\n\n3. **Provide Description**: Ensure that your tool has a clear description and parameter annotations, as shown in the snippets, to help users understand the tool's purpose and usage.\n\n4. **Use Context**: Make use of the `AgentContext` to interact with the current session or execution environment.\n\n5. **Command Execution**: If your tool requires executing commands (like running tests or shell commands), see how commands are handled and executed in existing tools (e.g., `RunTests`, `shell_command`).\n\nUnfortunately, further specific steps or files required to add a tool aren't available in the context. You might find more concrete guidance in the source code files and the tool trait implementations like those mentioned above.",
         "How can I add a tool for an agent?",
         "default"
        ],
        [
         "1",
         "The tools used by an agent in the context provided are integrated into several processes. Here’s how they are generally applied:\n\n1. **Agent Integration**: Tools are part of an agent's toolset, used during sessions to execute specific tasks. Each agent can use various tools depending on the session configuration (Reference: `./src/agent/agents/mod.rs`).\n\n2. **Execution in a Sandbox**: Agents leverage Docker containers to provide a safe execution environment for running the code. This ensures that agents can perform tasks without affecting the local system (Reference: `README.md`).\n\n3. **Example of Tool Invocation**: A tool like `DelegateAgent` takes tasks and delegates them to an agent within a session, utilizing the agent to query and perform tasks (Reference: `./src/agent/tools/delegate_agent.rs`).\n\n4. **Tool Evaluation**: Tools are also used for testing and evaluation purposes within controlled environments, such as managing isolated test environments using Docker (Reference: `./benchmarks/swe/README.md`).\n\n5. **Integration via Code Execution**: Tools can execute commands directly. For example, the `RunTests` and `RunCoverage` tools run shell commands to execute testing and coverage analysis (Reference: `./src/agent/tools/mod.rs`).\n\n6. **Feedback and Updates**: When a tool is invoked, feedback mechanisms are employed. Tools are used before and after their execution to provide updates and results (Reference: `./src/evaluations/tool_evaluation_agent.rs`).\n\nIn summary, tools in Kwaak are utilized to execute tasks, manage code safely, delegate operations to agents, perform evaluations, and provide real-time feedback within the sandboxed Docker environments.",
         "['## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '\\n\\n    if let Err(error) = app_result {\\n        ::tracing::error!(?error, \"Kwaak encountered an error\\\\n {error:#}\");\\n        eprintln!(\"Kwaak encountered an error\\\\n {error}\");\\n        std::process::exit(1);\\n    }\\n\\n    Ok(())\\n}\\n\\nasync fn test_tool(\\n    repository: &repository::Repository,\\n    tool_name: &str,\\n    tool_args: Option<&str>,\\n) -> Result<()> {\\n    let github_session = Arc::new(GithubSession::from_repository(&repository)?);\\n    let tool = available_tools(repository, Some(&github_session), None)?\\n        .into_iter()\\n        .find(|tool| tool.name() == tool_name)\\n        .context(\"Tool not found\")?;\\n\\n    let mut executor = DockerExecutor::default();\\n    let dockerfile = &repository.config().docker.dockerfile;\\n\\n    println!(\\n        \"Starting executor with dockerfile: {}\",\\n        dockerfile.display()\\n    );\\n    let running_executor = executor\\n        .with_context_path(&repository.config().docker.context)\\n        .with_image_name(repository.config().project_name.to_lowercase())\\n        .with_dockerfile(dockerfile)\\n        .to_owned()\\n        .start()\\n        .await?;\\n\\n    let agent_context = DefaultContext::from_executor(running_executor);\\n\\n    println!(\"Invoking tool: {tool_name}\");\\n    let output = tool\\n        .invoke(&agent_context as &dyn AgentContext, tool_args)\\n        .await?;\\n\\n    println!(\"{output}\");\\n\\n    Ok(())\\n}\\n\\n#[instrument(skip_all)]', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', 'mod delegate_agent;\\nmod replace_lines;\\n\\npub use delegate_agent::DelegateAgent;\\npub use replace_lines::replace_lines;\\n\\nuse std::sync::Arc;\\nuse swiftide::traits::CommandError;\\n\\nuse anyhow::{Context as _, Result};\\nuse swiftide::{\\n    chat_completion::{errors::ToolError, ToolOutput},\\n    query::{search_strategies, states},\\n    traits::{AgentContext, Command},\\n};\\nuse swiftide_macros::{tool, Tool};\\nuse tavily::Tavily;\\nuse tokio::sync::Mutex;\\n\\nuse crate::{\\n    config::ApiKey,\\n    git::github::GithubSession,\\n    templates::Templates,\\n    util::{self, accept_non_zero_exit},\\n};\\n\\n#[allow(dead_code)]\\nstatic MAIN_BRANCH_CMD: &str = \"git remote show origin | sed -n \\'/HEAD branch/s/.*: //p\\'\";\\n\\n/// WARN: Experimental\\n#[tool(\\n    description = \"Run any shell command in the current project, use this if other tools are not enough.\",\\n    param(\\n        name = \"cmd\",\\n        description = \"The shell command, including any arguments if needed, to run\"\\n    )\\n)]\\npub async fn shell_command(context: &dyn AgentContext, cmd: &str) -> Result<ToolOutput, ToolError> {\\n    if util::is_git_branch_change(cmd) {\\n        return Ok(\\n            \"You cannot change branches, you are already on a branch created specifically for you.\"\\n                .into(),\\n        );\\n    }\\n    let output = accept_non_zero_exit(context.exec_cmd(&Command::Shell(cmd.into())).await)?;\\n    Ok(output.into())\\n}\\n\\n#[tool(\\n    description = \"Reads file content\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}\\n\\n// TODO: Better to have a single read_file tool with an optional line number flag', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '## Additional information\\n\\nThis context is provided for an ai agent that has to accomplish the above. Additionally, the agent has access to the following tools:\\n{{available_tools}}', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '# Kwaak SWE-Bench Runner\\n\\nA Python package for running and evaluating the Kwaak agent against the SWE-bench dataset, a benchmark for evaluating LLMs on real-world software engineering tasks.', ' Agent::builder()\\n        .context(Arc::clone(&context) as Arc<dyn AgentContext>)\\n        .system_prompt(system_prompt)\\n        .tools(tools.to_vec())\\n        .before_all(move |agent| {\\n            let initial_context = initial_context.clone();\\n\\n            Box::pin(async move {\\n                agent.context()\\n                    .add_message(chat_completion::ChatMessage::new_user(initial_context))\\n                    .await;\\n\\n                let top_level_project_overview = agent.context().exec_cmd(&Command::shell(\"fd -iH -d2 -E \\'.git/*\\'\")).await?.output;\\n                agent.context().add_message(chat_completion::ChatMessage::new_user(format!(\"The following is a max depth 2, high level overview of the directory structure of the project: \\\\n ```{top_level_project_overview}```\"))).await;\\n\\n                Ok(())\\n            })\\n        })\\n        .on_new_message(move |_, message| {\\n            let command_responder = tx_2.clone();\\n            let message = message.clone();\\n\\n            Box::pin(async move {\\n                command_responder.agent_message(message);\\n\\n                Ok(())\\n            })\\n        })\\n        .before_completion(move |_, _| {\\n            let command_responder = tx_3.clone();\\n            Box::pin(async move {\\n                command_responder.update(\"running completions\");\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let command_responder = tx_4.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                command_responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .after_tool(tool_summarizer.summarize_hook())\\n        .after_each']",
         "The provided context does not specifically explain how tools are used by an agent, in terms of their operational mechanism within a larger system. However, there is some information about the structure and functionality of tools in `Kwaak`.\n\n### Key Points from the Context:\n\n1. **Agent and Tools System**:\n   - Agents in Kwaak can operate a number of tools that help them execute tasks. The context refers to various tools such as those for running tests, checking code coverage, and interacting with shell commands. ([source code](./src/agent/tools/mod.rs), [README.md](./README.md))\n\n2. **Delegate Agent Tool**:\n   - Presents an example of how a tool is set up. The `DelegateAgent` tool delegates tasks to a particular agent. It uses an object called a `RunningAgent` that is assumed to be already configured ([source code](./src/agent/tools/delegate_agent.rs)).\n\n3. **Tool Configuration and Invocation**:\n   - Tools are configured and utilized within agents during certain tasks, e.g., running shell commands or reading files. Some parts of the code provide functionality for running commands with a sandboxed shell environment using Docker ([source code](./src/agent/tools/mod.rs)).\n\n4. **Initial Context and Configuration**:\n   - The system can utilize initial context and configuration to guide the tools. This context might describe how a project is set up or give an overview of the directory structure to help with the execution of tasks ([source code](./src/agent/agents/coding.rs)).\n\n5. **Session and Agent Management**:\n   - Session management indicates parallel operations with each session containing its own configuration of agents and tools ([ARCHITECTURE.md](./ARCHITECTURE.md)).\n\n### Leads for Further Information:\nThe retrieved context has snippets pointing toward various sections that could provide additional details, such as the specific role of each tool and how they are incorporated into an agent's workflow. These include files like `agents/mod.rs`, `session.rs`, and `agent/tools/mod.rs`.\n\nBecause the context does not fully explain the specifics of tool usage by agents, I recommend checking further documentation or additional sections of the source code not provided here for comprehensive understanding.",
         "How are tools used by an agent?",
         "default"
        ],
        [
         "2",
         "Based on the provided context, here is a step-by-step plan to configure a session in a file with the capability for users to add their own custom agents in Kwaak:\n\n1. **Initialize a Configuration File**:\n   - Run `kwaak init` in the project where you want to configure a session. This command will guide you through the process and help you create a basic configuration file named `kwaak.toml` ([source](./README.md)).\n\n2. **Customize the Configuration File**:\n   - Review and adjust the `kwaak.toml` file to suit your specific needs. You are encouraged to take a close look at this file since it contains various options that can be tailored for performance and accuracy of the agents ([source](./README.md)).\n\n3. **Agent Session Management**:\n   - Sessions represent ongoing agent interactions and are managed as separate entities, each having its own state and configuration. This means different configurations can be experimented with by adding new agents without impacting existing setups ([source](./ARCHITECTURE.md)).\n\n4. **Defining a New Agent**:\n   - Within the `kwaak.toml` file, customize session configurations. This includes specifying agent types and tools by overriding or adding new configurations. This structure allows for flexibility such as using different tools, docker configurations, or even defining custom constraints for agents ([source](./src/config/config.rs)).\n\n5. **Additional Configuration (Optional)**:\n   - If contributors have different setups, you may utilize environment variable overrides or create a `kwaak.local.toml` file and ignore it in `.gitignore` ([source](./README.md)).\n\n6. **Docker Setup**:\n   - Ensure you have a Dockerfile in your project root or specify an alternate path in the `kwaak.toml`. This Dockerfile should encapsulate all dependencies your custom agents will need ([source](./README.md)).\n\n7. **Testing and Iteration**:\n   - After setting up the configuration, test your setup by running `kwaak` and observe any changes or behaviors with the new session configurations.\n   - Iterate based on feedback or performance metrics to further refine your custom agent configurations.\n\nThis approach provides a structured method for configuring sessions and adding custom agents. If additional guidance is needed, such as enabling tools that are disabled by default or running the agent in endless mode, you can refer to the detailed configurations and options specified in the `kwaak.toml` documentation sections ([source](./src/config/config.rs)).",
         "['### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '    /// repository instead.\\n    #[serde(default)]\\n    pub agent_custom_constraints: Option<Vec<String>>,\\n\\n    #[serde(default)]\\n    pub ui: UIConfig,\\n\\n    /// Number of completions before the agent summarizes the conversation.\\n    /// This is used to steer the agent to focus on the current task. If this value is too small\\n    /// the agent will have clear loss of context when performing tasks. If this value is too large\\n    /// the agent will not have focus and not understand what is relevant and important.\\n    ///\\n    /// Additionally, summarizing the conversation will reduce the context window which can be\\n    /// beneficial for APIs with stringent limits on context tokens.\\n    ///\\n    /// Defaults to 10.\\n    #[serde(default = \"default_num_completions_for_summary\")]\\n    pub num_completions_for_summary: usize,\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(default)]\\npub struct UIConfig {\\n    pub hide_header: bool,\\n}\\n\\nfn default_otel_enabled() -> bool {\\n    false\\n}\\n\\nfn default_num_completions_for_summary() -> usize {\\n    10\\n}\\n\\n/// Agent session configurations supported by Kwaak\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\npub enum SupportedAgentConfigurations {\\n    /// Single looping agent that has all tools available\\n    #[default]\\n    #[serde(alias = \"V1\")]\\n    Coding,\\n    /// A two stage agent, starting with a planning agent that delegates to the coding\\n    /// agent\\n    PlanAct,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum SupportedToolExecutors {\\n    #[default]\\n    Docker,\\n    Local,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default, strum_macros::EnumIs)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum AgentEditMode {\\n    #[default]\\n    Whole,\\n    Line,\\n    // i.e. udiff, llm reviewed, etc\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize)]', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', \"### Configuration\\n\\nKwaak supports configuring different Large Language Models (LLMs) for distinct tasks like indexing, querying, and embedding to optimize performance and accuracy. Be sure to tailor the configurations to fit the scope and blend of the tasks you're tackling.\", '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '### Session Lifecycle\\n\\n1. **Creation**: When a user starts a new chat or creates a new agent, a new session is created with a unique UUID.\\n2. **Initialization**: The session sets up a Docker container, generates initial context using RAG, and configures the environment.\\n3. **Agent Execution**: The session starts an agent (e.g., coding agent or plan-and-act agent) which interacts with the LLM.\\n4. **Message Handling**: Sessions maintain communication channels for handling messages, including potential agent swaps.\\n5. **Termination**: When a chat is closed or when Kwaak exits, the associated session is stopped.', '\\n\\n    /// Optional: Use github for code search, creating pull requests, and automatic pushing to\\n    /// remotes\\n    #[serde(default)]\\n    pub github_api_key: Option<ApiKey>,\\n\\n    /// Required if using `OpenAI`\\n    #[serde(default)]\\n    pub openai_api_key: Option<ApiKey>,\\n\\n    /// Required if using \\'Anthropic\\'\\n    #[serde(default)]\\n    pub anthropic_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Open Router`\\n    #[serde(default)]\\n    pub open_router_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Azure OpenAI`\\n    #[serde(default)]\\n    pub azure_openai_api_key: Option<ApiKey>,\\n\\n    #[serde(default)]\\n    pub tool_executor: SupportedToolExecutors,\\n\\n    /// A list of tool name and whether it is enabled or disabled\\n    ///\\n    /// This allows the user to disable tools that are not needed for their workflow. Or enable\\n    /// tools that are disabled by default\\n    #[serde(default)]\\n    pub tools: Tools,\\n\\n    /// By default the agent stops if the last message was its own and there are no new\\n    /// completions.\\n    ///\\n    /// When endless mode is enabled, the agent will keep running until it either cannot complete,\\n    /// did complete or was manually stopped.\\n    ///\\n    /// In addition, the agent is instructed that it cannot ask for feedback, but should try to\\n    /// complete its task instead.\\n    ///\\n    /// When running without a TUI, the agent will always run in endless mode.\\n    ///\\n    /// WARN: There currently is _no_ limit for endless mode\\n    #[serde(default)]\\n    pub endless_mode: bool,\\n\\n    /// OpenTelemetry tracing feature toggle\\n    #[serde(default = \"default_otel_enabled\")]\\n    pub otel_enabled: bool,\\n\\n    /// How the agent will edit files, defaults to whole\\n    #[serde(default)]\\n    pub agent_edit_mode: AgentEditMode,\\n\\n    /// Additional constraints / instructions for the agent\\n    ///\\n    /// These are passes to the agent in the system prompt and are rendered in a list. If you\\n    /// intend to use more complicated instructions, consider adding a file to read in the\\n', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '\\n\\npub async fn run(file: Option<PathBuf>, dry_run: bool) -> Result<()> {\\n    let file = file.unwrap_or_else(|| PathBuf::from(\"kwaak.toml\"));\\n    if !dry_run {\\n        if std::fs::metadata(\".git\").is_err() {\\n            anyhow::bail!(\"Not a git repository, please run `git init` first\");\\n        }\\n        if std::fs::metadata(&file).is_ok() {\\n            anyhow::bail!(\\n                \"{} already exists in current directory, skipping initialization\",\\n                file.display()\\n            );\\n        }\\n    }\\n\\n    println!(\"Welcome to Kwaak! Let\\'s get started by initializing a new configuration file.\");\\n    println!(\"\\\\n\");\\n    println!(\\n        \"We have a few questions to ask you to get started, you can always change these later in the `{}` file.\",\\n        file.display()\\n    );\\n\\n    let mut context = tera::Context::new();\\n    project_questions(&mut context)?;\\n    git_questions(&mut context)?;\\n    llm_questions(&mut context).await?;\\n    command_questions(&mut context)?;\\n\\n    let config =\\n        Templates::render(\"kwaak.toml\", &context).context(\"Failed to render default config\")?;\\n\\n    // Ensure we panic during tests\\n    debug_assert!(\\n        toml::from_str::<crate::config::Config>(&config).is_ok(),\\n        \"Failed to parse the rendered config with error: {error:#}, config: \\\\n{config}\",\\n        error = toml::from_str::<crate::config::Config>(&config).unwrap_err()\\n    );\\n    toml::from_str::<crate::config::Config>(&config)\\n        .context(\"There is an error in the configuration\")?;\\n\\n    // Since we want the template annotated with comments, just return the template\\n    if dry_run {\\n        println!(\"\\\\nDry run, would have written the following to kwaak.toml:\\\\n\\\\n{config}\");\\n    } else {\\n        std::fs::write(&file, &config)?;\\n        println!(\\n            \"\\\\nInitialized kwaak project in current directory, please review and customize the created `{}` file.\\\\n Kwaak also needs a `Dockerfile` to execute your code in.\",\\n            file.display()\\n        );\\n    }\\n\\n    Ok(())\\n}', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)']",
         "To configure a session in a file such that users can add their own custom agents in Kwaak, follow this detailed step-by-step plan based on the given context:\n\n1. **Understanding the Session Concept**: \n   - Sessions in Kwaak are used to represent an ongoing agent interaction. They are more general than a simple chat and may be utilized for non-chat interactions in the future (Reference: _ARCHITECTURE.md_).\n\n2. **Configure Session Lifecycle**:\n   - When a session is created via a new chat or agent, a Docker container is initialized, the environment is configured, and an agent is started (Reference: _ARCHITECTURE.md_).\n\n3. **Use `kwaak.toml` for Configuration**:\n   - Create a `kwaak.toml` file which will include the session configurations. This configuration file is pivotal to adjusting agent settings and tool configurations (Reference: _README.md_).\n\n4. **Session Configuration Parameters**:\n   - Make sure to include necessary configurations in the `kwaak.toml` file. These configurations include, but are not limited to:\n     - `SupportedAgentConfigurations` for defining agent architectures (e.g., `Coding`, `PlanAct`).\n     - Tool executors configurations such as `Docker` or `Local`.\n\n5. **Custom Agent Definitions**:\n   - Users can create custom agents by defining them in the `kwaak.toml` configuration file. Support for custom tools can also be configured here.\n   - Example from the context suggests the use of agent constraints, tool lists, and edit modes to customize agent behavior (`config.rs`).\n\n6. **Onboarding and Setup**:\n   - Utilize Kwaak’s onboarding module to guide users through setting up their configurations with the configuration file being generated during this process. This accommodates user-specific setups (Reference: _onboarding/mod.rs_).\n\n7. **Use Environment Variables for Customization**:\n   - Provide flexibility for users to override configurations via environment variables. This helps accommodate different setups for diverse contributor environments (Reference: _README.md_).\n\n8. **Testing and Validating Configurations**:\n   - Use Docker to manage test environments and validate the agent setups to ensure they perform as intended (Reference: _benchmarks/swe/README.md_).\n\nBy following these steps, you can configure sessions in a file, allowing users to add their custom agents. The core idea rests on leveraging `kwaak.toml` for flexible and customizable agent configurations as well as providing an onboarding flow to support end-user interaction with the configuration process. \n\nIf you need more detailed steps for specific configurations, please consult the full documentation or context for additional guidance.",
         "I'd like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan.",
         "default"
        ],
        [
         "3",
         "Based on the provided context, here is an explanation of how Kwaak works and its architecture:\n\n### Explanation of Kwaak\n\nKwaak is a free, open-source platform that enables you to run autonomous AI agents on your local machine. It's designed to handle tasks such as code writing, executing, and creating pull requests in a parallel and autonomous manner. The platform uses a terminal-based chat interface through which users can interact with the agents to accomplish various coding tasks. Kwaak can index your entire codebase, making it capable of answering questions related to the code, finding examples, and even contributing to the code by pushing changes to a remote repository.\n\nKwaak's interaction with your codebase begins by indexing using Swiftide, which is crucial for its Retrieval-Augmented Generation (RAG) capabilities. The indexing is stored using DuckDB, and caching is handled through Redb, ensuring that subsequent startups are faster after the initial indexing.\n\n### Kwaak Architecture\n\nThe architecture of Kwaak involves a lightweight `ratatui`-based frontend that interacts with the backend through dispatched commands. Commands operate with channels for feedback responses. The backend encompasses managing sessions in Docker containers which isolate each agent task, allowing multiple sessions to run in parallel.\n\nWhen running, Kwaak utilizes sessions that handle agent interactions and configurations via Docker containers. Each session is self-contained with sandboxed code execution environments, agent states, configurations, and communication channels.\n\n### High-Level Components Diagram\n\nThe architecture can be visualized in a high-level component diagram represented using a Mermaid diagram (as extracted from the provided context):\n\n```mermaid\ngraph TD\n    A[Frontend (Ratatui)] --> B[Backend]\n    B --> C[Command Dispatcher]\n    B --> D[Session Management]\n    D --> E[Docker Container]\n    E --> F[Agent State and Configuration]\n    F --> G[Continuous Feedback Loop]\n    E --> H[Code Execution]\n    B --> I[DuckDB Storage]\n    C --> J[Command Response Channel]\n    J --> A\n```\n\n### References\n\n- Kwaak's architecture description from `./ARCHITECTURE.md`.\n- High-level overview and functionality explanation from `./README.md`.\n\nIf there are specific aspects of the architecture that need further exploration that are not covered in the provided context, providing additional documentation or source paths might be necessary for detailed exploration.",
         "['Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '**Q:** I get a redb/duckdb error when starting, what is up?\\n\\n**A**: Possibly your index got corrupted, or you have another kwaak instance running on the same project. Try clearing the index with `kwaak clear-index` and restart kwaak. Note that this will require a reindexing of your codebase.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## Latest updates on our blog :fire:\\n\\n- [Releasing kwaak with kwaak](https://bosun.ai/posts/releasing-kwaak-with-kwaak/)', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '**Q:** Kwaak feels very slow\\n\\n**A:** Try increasing the resources available for docker. For docker desktop this is in Settings -> Resources -> Advanced. On MacOS, adding your terminal and/or kwaak to developer tools can also help.', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '//! Builds various storage providers for kwaak\\n//!\\n//! Handled as statics to avoid multiple instances of the same storage provider\\n//!\\n//!\\n//! Currently there are 3 tables:\\n//! - project itself (indexing/retrieval) (uuid, path, chunk, embeddings)\\n//! - cache (for caching in indexing/retrieval) (uuid, path)\\n//! - runtime settings (for storing runtime settings) (key, value)\\n//!\\n//! Right now, these are relatively simple. Friendly reminder for future me and others to consider\\n//! a decent migration strategy if these tables change.\\n\\nuse std::sync::OnceLock;\\n\\nuse anyhow::{Context, Result};\\nuse swiftide::{indexing::EmbeddedField, integrations::duckdb::Duckdb};\\n\\nuse crate::repository::Repository;\\n\\nstatic DUCK_DB: OnceLock<Duckdb> = OnceLock::new();\\n\\n/// Retrieves a static duckdb\\n///\\n/// # Panics\\n///\\n/// Panics if it cannot setup duckdb\\npub fn get_duckdb(repository: &Repository) -> Duckdb {\\n    DUCK_DB\\n        .get_or_init(|| build_duckdb(repository).expect(\"Failed to build duckdb\"))\\n        .to_owned()\\n}\\n\\n// Probably should just be on the repository/config, cloned from there.\\n// This sucks in tests\\npub(crate) fn build_duckdb(repository: &Repository) -> Result<Duckdb> {\\n    let config = repository.config();\\n    let path = config.cache_dir().join(\"duck.db3\");\\n\\n    tracing::debug!(\"Building Duckdb: {}\", path.display());\\n\\n    let embedding_provider = config.embedding_provider();\\n\\n    let connection =\\n        duckdb::Connection::open(&path).context(\"Failed to open connection to duckdb\")?;\\n    Duckdb::builder()\\n        .connection(connection)\\n        .with_vector(\\n            EmbeddedField::Combined,\\n            embedding_provider.vector_size().try_into()?,\\n        )\\n        .table_name(normalize_table_name(&config.project_name))\\n        .cache_table(format!(\\n            \"cache_{}\",\\n            normalize_table_name(&config.project_name)\\n        ))\\n        .build()\\n        .context(\"Failed to build Duckdb\")\\n}\\n\\n// Is this enough?\\nfn normalize_table_name(name: &str) -> String {\\n    name.replace(\\'-\\', \"_\")\\n}', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", \"### Configuration\\n\\nKwaak supports configuring different Large Language Models (LLMs) for distinct tasks like indexing, querying, and embedding to optimize performance and accuracy. Be sure to tailor the configurations to fit the scope and blend of the tasks you're tackling.\", \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\"]",
         "The context provided does not offer detailed information specific to the complete architecture of Kwaak or a high-level component diagram in a format such as Mermaid. Therefore, I cannot generate a diagram or a full architectural description based solely on the given context.\n\nHowever, based on the snippets retrieved, here are some relevant points about how Kwaak works and its components:\n\n1. **General Functionality**: \n   - Kwaak allows you to run autonomous AI agents locally to work on coding tasks such as documenting, testing, and improving code quality.\n   - It provides a terminal user interface (TUI) for interaction with the agents.\n\n2. **Backend and Frontend**:\n   - It has a lightweight frontend based on `ratatui` that communicates with a backend via commands, and a command pattern is used to handle backend functionalities asynchronously. [Reference: ARCHITECTURE.md]\n\n3. **Indexing**:\n   - Upon initial setup, it indexes the codebase using \"Swiftide\" for Retrieval-Augmented Generation (RAG). This indexing is stored using `duckdb` and is cached with `redb`. [Reference: README.md]\n\n4. **Execution Environment**:\n   - Kwaak uses Docker containers to create safe execution environments for agents to run code. This ensures that the agents' execution doesn't affect the local system environment. [Reference: README.md]\n\n5. **Feedback Loop and Sessions**:\n   - Agents operate in a session, usually involving continuous feedback with an LLM until their assigned task is completed.\n\nUnfortunately, the provided context does not contain enough specific details about the architecture to further elaborate with a high-level diagram illustrative of all components in Mermaid or any other format. Additionally, any graphical architecture diagrams referred to in the content (e.g., `architecture.svg`) are not included as text, and hence such visual information cannot be reproduced here.\n\nFor a more detailed exploration of the architecture diagram or component breakdown, a look at the referenced architecture image or further documentation beyond the provided context would be necessary.",
         "Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components.",
         "default"
        ],
        [
         "4",
         "The context provided does not contain specific information explaining how channels work, interact, or relate in the app from a user's perspective. It only mentions that a \"command includes a channel to feed back responses into\" but does not provide further details on how this is implemented or functions within the app. \n\nTherefore, I cannot provide a comprehensive explanation based on the given context. More detailed documentation or code regarding the implementation of channels would be necessary to answer this question fully.",
         "['Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', 'use std::collections::HashSet;\\n\\nuse ratatui::widgets::ScrollbarState;\\n\\nuse crate::{chat_message::ChatMessage, repository::Repository};\\n\\n#[derive(Debug, Clone)]\\npub struct Chat {\\n    /// Display name of the chat\\n    pub name: String,\\n    /// Identifier used to match responses\\n    pub uuid: uuid::Uuid,\\n    pub branch_name: Option<String>,\\n    pub messages: Vec<ChatMessage>,\\n    pub state: ChatState,\\n    pub new_message_count: usize,\\n    pub completed_tool_call_ids: HashSet<String>,\\n\\n    // Scrolling is per chat\\n    // but handled in the ui\\n    pub vertical_scroll_state: ScrollbarState,\\n    pub vertical_scroll: usize,\\n    pub num_lines: usize,\\n\\n    // Whether to auto-tail the chat on new messages\\n    pub auto_tail: bool,\\n\\n    pub repository: Option<Repository>,\\n}\\n\\nimpl Chat {\\n    pub fn add_message(&mut self, message: ChatMessage) {\\n        if !message.role().is_user() {\\n            self.new_message_count += 1;\\n        }\\n\\n        // If it\\'s a completed tool call, just register it is done and do not add the message\\n        // The state is updated when rendering on the initial tool call\\n        if message.role().is_tool() {\\n            let Some(tool_call) = message.maybe_completed_tool_call() else {\\n                tracing::error!(\\n                    \"Received a tool message without a tool call ID: {:?}\",\\n                    message\\n                );\\n                return;\\n            };\\n\\n            self.completed_tool_call_ids\\n                .insert(tool_call.id().to_string());\\n\\n            return;\\n        }\\n        self.messages.push(message);\\n    }\\n\\n    pub fn transition(&mut self, state: ChatState) {\\n        self.state = state;\\n    }\\n\\n    #[must_use]\\n    pub fn is_loading(&self) -> bool {\\n        matches!(\\n            self.state,\\n            ChatState::Loading | ChatState::LoadingWithMessage(_)\\n        )\\n    }\\n\\n    #[must_use]\\n    pub fn is_tool_call_completed(&self, tool_call_id: &str) -> bool {\\n        self.completed_tool_call_ids.contains(tool_call_id)\\n    }\\n}', 'pub struct App<\\'a> {\\n    pub splash: splash::Splash<\\'a>,\\n    pub has_indexed_on_boot: bool,\\n    // /// The chat input\\n    // pub input: String,\\n    pub text_input: TextArea<\\'a>,\\n\\n    /// All known chats\\n    pub chats: Vec<Chat>,\\n\\n    /// UUID of the current chat\\n    pub current_chat_uuid: uuid::Uuid,\\n\\n    /// Holds the sender of UI events for later cloning if needed\\n    pub ui_tx: mpsc::UnboundedSender<UIEvent>,\\n\\n    /// Receives UI events (key presses, commands, etc)\\n    pub ui_rx: mpsc::UnboundedReceiver<UIEvent>,\\n\\n    /// Sends commands to the backend\\n    pub command_tx: Option<mpsc::UnboundedSender<CommandEvent>>,\\n\\n    /// Responds to commands from the backend\\n    /// And maps them to ui events\\n    pub command_responder: AppCommandResponder,\\n\\n    /// Mode the app is in, manages the which layout is rendered and if it should quit\\n    pub mode: AppMode,\\n\\n    /// Tracks the current selected state in the UI\\n    pub chats_state: ListState,\\n\\n    /// Tab names\\n    pub tab_names: Vec<&\\'static str>,\\n\\n    /// Index of selected tab\\n    pub selected_tab: usize,\\n\\n    /// States when viewing logs\\n    pub log_state: TuiWidgetState,\\n\\n    /// Commands that relate to boot, and not a chat\\n    pub boot_uuid: Uuid,\\n\\n    /// Skip indexing on boot\\n    pub skip_indexing: bool,\\n\\n    /// Override the working directory if it is not \".\"\\n    pub workdir: PathBuf,\\n\\n    /// Hack to get line wrapping on input into the textarea\\n    pub input_width: Option<u16>,\\n\\n    /// Max lines we can render in the chat messages\\n    pub chat_messages_max_lines: u16,\\n\\n    /// User configuration for the UI\\n    pub ui_config: UIConfig,\\n\\n    /// Informs the user if there is an update available\\n    pub update_available: Option<update_informer::Version>,\\n}\\n\\n#[derive(Debug, Clone, Copy, Default, PartialEq)]\\npub enum AppMode {\\n    #[default]\\n    Chat,\\n    Logs,\\n    Quit,\\n}', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', 'mod chat_list_widget;\\nmod chat_messages_widget;\\nmod help_section_widget;\\nmod input_bar_widget;\\nmod message_formatting;\\nmod on_key;\\nmod ui;\\n\\npub use on_key::on_key;\\npub use ui::ui;', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '\\n    async fn test_add_chat() {\\n        let mut app = App::default();\\n        let initial_chat_count = app.chats.len();\\n\\n        app.add_chat(Chat::default());\\n\\n        assert_eq!(app.chats.len(), initial_chat_count + 1);\\n        assert_eq!(\\n            app.chats.last().unwrap().name,\\n            format!(\"Chat #{}\", initial_chat_count + 1)\\n        );\\n    }\\n\\n    #[tokio::test]\\n    async fn test_next_chat() {\\n        let mut app = App::default();\\n        let first_uuid = app.current_chat_uuid;\\n\\n        app.add_chat(Chat::default());\\n        let second_uuid = app.current_chat_uuid;\\n\\n        app.next_chat();\\n        assert_eq!(app.current_chat_uuid, first_uuid);\\n\\n        app.next_chat();\\n        assert_eq!(app.current_chat_uuid, second_uuid);\\n    }\\n\\n    #[tokio::test]\\n    async fn test_find_chat() {\\n        let mut app = App::default();\\n        let chat = Chat::default();\\n        let uuid = chat.uuid;\\n\\n        app.add_chat(chat);\\n\\n        assert!(app.find_chat(uuid).is_some());\\n        assert!(app.find_chat(Uuid::new_v4()).is_none());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_find_chat_mut() {\\n        let mut app = App::default();\\n        let chat = Chat::default();\\n        let uuid = chat.uuid;\\n\\n        app.add_chat(chat);\\n\\n        assert!(app.find_chat_mut(uuid).is_some());\\n        assert!(app.find_chat_mut(Uuid::new_v4()).is_none());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_current_chat() {\\n        let app = App::default();\\n        assert!(app.current_chat().is_some());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_current_chat_mut() {\\n        let mut app = App::default();\\n        assert!(app.current_chat_mut().is_some());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_add_chat_message() {\\n        let mut app = App::default();\\n        let message = ChatMessage::new_system(\"Test message\");\\n\\n        app.add_chat_message(app.current_chat_uuid, message.clone());\\n\\n        let chat = app.current_chat().unwrap();\\n        assert!(chat.messages.contains(&message));\\n    }\\n}', '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', 'use crate::frontend::App;\\n\\npub fn scroll_up(app: &mut App) {\\n    let Some(current_chat) = app.current_chat_mut() else {\\n        return;\\n    };\\n    current_chat.vertical_scroll = current_chat.vertical_scroll.saturating_sub(2);\\n    current_chat.vertical_scroll_state = current_chat\\n        .vertical_scroll_state\\n        .position(current_chat.vertical_scroll);\\n    current_chat.auto_tail = false;\\n}\\n\\npub fn scroll_down(app: &mut App) {\\n    let Some(current_chat) = app.current_chat_mut() else {\\n        return;\\n    };\\n    current_chat.vertical_scroll = current_chat.vertical_scroll.saturating_add(2);\\n    current_chat.vertical_scroll_state = current_chat\\n        .vertical_scroll_state\\n        .position(current_chat.vertical_scroll);\\n    // Optional: only disable auto_tail when actually scrolling up\\n    current_chat.auto_tail = false;\\n}\\n\\npub fn scroll_end(app: &mut App) {\\n    let max_lines_in_area = app.chat_messages_max_lines.saturating_sub(2);\\n\\n    let Some(current_chat) = app.current_chat_mut() else {\\n        tracing::error!(\"No current chat to scroll to end\");\\n        return;\\n    };\\n    let scroll_position = current_chat\\n        .num_lines\\n        .saturating_sub(max_lines_in_area as usize);\\n\\n    current_chat.vertical_scroll = scroll_position;\\n    current_chat.vertical_scroll_state =\\n        current_chat.vertical_scroll_state.position(scroll_position);\\n    current_chat.auto_tail = true;\\n}', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', 'use ratatui::text::Text;\\n\\n/// Represents a chat message that can be stored in a [`Chat`]\\n///\\n/// Messages are expected to be formatted strings and are displayed as-is. Markdown is rendered\\n/// using `tui-markdown`.\\n///\\n/// TODO: All should be Cows\\n#[derive(Clone, Default, PartialEq)]\\npub struct ChatMessage {\\n    role: ChatRole,\\n    content: String,\\n    /// Owned rendered text\\n    rendered: Option<Text<\\'static>>,\\n    original: Option<swiftide::chat_completion::ChatMessage>,\\n}\\n\\n// Debug with truncated content\\nimpl std::fmt::Debug for ChatMessage {\\n    fn fmt(&self, f: &mut std::fmt::Formatter<\\'_>) -> std::fmt::Result {\\n        f.debug_struct(\"ChatMessage\")\\n            .field(\"role\", &self.role)\\n            .field(\"content\", &self.content)\\n            .field(\"original\", &self.original)\\n            .field(\"rendered\", &self.rendered.is_some())\\n            .finish()\\n    }\\n}\\n\\n#[derive(\\n    Debug,\\n    Clone,\\n    Copy,\\n    Default,\\n    strum::EnumString,\\n    strum::Display,\\n    strum::AsRefStr,\\n    strum::EnumIs,\\n    PartialEq,\\n)]\\npub enum ChatRole {\\n    User,\\n    #[default]\\n    System,\\n    Command,\\n    Assistant,\\n    Tool,\\n}\\n\\nimpl ChatMessage {\\n    pub fn new_user(msg: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::User)\\n            .with_content(msg.into())\\n            .to_owned()\\n    }\\n\\n    pub fn new_system(msg: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::System)\\n            .with_content(msg.into())\\n            .to_owned()\\n    }\\n\\n    pub fn new_command(cmd: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::Command)\\n            .with_content(cmd.into().to_string())\\n            .to_owned()\\n    }\\n\\n    pub fn new_assistant(msg: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::Assistant)\\n            .with_content(msg.into())\\n            .to_owned()\\n    }', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'You can use the following slash commands to interact with kwaak and the agent:\\n\\n{% for command, description in commands -%}\\n**/{{command}}** - {{description}}\\n{% endfor %}', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '\\n\\n#[derive(Debug, Clone, Default, strum::EnumIs, PartialEq)]\\npub enum ChatState {\\n    Loading,\\n    LoadingWithMessage(String),\\n    #[default]\\n    Ready,\\n}\\n\\nimpl Default for Chat {\\n    fn default() -> Self {\\n        Self {\\n            name: \"Chat\".to_string(),\\n            uuid: uuid::Uuid::new_v4(),\\n            branch_name: None,\\n            messages: Vec::new(),\\n            state: ChatState::default(),\\n            new_message_count: 0,\\n            completed_tool_call_ids: HashSet::new(),\\n            vertical_scroll_state: ScrollbarState::default(),\\n            vertical_scroll: 0,\\n            num_lines: 0,\\n            auto_tail: true,\\n            repository: None,\\n        }\\n    }\\n}\\n\\n#[cfg(test)]', 'use kwaak::commands::Command;\\nuse kwaak::frontend::{ui, UIEvent, UserInputCommand};\\nuse kwaak::test_utils::{setup_integration, IntegrationContext};\\nuse kwaak::{assert_agent_responded, assert_command_done};\\n\\n#[test_log::test(tokio::test(flavor = \"multi_thread\"))]\\nasync fn retry_chat() {\\n    let IntegrationContext {\\n        mut app,\\n        uuid,\\n        mut terminal,\\n\\n        handler_guard,\\n        repository_guard: _repository_guard,\\n        ..\\n    } = setup_integration().await.unwrap();\\n\\n    // First, let\\'s start a noop agent so an environment is running\\n    app.dispatch_command(\\n        uuid,\\n        Command::Chat {\\n            message: \"hello\".to_string(),\\n        },\\n    );\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"before_retry\", terminal.backend());\\n\\n    // Let\\'s retry the chat\\n    app.send_ui_event(UIEvent::UserInputCommand(uuid, UserInputCommand::Retry));\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    // It should now show 2 messages\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"after_retry\", terminal.backend());\\n\\n    // Force dropping it, for some reason it\\'s not being dropped\\n    drop(handler_guard);\\n}', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.']",
         "The provided context does not contain sufficient information to fully explain how channels work within the app from a user's perspective. It mentions that commands include a \"channel to feed back responses\" into, but it does not elaborate further on how these channels interact, relate, or are utilized from a user's perspective. Additionally, there is no detailed description or explanation about user interaction with these channels within the retrieved content. Therefore, the question cannot be answered based on the current context. \n\nIf further details are needed, exploring the files or code sections mentioning \"channels\" specifically within the `commands` or `frontend` modules might be a good starting point, as these modules seem to deal with command patterns and user interaction.",
         "There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective.",
         "default"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>[Kwaak is free and open-source. You can bring ...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>How can I add a tool for an agent?</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The tools used by an agent in the context prov...</td>\n",
       "      <td>[## How is Kwaak different from other tools?\\n...</td>\n",
       "      <td>The provided context does not specifically exp...</td>\n",
       "      <td>How are tools used by an agent?</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the provided context, here is a step-...</td>\n",
       "      <td>[### Arch Linux\\n\\nThe package is available in...</td>\n",
       "      <td>To configure a session in a file such that use...</td>\n",
       "      <td>I'd like to be able to configure a session in ...</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the provided context, here is an expl...</td>\n",
       "      <td>[Kwaak is free and open-source. You can bring ...</td>\n",
       "      <td>The context provided does not offer detailed i...</td>\n",
       "      <td>Explain kwaak works and explain the architectu...</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The context provided does not contain specific...</td>\n",
       "      <td>[Kwaak provides a chat interface similar to ot...</td>\n",
       "      <td>The provided context does not contain sufficie...</td>\n",
       "      <td>There are multiple uses of channels in the app...</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  The provided context does not contain specific...   \n",
       "1  The tools used by an agent in the context prov...   \n",
       "2  Based on the provided context, here is a step-...   \n",
       "3  Based on the provided context, here is an expl...   \n",
       "4  The context provided does not contain specific...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Kwaak is free and open-source. You can bring ...   \n",
       "1  [## How is Kwaak different from other tools?\\n...   \n",
       "2  [### Arch Linux\\n\\nThe package is available in...   \n",
       "3  [Kwaak is free and open-source. You can bring ...   \n",
       "4  [Kwaak provides a chat interface similar to ot...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The provided context does not contain specific...   \n",
       "1  The provided context does not specifically exp...   \n",
       "2  To configure a session in a file such that use...   \n",
       "3  The context provided does not offer detailed i...   \n",
       "4  The provided context does not contain sufficie...   \n",
       "\n",
       "                                            question features  \n",
       "0                 How can I add a tool for an agent?  default  \n",
       "1                    How are tools used by an agent?  default  \n",
       "2  I'd like to be able to configure a session in ...  default  \n",
       "3  Explain kwaak works and explain the architectu...  default  \n",
       "4  There are multiple uses of channels in the app...  default  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load all the evals into a single dataframe, and we add the features as a column\n",
    "pd_all = pd.DataFrame()\n",
    "\n",
    "for eval in evals:\n",
    "    df_eval = pd.read_json(eval[\"output_file\"])\n",
    "    df_eval[\"features\"] = \",\".join(eval[\"features\"])\n",
    "    pd_all = pd.concat([pd_all, df_eval], ignore_index=True)\n",
    "\n",
    "pd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617ab4a28bbc4935856205e49c2f1d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[                                          user_input  \\\n",
       " 0                 How can I add a tool for an agent?   \n",
       " 1                    How are tools used by an agent?   \n",
       " 2  I'd like to be able to configure a session in ...   \n",
       " 3  Explain kwaak works and explain the architectu...   \n",
       " 4  There are multiple uses of channels in the app...   \n",
       " \n",
       "                                   retrieved_contexts  \\\n",
       " 0  [Kwaak is free and open-source. You can bring ...   \n",
       " 1  [## How is Kwaak different from other tools?\\n...   \n",
       " 2  [### Arch Linux\\n\\nThe package is available in...   \n",
       " 3  [Kwaak is free and open-source. You can bring ...   \n",
       " 4  [Kwaak provides a chat interface similar to ot...   \n",
       " \n",
       "                                             response  \\\n",
       " 0  The provided context does not contain specific...   \n",
       " 1  The tools used by an agent in the context prov...   \n",
       " 2  Based on the provided context, here is a step-...   \n",
       " 3  Based on the provided context, here is an expl...   \n",
       " 4  The context provided does not contain specific...   \n",
       " \n",
       "                                            reference  answer_relevancy  \\\n",
       " 0  The provided context does not contain specific...          0.000000   \n",
       " 1  The provided context does not specifically exp...          0.963323   \n",
       " 2  To configure a session in a file such that use...          0.869238   \n",
       " 3  The context provided does not offer detailed i...          0.913148   \n",
       " 4  The provided context does not contain sufficie...          0.000000   \n",
       " \n",
       "    faithfulness  context_recall  context_precision features  \n",
       " 0      1.000000        1.000000           1.000000  default  \n",
       " 1      1.000000        0.923077           0.901089  default  \n",
       " 2      0.692308        0.818182           0.927719  default  \n",
       " 3      0.833333        1.000000           0.038462  default  \n",
       " 4      1.000000        1.000000           0.000000  default  ]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Runs the evaluations on the gathered data for each feature combination\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "# Convert the dataframe to a Hugging Face dataset\n",
    "hf_dataset = Dataset.from_pandas(pd_all)\n",
    "\n",
    "# Now let's add evaluation metrics to each row in the dataset\n",
    "all_results = []\n",
    "for features, df in pd_all.groupby(\"features\"):\n",
    "    hf_dataset = Dataset.from_pandas(df)\n",
    "    results = evaluate(hf_dataset, metrics=[answer_relevancy, faithfulness, context_recall, context_precision]).to_pandas()\n",
    "    results[\"features\"] = features\n",
    "    all_results.append(results)\n",
    "\n",
    "# Convert the updated dataframe back to a Hugging Face dataset\n",
    "all_results\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "retrieved_contexts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "response",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer_relevancy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "faithfulness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "context_recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "context_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "features",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0ef58306-0ee7-411e-bf66-1decb79f90d2",
       "rows": [
        [
         "0",
         "How can I add a tool for an agent?",
         "['Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '{{description}}\\n\\n---\\n\\n_This pull request was created by [kwaak](https://github.com/bosun-ai/kwaak), a free, open-source, autonomous coding agent tool. Pull requests are tracked in bosun-ai/kwaak#48_\\n\\n{% if messages | length > 0 -%}\\n<details>\\n<summary>Message History</summary>\\n\\n{% for message in messages -%}\\n<details>\\n  <summary>{{message.role}}</summary>\\n\\n```markdown\\n{{message.content}}\\n```\\n</details>\\n{% if message.role is containing(\"Assistant\") -%}', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '# Kwaak SWE-Bench Runner\\n\\nA Python package for running and evaluating the Kwaak agent against the SWE-bench dataset, a benchmark for evaluating LLMs on real-world software engineering tasks.', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.']",
         "The provided context does not contain specific instructions or steps on how to add a tool for an agent in the Kwaak system. The context mentions tools in several different snippets, such as in the code example of `DelegateAgent` in `delegate_agent.rs`, which is a tool that delegates a task to an agent, and in `tool_evaluation_agent.rs`, where tools are part of an agent's functionalities. However, there are no explicit instructions on how to add a new tool.\n\nHere are some leads from the context that could guide further exploration:\n\n1. **Tool Interface and Implementation**: Snippets from files like `delegate_agent.rs` and `tool_evaluation_agent.rs` describe tools that appear to implement the `Tool` trait from `swiftide::chat_completion`. Implementing this trait might be a necessary step in creating a new tool.\n\n2. **Tool Registration**: In `tool_evaluation_agent.rs`, tools seem to be passed into an `Agent::builder()` via a `tools` parameter, indicating a possible mechanism for associating tools with agents.\n\n3. **Agent Configuration**: Since agents and their configurations might be part of the `Session` and `RunningAgent` structures mentioned in the context, looking into how configurations are specified in these entities might provide insights.\n\n4. **Documentation**: The configuration section of the README mentions various aspects like command configuration and agent configuration, which might hold relevant details on adding new functionalities or tools.\n\nIf more detailed information is needed, reviewing the source code and documentation related to these components would be necessary, especially around where tools are defined and associated with agents in the Kwaak framework.",
         "The provided context does not contain specific instructions on how to add a tool for an agent in Kwaak. However, the context does provide some relevant information about existing tools and how they might be structured.\n\nFor example, Kwaak's tools are implemented using traits such as `Tool` from the `swiftide` library, and typically involve defining specific functionalities and parameters as shown in the `DelegateAgent` and `RunTests` implementations.\n\nHere are some details you might consider when adding a new tool based on the context:\n\n1. **Define Tool Struct**: Create a new struct for your tool, implementing necessary fields and methods. Reference existing tools like `DelegateAgent` and `RunTests` as examples.\n\n2. **Implement the Tool Trait**: Use the `Tool` trait to define the behavior of your tool, including how it should be invoked and what parameters it expects.\n\n3. **Provide Description**: Ensure that your tool has a clear description and parameter annotations, as shown in the snippets, to help users understand the tool's purpose and usage.\n\n4. **Use Context**: Make use of the `AgentContext` to interact with the current session or execution environment.\n\n5. **Command Execution**: If your tool requires executing commands (like running tests or shell commands), see how commands are handled and executed in existing tools (e.g., `RunTests`, `shell_command`).\n\nUnfortunately, further specific steps or files required to add a tool aren't available in the context. You might find more concrete guidance in the source code files and the tool trait implementations like those mentioned above.",
         "0.0",
         "1.0",
         "1.0",
         "0.9999999999966668",
         "default"
        ],
        [
         "1",
         "How are tools used by an agent?",
         "['## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', 'use anyhow::Result;\\nuse std::sync::Arc;\\nuse swiftide::agents::{Agent, DefaultContext};\\nuse swiftide::chat_completion::{ChatCompletion, Tool};\\nuse swiftide::traits::AgentContext;\\n\\nuse crate::agent::agents;\\nuse crate::agent::running_agent::RunningAgent;\\nuse crate::commands::Responder;\\nuse crate::repository::Repository;\\n\\n// Note that this uses a local executor\\npub async fn start_tool_evaluation_agent(\\n    repository: &Repository,\\n    responder: Arc<dyn Responder>,\\n    tools: Vec<Box<dyn Tool>>,\\n) -> Result<RunningAgent> {\\n    // Create agent with simplified tools\\n    let system_prompt = agents::coding::build_system_prompt(repository)?;\\n    let agent_context: Arc<dyn AgentContext> =\\n        Arc::new(DefaultContext::default()) as Arc<dyn AgentContext>;\\n\\n    let backoff = repository.config().backoff;\\n\\n    let query_provider: Box<dyn ChatCompletion> = repository\\n        .config()\\n        .query_provider()\\n        .get_chat_completion_model(backoff)?;\\n\\n    let responder_for_messages = responder.clone();\\n    let responder_for_tools = responder.clone();\\n\\n    let agent = Agent::builder()\\n        .tools(tools)\\n        .system_prompt(system_prompt)\\n        .context(agent_context.clone())\\n        .llm(&query_provider)\\n        .on_new_message(move |_, message| {\\n            let responder = responder_for_messages.clone();\\n            let message = message.clone();\\n            Box::pin(async move {\\n                responder.agent_message(message);\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let responder = responder_for_tools.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .build()?;\\n\\n    let agent = RunningAgent::builder()\\n        .agent(agent)\\n        .agent_context(agent_context)\\n        .build()?;\\n\\n    Ok(agent)\\n}', 'use std::path::PathBuf;\\n\\nuse clap::{Parser, Subcommand, ValueEnum};\\n\\n#[derive(Parser, Debug, Clone)]\\n#[clap(author, about, version)]\\npub struct Args {\\n    /// Optional path to overwrite the config\\n    #[arg(short, long, default_value = None)]\\n    pub config_path: Option<PathBuf>,\\n\\n    /// Skip initial indexing and splash screen\\n    #[arg(short, long, default_value_t = false)]\\n    pub skip_indexing: bool,\\n\\n    /// Allow running with a dirty git directory\\n    #[arg(long, default_value_t = false)]\\n    pub allow_dirty: bool,\\n\\n    /// Subcommands corresponding to each mode\\n    #[clap(subcommand)]\\n    pub command: Option<Commands>,\\n}\\n\\n#[derive(Subcommand, Debug, Clone, Default)]\\npub enum Commands {\\n    /// Initializes a new kwaak project in the current directory\\n    Init {\\n        #[arg(long, default_value_t = false)]\\n        dry_run: bool,\\n        /// Output to a specific file\\n        #[arg(long)]\\n        file: Option<PathBuf>,\\n    },\\n    /// Start the TUI (default)\\n    #[default]\\n    Tui,\\n    /// Query the indexed project\\n    Query {\\n        #[arg(short, long)]\\n        query: String,\\n    },\\n    /// Run an agent directly\\n    RunAgent {\\n        #[arg(short, long)]\\n        initial_message: String,\\n    },\\n    /// Index the current project\\n    Index,\\n    /// Tests a tool\\n    TestTool {\\n        tool_name: String,\\n        tool_args: Option<String>,\\n    },\\n    /// Print the configuration and exit\\n    PrintConfig,\\n    /// Clear the index and cache for this project and exit\\n    ClearCache,\\n    /// Run evaluations\\n    #[cfg(feature = \"evaluations\")]\\n    Eval {\\n        #[command(subcommand)]\\n        eval_type: EvalCommands,\\n    },\\n}\\n\\n#[derive(Subcommand, Debug, Clone)]', 'use std::{borrow::Cow, sync::Arc};\\n\\nuse async_trait::async_trait;\\nuse derive_builder::Builder;\\nuse serde::Deserialize;\\nuse swiftide::{\\n    chat_completion::{self, errors::ToolError, Tool, ToolOutput, ToolSpec},\\n    traits::AgentContext,\\n};\\n\\nuse crate::agent::{running_agent::RunningAgent, session::Session};\\n\\n/// A tool that delegates to an agent\\n///\\n/// For convenience, its assumed the agent is already set up (a `RunningAgent`).\\n///\\n/// The tool takes a tool spec, agent and session during creating, so that it can be utilized to\\n/// delegate to any agent.\\n///\\n/// After delegation, the agent invoking the tool is stopped, but not destroyed.\\n#[derive(Clone, Builder)]\\npub struct DelegateAgent {\\n    session: Arc<Session>,\\n    agent: RunningAgent,\\n\\n    tool_spec: ToolSpec,\\n}\\n\\nimpl DelegateAgent {\\n    #[must_use]\\n    pub fn builder() -> DelegateAgentBuilder {\\n        DelegateAgentBuilder::default()\\n    }\\n\\n    pub async fn delegate_agent(\\n        &self,\\n        _context: &dyn AgentContext,\\n        task: &str,\\n    ) -> Result<ToolOutput, ToolError> {\\n        self.session.swap_agent(self.agent.clone())?;\\n        self.agent.query(task).await?;\\n\\n        tracing::info!(\"Delegated task to agent\");\\n        Ok(ToolOutput::Stop)\\n    }\\n}\\n\\n#[derive(Deserialize)]\\nstruct DelegateArgs {\\n    task: String,\\n}\\n\\n#[async_trait]\\nimpl Tool for DelegateAgent {\\n    async fn invoke(\\n        &self,\\n        agent_context: &dyn AgentContext,\\n        raw_args: Option<&str>,\\n    ) -> Result<ToolOutput, ToolError> {\\n        let Some(args) = raw_args else {\\n            return Err(ToolError::MissingArguments(format!(\\n                \"No arguments provided for {}\",\\n                self.name()\\n            )));\\n        };\\n\\n        let args: DelegateArgs = serde_json::from_str(&args)?;\\n        return self.delegate_agent(agent_context, &args.task).await;\\n    }\\n\\n    fn tool_spec(&self) -> chat_completion::ToolSpec {\\n        self.tool_spec.clone()\\n    }\\n\\n    fn name(&self) -> Cow<\\'_, str> {\\n        self.tool_spec().name.into()\\n    }\\n}', '\\npub struct RunTests {\\n    pub test_command: String,\\n}\\n\\nimpl RunTests {\\n    pub fn new(test_command: impl AsRef<str>) -> Self {\\n        Self {\\n            test_command: test_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_tests(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.test_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone, Debug)]\\n#[tool(\\n    description = \"Get coverage of tests, this also runs the tests. Only run this in favour of just the tests if you need coverage, as it is typically slower than running tests.\"\\n)]\\npub struct RunCoverage {\\n    pub coverage_command: String,\\n}\\n\\nimpl RunCoverage {\\n    pub fn new(coverage_command: impl AsRef<str>) -> Self {\\n        Self {\\n            coverage_command: coverage_command.as_ref().to_string(),\\n        }\\n    }\\n\\n    async fn run_coverage(&self, context: &dyn AgentContext) -> Result<ToolOutput, ToolError> {\\n        let cmd = Command::Shell(self.coverage_command.clone());\\n        let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n        Ok(output.into())\\n    }\\n}\\n\\n#[derive(Tool, Clone)]\\n#[tool(\\n    description = \"Search the web to answer a question. If you encounter an issue that cannot be resolved, use this tool to help getting an answer.\",\\n    param(name = \"query\", description = \"Search query\")\\n)]\\npub struct SearchWeb {\\n    tavily_client: Arc<Tavily>,\\n    api_key: ApiKey,\\n}', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '\\n\\n    if let Err(error) = app_result {\\n        ::tracing::error!(?error, \"Kwaak encountered an error\\\\n {error:#}\");\\n        eprintln!(\"Kwaak encountered an error\\\\n {error}\");\\n        std::process::exit(1);\\n    }\\n\\n    Ok(())\\n}\\n\\nasync fn test_tool(\\n    repository: &repository::Repository,\\n    tool_name: &str,\\n    tool_args: Option<&str>,\\n) -> Result<()> {\\n    let github_session = Arc::new(GithubSession::from_repository(&repository)?);\\n    let tool = available_tools(repository, Some(&github_session), None)?\\n        .into_iter()\\n        .find(|tool| tool.name() == tool_name)\\n        .context(\"Tool not found\")?;\\n\\n    let mut executor = DockerExecutor::default();\\n    let dockerfile = &repository.config().docker.dockerfile;\\n\\n    println!(\\n        \"Starting executor with dockerfile: {}\",\\n        dockerfile.display()\\n    );\\n    let running_executor = executor\\n        .with_context_path(&repository.config().docker.context)\\n        .with_image_name(repository.config().project_name.to_lowercase())\\n        .with_dockerfile(dockerfile)\\n        .to_owned()\\n        .start()\\n        .await?;\\n\\n    let agent_context = DefaultContext::from_executor(running_executor);\\n\\n    println!(\"Invoking tool: {tool_name}\");\\n    let output = tool\\n        .invoke(&agent_context as &dyn AgentContext, tool_args)\\n        .await?;\\n\\n    println!(\"{output}\");\\n\\n    Ok(())\\n}\\n\\n#[instrument(skip_all)]', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', 'mod delegate_agent;\\nmod replace_lines;\\n\\npub use delegate_agent::DelegateAgent;\\npub use replace_lines::replace_lines;\\n\\nuse std::sync::Arc;\\nuse swiftide::traits::CommandError;\\n\\nuse anyhow::{Context as _, Result};\\nuse swiftide::{\\n    chat_completion::{errors::ToolError, ToolOutput},\\n    query::{search_strategies, states},\\n    traits::{AgentContext, Command},\\n};\\nuse swiftide_macros::{tool, Tool};\\nuse tavily::Tavily;\\nuse tokio::sync::Mutex;\\n\\nuse crate::{\\n    config::ApiKey,\\n    git::github::GithubSession,\\n    templates::Templates,\\n    util::{self, accept_non_zero_exit},\\n};\\n\\n#[allow(dead_code)]\\nstatic MAIN_BRANCH_CMD: &str = \"git remote show origin | sed -n \\'/HEAD branch/s/.*: //p\\'\";\\n\\n/// WARN: Experimental\\n#[tool(\\n    description = \"Run any shell command in the current project, use this if other tools are not enough.\",\\n    param(\\n        name = \"cmd\",\\n        description = \"The shell command, including any arguments if needed, to run\"\\n    )\\n)]\\npub async fn shell_command(context: &dyn AgentContext, cmd: &str) -> Result<ToolOutput, ToolError> {\\n    if util::is_git_branch_change(cmd) {\\n        return Ok(\\n            \"You cannot change branches, you are already on a branch created specifically for you.\"\\n                .into(),\\n        );\\n    }\\n    let output = accept_non_zero_exit(context.exec_cmd(&Command::Shell(cmd.into())).await)?;\\n    Ok(output.into())\\n}\\n\\n#[tool(\\n    description = \"Reads file content\",\\n    param(name = \"file_name\", description = \"Full path of the file\")\\n)]\\npub async fn read_file(\\n    context: &dyn AgentContext,\\n    file_name: &str,\\n) -> Result<ToolOutput, ToolError> {\\n    let cmd = Command::ReadFile(file_name.into());\\n\\n    // i.e. if the file doesn\\'t exist, just forward that message\\n    let output = accept_non_zero_exit(context.exec_cmd(&cmd).await)?;\\n\\n    Ok(output.into())\\n}\\n\\n// TODO: Better to have a single read_file tool with an optional line number flag', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '## Additional information\\n\\nThis context is provided for an ai agent that has to accomplish the above. Additionally, the agent has access to the following tools:\\n{{available_tools}}', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '# Kwaak SWE-Bench Runner\\n\\nA Python package for running and evaluating the Kwaak agent against the SWE-bench dataset, a benchmark for evaluating LLMs on real-world software engineering tasks.', ' Agent::builder()\\n        .context(Arc::clone(&context) as Arc<dyn AgentContext>)\\n        .system_prompt(system_prompt)\\n        .tools(tools.to_vec())\\n        .before_all(move |agent| {\\n            let initial_context = initial_context.clone();\\n\\n            Box::pin(async move {\\n                agent.context()\\n                    .add_message(chat_completion::ChatMessage::new_user(initial_context))\\n                    .await;\\n\\n                let top_level_project_overview = agent.context().exec_cmd(&Command::shell(\"fd -iH -d2 -E \\'.git/*\\'\")).await?.output;\\n                agent.context().add_message(chat_completion::ChatMessage::new_user(format!(\"The following is a max depth 2, high level overview of the directory structure of the project: \\\\n ```{top_level_project_overview}```\"))).await;\\n\\n                Ok(())\\n            })\\n        })\\n        .on_new_message(move |_, message| {\\n            let command_responder = tx_2.clone();\\n            let message = message.clone();\\n\\n            Box::pin(async move {\\n                command_responder.agent_message(message);\\n\\n                Ok(())\\n            })\\n        })\\n        .before_completion(move |_, _| {\\n            let command_responder = tx_3.clone();\\n            Box::pin(async move {\\n                command_responder.update(\"running completions\");\\n                Ok(())\\n            })\\n        })\\n        .before_tool(move |_, tool| {\\n            let command_responder = tx_4.clone();\\n            let tool = tool.clone();\\n            Box::pin(async move {\\n                command_responder.update(&format!(\"running tool {}\", tool.name()));\\n                Ok(())\\n            })\\n        })\\n        .after_tool(tool_summarizer.summarize_hook())\\n        .after_each']",
         "The tools used by an agent in the context provided are integrated into several processes. Here’s how they are generally applied:\n\n1. **Agent Integration**: Tools are part of an agent's toolset, used during sessions to execute specific tasks. Each agent can use various tools depending on the session configuration (Reference: `./src/agent/agents/mod.rs`).\n\n2. **Execution in a Sandbox**: Agents leverage Docker containers to provide a safe execution environment for running the code. This ensures that agents can perform tasks without affecting the local system (Reference: `README.md`).\n\n3. **Example of Tool Invocation**: A tool like `DelegateAgent` takes tasks and delegates them to an agent within a session, utilizing the agent to query and perform tasks (Reference: `./src/agent/tools/delegate_agent.rs`).\n\n4. **Tool Evaluation**: Tools are also used for testing and evaluation purposes within controlled environments, such as managing isolated test environments using Docker (Reference: `./benchmarks/swe/README.md`).\n\n5. **Integration via Code Execution**: Tools can execute commands directly. For example, the `RunTests` and `RunCoverage` tools run shell commands to execute testing and coverage analysis (Reference: `./src/agent/tools/mod.rs`).\n\n6. **Feedback and Updates**: When a tool is invoked, feedback mechanisms are employed. Tools are used before and after their execution to provide updates and results (Reference: `./src/evaluations/tool_evaluation_agent.rs`).\n\nIn summary, tools in Kwaak are utilized to execute tasks, manage code safely, delegate operations to agents, perform evaluations, and provide real-time feedback within the sandboxed Docker environments.",
         "The provided context does not specifically explain how tools are used by an agent, in terms of their operational mechanism within a larger system. However, there is some information about the structure and functionality of tools in `Kwaak`.\n\n### Key Points from the Context:\n\n1. **Agent and Tools System**:\n   - Agents in Kwaak can operate a number of tools that help them execute tasks. The context refers to various tools such as those for running tests, checking code coverage, and interacting with shell commands. ([source code](./src/agent/tools/mod.rs), [README.md](./README.md))\n\n2. **Delegate Agent Tool**:\n   - Presents an example of how a tool is set up. The `DelegateAgent` tool delegates tasks to a particular agent. It uses an object called a `RunningAgent` that is assumed to be already configured ([source code](./src/agent/tools/delegate_agent.rs)).\n\n3. **Tool Configuration and Invocation**:\n   - Tools are configured and utilized within agents during certain tasks, e.g., running shell commands or reading files. Some parts of the code provide functionality for running commands with a sandboxed shell environment using Docker ([source code](./src/agent/tools/mod.rs)).\n\n4. **Initial Context and Configuration**:\n   - The system can utilize initial context and configuration to guide the tools. This context might describe how a project is set up or give an overview of the directory structure to help with the execution of tasks ([source code](./src/agent/agents/coding.rs)).\n\n5. **Session and Agent Management**:\n   - Session management indicates parallel operations with each session containing its own configuration of agents and tools ([ARCHITECTURE.md](./ARCHITECTURE.md)).\n\n### Leads for Further Information:\nThe retrieved context has snippets pointing toward various sections that could provide additional details, such as the specific role of each tool and how they are incorporated into an agent's workflow. These include files like `agents/mod.rs`, `session.rs`, and `agent/tools/mod.rs`.\n\nBecause the context does not fully explain the specifics of tool usage by agents, I recommend checking further documentation or additional sections of the source code not provided here for comprehensive understanding.",
         "0.9633231117107672",
         "1.0",
         "0.9230769230769231",
         "0.9010890241735758",
         "default"
        ],
        [
         "2",
         "I'd like to be able to configure a session in a file, such that users can add their own custom agents. Create a detailed step-by-step plan.",
         "['### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\", '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '    /// repository instead.\\n    #[serde(default)]\\n    pub agent_custom_constraints: Option<Vec<String>>,\\n\\n    #[serde(default)]\\n    pub ui: UIConfig,\\n\\n    /// Number of completions before the agent summarizes the conversation.\\n    /// This is used to steer the agent to focus on the current task. If this value is too small\\n    /// the agent will have clear loss of context when performing tasks. If this value is too large\\n    /// the agent will not have focus and not understand what is relevant and important.\\n    ///\\n    /// Additionally, summarizing the conversation will reduce the context window which can be\\n    /// beneficial for APIs with stringent limits on context tokens.\\n    ///\\n    /// Defaults to 10.\\n    #[serde(default = \"default_num_completions_for_summary\")]\\n    pub num_completions_for_summary: usize,\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(default)]\\npub struct UIConfig {\\n    pub hide_header: bool,\\n}\\n\\nfn default_otel_enabled() -> bool {\\n    false\\n}\\n\\nfn default_num_completions_for_summary() -> usize {\\n    10\\n}\\n\\n/// Agent session configurations supported by Kwaak\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\npub enum SupportedAgentConfigurations {\\n    /// Single looping agent that has all tools available\\n    #[default]\\n    #[serde(alias = \"V1\")]\\n    Coding,\\n    /// A two stage agent, starting with a planning agent that delegates to the coding\\n    /// agent\\n    PlanAct,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum SupportedToolExecutors {\\n    #[default]\\n    Docker,\\n    Local,\\n}\\n\\n#[derive(PartialEq, Debug, Clone, Serialize, Deserialize, Default, strum_macros::EnumIs)]\\n#[serde(rename_all = \"kebab-case\")]\\npub enum AgentEditMode {\\n    #[default]\\n    Whole,\\n    Line,\\n    // i.e. udiff, llm reviewed, etc\\n}\\n\\n#[derive(Debug, Clone, Serialize, Deserialize)]', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', \"### Configuration\\n\\nKwaak supports configuring different Large Language Models (LLMs) for distinct tasks like indexing, querying, and embedding to optimize performance and accuracy. Be sure to tailor the configurations to fit the scope and blend of the tasks you're tackling.\", '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '### Session Lifecycle\\n\\n1. **Creation**: When a user starts a new chat or creates a new agent, a new session is created with a unique UUID.\\n2. **Initialization**: The session sets up a Docker container, generates initial context using RAG, and configures the environment.\\n3. **Agent Execution**: The session starts an agent (e.g., coding agent or plan-and-act agent) which interacts with the LLM.\\n4. **Message Handling**: Sessions maintain communication channels for handling messages, including potential agent swaps.\\n5. **Termination**: When a chat is closed or when Kwaak exits, the associated session is stopped.', '\\n\\n    /// Optional: Use github for code search, creating pull requests, and automatic pushing to\\n    /// remotes\\n    #[serde(default)]\\n    pub github_api_key: Option<ApiKey>,\\n\\n    /// Required if using `OpenAI`\\n    #[serde(default)]\\n    pub openai_api_key: Option<ApiKey>,\\n\\n    /// Required if using \\'Anthropic\\'\\n    #[serde(default)]\\n    pub anthropic_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Open Router`\\n    #[serde(default)]\\n    pub open_router_api_key: Option<ApiKey>,\\n\\n    /// Required if using `Azure OpenAI`\\n    #[serde(default)]\\n    pub azure_openai_api_key: Option<ApiKey>,\\n\\n    #[serde(default)]\\n    pub tool_executor: SupportedToolExecutors,\\n\\n    /// A list of tool name and whether it is enabled or disabled\\n    ///\\n    /// This allows the user to disable tools that are not needed for their workflow. Or enable\\n    /// tools that are disabled by default\\n    #[serde(default)]\\n    pub tools: Tools,\\n\\n    /// By default the agent stops if the last message was its own and there are no new\\n    /// completions.\\n    ///\\n    /// When endless mode is enabled, the agent will keep running until it either cannot complete,\\n    /// did complete or was manually stopped.\\n    ///\\n    /// In addition, the agent is instructed that it cannot ask for feedback, but should try to\\n    /// complete its task instead.\\n    ///\\n    /// When running without a TUI, the agent will always run in endless mode.\\n    ///\\n    /// WARN: There currently is _no_ limit for endless mode\\n    #[serde(default)]\\n    pub endless_mode: bool,\\n\\n    /// OpenTelemetry tracing feature toggle\\n    #[serde(default = \"default_otel_enabled\")]\\n    pub otel_enabled: bool,\\n\\n    /// How the agent will edit files, defaults to whole\\n    #[serde(default)]\\n    pub agent_edit_mode: AgentEditMode,\\n\\n    /// Additional constraints / instructions for the agent\\n    ///\\n    /// These are passes to the agent in the system prompt and are rendered in a list. If you\\n    /// intend to use more complicated instructions, consider adding a file to read in the\\n', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '\\n\\npub async fn run(file: Option<PathBuf>, dry_run: bool) -> Result<()> {\\n    let file = file.unwrap_or_else(|| PathBuf::from(\"kwaak.toml\"));\\n    if !dry_run {\\n        if std::fs::metadata(\".git\").is_err() {\\n            anyhow::bail!(\"Not a git repository, please run `git init` first\");\\n        }\\n        if std::fs::metadata(&file).is_ok() {\\n            anyhow::bail!(\\n                \"{} already exists in current directory, skipping initialization\",\\n                file.display()\\n            );\\n        }\\n    }\\n\\n    println!(\"Welcome to Kwaak! Let\\'s get started by initializing a new configuration file.\");\\n    println!(\"\\\\n\");\\n    println!(\\n        \"We have a few questions to ask you to get started, you can always change these later in the `{}` file.\",\\n        file.display()\\n    );\\n\\n    let mut context = tera::Context::new();\\n    project_questions(&mut context)?;\\n    git_questions(&mut context)?;\\n    llm_questions(&mut context).await?;\\n    command_questions(&mut context)?;\\n\\n    let config =\\n        Templates::render(\"kwaak.toml\", &context).context(\"Failed to render default config\")?;\\n\\n    // Ensure we panic during tests\\n    debug_assert!(\\n        toml::from_str::<crate::config::Config>(&config).is_ok(),\\n        \"Failed to parse the rendered config with error: {error:#}, config: \\\\n{config}\",\\n        error = toml::from_str::<crate::config::Config>(&config).unwrap_err()\\n    );\\n    toml::from_str::<crate::config::Config>(&config)\\n        .context(\"There is an error in the configuration\")?;\\n\\n    // Since we want the template annotated with comments, just return the template\\n    if dry_run {\\n        println!(\"\\\\nDry run, would have written the following to kwaak.toml:\\\\n\\\\n{config}\");\\n    } else {\\n        std::fs::write(&file, &config)?;\\n        println!(\\n            \"\\\\nInitialized kwaak project in current directory, please review and customize the created `{}` file.\\\\n Kwaak also needs a `Dockerfile` to execute your code in.\",\\n            file.display()\\n        );\\n    }\\n\\n    Ok(())\\n}', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '{{ query }}\\n\\nProject the agent is working on: {{project_name}}\\nThe language the project is written in: {{lang}}\\n\\nFor the agent to accomplish this task, example questions could be (not limited to!):\\n\\n- What files might be relevant to the agent?\\n- Any directories the agent could explore?\\n- Any issues the agent might encounter? Suggest how to resolve them or work around them.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)']",
         "Based on the provided context, here is a step-by-step plan to configure a session in a file with the capability for users to add their own custom agents in Kwaak:\n\n1. **Initialize a Configuration File**:\n   - Run `kwaak init` in the project where you want to configure a session. This command will guide you through the process and help you create a basic configuration file named `kwaak.toml` ([source](./README.md)).\n\n2. **Customize the Configuration File**:\n   - Review and adjust the `kwaak.toml` file to suit your specific needs. You are encouraged to take a close look at this file since it contains various options that can be tailored for performance and accuracy of the agents ([source](./README.md)).\n\n3. **Agent Session Management**:\n   - Sessions represent ongoing agent interactions and are managed as separate entities, each having its own state and configuration. This means different configurations can be experimented with by adding new agents without impacting existing setups ([source](./ARCHITECTURE.md)).\n\n4. **Defining a New Agent**:\n   - Within the `kwaak.toml` file, customize session configurations. This includes specifying agent types and tools by overriding or adding new configurations. This structure allows for flexibility such as using different tools, docker configurations, or even defining custom constraints for agents ([source](./src/config/config.rs)).\n\n5. **Additional Configuration (Optional)**:\n   - If contributors have different setups, you may utilize environment variable overrides or create a `kwaak.local.toml` file and ignore it in `.gitignore` ([source](./README.md)).\n\n6. **Docker Setup**:\n   - Ensure you have a Dockerfile in your project root or specify an alternate path in the `kwaak.toml`. This Dockerfile should encapsulate all dependencies your custom agents will need ([source](./README.md)).\n\n7. **Testing and Iteration**:\n   - After setting up the configuration, test your setup by running `kwaak` and observe any changes or behaviors with the new session configurations.\n   - Iterate based on feedback or performance metrics to further refine your custom agent configurations.\n\nThis approach provides a structured method for configuring sessions and adding custom agents. If additional guidance is needed, such as enabling tools that are disabled by default or running the agent in endless mode, you can refer to the detailed configurations and options specified in the `kwaak.toml` documentation sections ([source](./src/config/config.rs)).",
         "To configure a session in a file such that users can add their own custom agents in Kwaak, follow this detailed step-by-step plan based on the given context:\n\n1. **Understanding the Session Concept**: \n   - Sessions in Kwaak are used to represent an ongoing agent interaction. They are more general than a simple chat and may be utilized for non-chat interactions in the future (Reference: _ARCHITECTURE.md_).\n\n2. **Configure Session Lifecycle**:\n   - When a session is created via a new chat or agent, a Docker container is initialized, the environment is configured, and an agent is started (Reference: _ARCHITECTURE.md_).\n\n3. **Use `kwaak.toml` for Configuration**:\n   - Create a `kwaak.toml` file which will include the session configurations. This configuration file is pivotal to adjusting agent settings and tool configurations (Reference: _README.md_).\n\n4. **Session Configuration Parameters**:\n   - Make sure to include necessary configurations in the `kwaak.toml` file. These configurations include, but are not limited to:\n     - `SupportedAgentConfigurations` for defining agent architectures (e.g., `Coding`, `PlanAct`).\n     - Tool executors configurations such as `Docker` or `Local`.\n\n5. **Custom Agent Definitions**:\n   - Users can create custom agents by defining them in the `kwaak.toml` configuration file. Support for custom tools can also be configured here.\n   - Example from the context suggests the use of agent constraints, tool lists, and edit modes to customize agent behavior (`config.rs`).\n\n6. **Onboarding and Setup**:\n   - Utilize Kwaak’s onboarding module to guide users through setting up their configurations with the configuration file being generated during this process. This accommodates user-specific setups (Reference: _onboarding/mod.rs_).\n\n7. **Use Environment Variables for Customization**:\n   - Provide flexibility for users to override configurations via environment variables. This helps accommodate different setups for diverse contributor environments (Reference: _README.md_).\n\n8. **Testing and Validating Configurations**:\n   - Use Docker to manage test environments and validate the agent setups to ensure they perform as intended (Reference: _benchmarks/swe/README.md_).\n\nBy following these steps, you can configure sessions in a file, allowing users to add their custom agents. The core idea rests on leveraging `kwaak.toml` for flexible and customizable agent configurations as well as providing an onboarding flow to support end-user interaction with the configuration process. \n\nIf you need more detailed steps for specific configurations, please consult the full documentation or context for additional guidance.",
         "0.8692375777390846",
         "0.6923076923076923",
         "0.8181818181818182",
         "0.9277193689099632",
         "default"
        ],
        [
         "3",
         "Explain kwaak works and explain the architecture. Include a mermaid diagram of all the high level components.",
         "['Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '#### Docker\\n\\nKwaak expects a Dockerfile in the root of your project. If you already have a Dockerfile, you can just name it differently and configure it in the configuration file. This Dockerfile should contain all the dependencies required to test and run your code.', '### Arch Linux\\n\\nThe package is available in the [extra repositories](https://archlinux.org/packages/extra/x86_64/kwaak/) and can be installed with [pacman](https://wiki.archlinux.org/title/Pacman):\\n\\n```shell\\npacman -S kwaak\\n```\\n\\n#### Setup\\n\\nOnce installed, you can run `kwaak init` in the project you want to use Kwaak in. This will guide you through the setup process and it will help you create a configuration file. See [Configuration](#configuration) for more customization options.\\n\\nApi keys can be prefixed by `env:`, `text:` and `file:` to read secrets from the environment, a text string, or a file respectively.\\n\\nWe highly recommend taking a look at the configuration file and adjusting it to your needs. There are various options that can improve the performance and accuracy of the agents.', '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '**Q:** I get a redb/duckdb error when starting, what is up?\\n\\n**A**: Possibly your index got corrupted, or you have another kwaak instance running on the same project. Try clearing the index with `kwaak clear-index` and restart kwaak. Note that this will require a reindexing of your codebase.', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.', '## Latest updates on our blog :fire:\\n\\n- [Releasing kwaak with kwaak](https://bosun.ai/posts/releasing-kwaak-with-kwaak/)', '#### General Configuration\\n\\nAll of these are inferred from the project directory and can be overridden in the `kwaak.toml` configuration file.\\n\\n- **`project_name`**: Defaults to the current directory name. Represents the name of your project.\\n- **`language`**: The programming language of the project, for instance, Rust, Go, Python, JavaScript, etc.', '## Bug reports\\n\\nIt happens, but we still love them.\\n\\n## Submitting pull requests\\n\\nIf you have a great idea, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\\nDon\\'t forget to give the project a star! Thanks again!\\n\\nIf you just want to contribute (bless you!), see [our issues](https://github.com/bosun-ai/kwaak/issues).\\n\\n1. Fork the Project\\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\\n3. Commit your Changes (`git commit -m \\'feat: Add some AmazingFeature\\'`)\\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\\n5. Open a Pull Request\\n\\nMake sure that:\\n\\n- Public functions are documented in code\\n- Documentation is updated in the [user documentation](https://github.com/bosun-ai/swiftide-website)\\n- Tests are added\\n- Evals are added for tool / agent improvements (see [Evaluations](EVALUATIONS.md))\\n- Verified performance with benchmarks if applicable', '**Q:** Kwaak feels very slow\\n\\n**A:** Try increasing the resources available for docker. For docker desktop this is in Settings -> Resources -> Advanced. On MacOS, adding your terminal and/or kwaak to developer tools can also help.', '## Overview\\n\\nThis package provides a complete test harness for evaluating the Kwaak agent against SWE-bench:\\n- Loads and processes the SWE-bench dataset\\n- Manages Docker containers for isolated test environments\\n- Executes test cases with proper environment setup\\n- Evaluates and grades test results\\n- Generates submission-ready predictions', '//! Builds various storage providers for kwaak\\n//!\\n//! Handled as statics to avoid multiple instances of the same storage provider\\n//!\\n//!\\n//! Currently there are 3 tables:\\n//! - project itself (indexing/retrieval) (uuid, path, chunk, embeddings)\\n//! - cache (for caching in indexing/retrieval) (uuid, path)\\n//! - runtime settings (for storing runtime settings) (key, value)\\n//!\\n//! Right now, these are relatively simple. Friendly reminder for future me and others to consider\\n//! a decent migration strategy if these tables change.\\n\\nuse std::sync::OnceLock;\\n\\nuse anyhow::{Context, Result};\\nuse swiftide::{indexing::EmbeddedField, integrations::duckdb::Duckdb};\\n\\nuse crate::repository::Repository;\\n\\nstatic DUCK_DB: OnceLock<Duckdb> = OnceLock::new();\\n\\n/// Retrieves a static duckdb\\n///\\n/// # Panics\\n///\\n/// Panics if it cannot setup duckdb\\npub fn get_duckdb(repository: &Repository) -> Duckdb {\\n    DUCK_DB\\n        .get_or_init(|| build_duckdb(repository).expect(\"Failed to build duckdb\"))\\n        .to_owned()\\n}\\n\\n// Probably should just be on the repository/config, cloned from there.\\n// This sucks in tests\\npub(crate) fn build_duckdb(repository: &Repository) -> Result<Duckdb> {\\n    let config = repository.config();\\n    let path = config.cache_dir().join(\"duck.db3\");\\n\\n    tracing::debug!(\"Building Duckdb: {}\", path.display());\\n\\n    let embedding_provider = config.embedding_provider();\\n\\n    let connection =\\n        duckdb::Connection::open(&path).context(\"Failed to open connection to duckdb\")?;\\n    Duckdb::builder()\\n        .connection(connection)\\n        .with_vector(\\n            EmbeddedField::Combined,\\n            embedding_provider.vector_size().try_into()?,\\n        )\\n        .table_name(normalize_table_name(&config.project_name))\\n        .cache_table(format!(\\n            \"cache_{}\",\\n            normalize_table_name(&config.project_name)\\n        ))\\n        .build()\\n        .context(\"Failed to build Duckdb\")\\n}\\n\\n// Is this enough?\\nfn normalize_table_name(name: &str) -> String {\\n    name.replace(\\'-\\', \"_\")\\n}', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', '//! This modules provides the onboarding flow for Kwaak.\\n//!\\n//! It asks the user a series of questions to generate a basic configuration file.\\n//!\\n//! Intention is to provide a smooth onboarding experience, not to support every possible\\n//! configuration.\\n//!\\n//! Currently all values are inserted into a tera context, which is then rendered into the\\n//! `kwaak.toml` template.\\n//!\\n//! In the future it would be much nicer if it builds an actual `Config` struct. Then this can also\\n//! be used for\\nuse std::path::PathBuf;\\n\\nuse crate::templates::Templates;\\nuse anyhow::{Context, Result};\\nuse commands::command_questions;\\nuse git::git_questions;\\nuse llm::llm_questions;\\nuse project::project_questions;\\n\\nmod commands;\\nmod git;\\nmod llm;\\nmod project;\\nmod util;', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", \"### Configuration\\n\\nKwaak supports configuring different Large Language Models (LLMs) for distinct tasks like indexing, querying, and embedding to optimize performance and accuracy. Be sure to tailor the configurations to fit the scope and blend of the tasks you're tackling.\", \"> [!NOTE]\\n> Docker is used to provide a safe execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.\\n\\nAdditionally, the Dockerfile expects `git` and should be `ubuntu` based.\\n\\nA simple example for Rust:\\n\\n```Dockerfile\\nFROM rust:latest\\n\\nRUN apt-get update && apt install git -y --no-install-recommends\\n\\nCOPY . /app\\n\\nWORKDIR /app\\n```\\n\\nIf you already have a Dockerfile for other purposes, you can either extend it or provide a new one and override the dockerfile path in the configuration.\\n\\n_For an example Dockerfile in Rust, see [this project's Dockerfile](/Dockerfile)_\"]",
         "Based on the provided context, here is an explanation of how Kwaak works and its architecture:\n\n### Explanation of Kwaak\n\nKwaak is a free, open-source platform that enables you to run autonomous AI agents on your local machine. It's designed to handle tasks such as code writing, executing, and creating pull requests in a parallel and autonomous manner. The platform uses a terminal-based chat interface through which users can interact with the agents to accomplish various coding tasks. Kwaak can index your entire codebase, making it capable of answering questions related to the code, finding examples, and even contributing to the code by pushing changes to a remote repository.\n\nKwaak's interaction with your codebase begins by indexing using Swiftide, which is crucial for its Retrieval-Augmented Generation (RAG) capabilities. The indexing is stored using DuckDB, and caching is handled through Redb, ensuring that subsequent startups are faster after the initial indexing.\n\n### Kwaak Architecture\n\nThe architecture of Kwaak involves a lightweight `ratatui`-based frontend that interacts with the backend through dispatched commands. Commands operate with channels for feedback responses. The backend encompasses managing sessions in Docker containers which isolate each agent task, allowing multiple sessions to run in parallel.\n\nWhen running, Kwaak utilizes sessions that handle agent interactions and configurations via Docker containers. Each session is self-contained with sandboxed code execution environments, agent states, configurations, and communication channels.\n\n### High-Level Components Diagram\n\nThe architecture can be visualized in a high-level component diagram represented using a Mermaid diagram (as extracted from the provided context):\n\n```mermaid\ngraph TD\n    A[Frontend (Ratatui)] --> B[Backend]\n    B --> C[Command Dispatcher]\n    B --> D[Session Management]\n    D --> E[Docker Container]\n    E --> F[Agent State and Configuration]\n    F --> G[Continuous Feedback Loop]\n    E --> H[Code Execution]\n    B --> I[DuckDB Storage]\n    C --> J[Command Response Channel]\n    J --> A\n```\n\n### References\n\n- Kwaak's architecture description from `./ARCHITECTURE.md`.\n- High-level overview and functionality explanation from `./README.md`.\n\nIf there are specific aspects of the architecture that need further exploration that are not covered in the provided context, providing additional documentation or source paths might be necessary for detailed exploration.",
         "The context provided does not offer detailed information specific to the complete architecture of Kwaak or a high-level component diagram in a format such as Mermaid. Therefore, I cannot generate a diagram or a full architectural description based solely on the given context.\n\nHowever, based on the snippets retrieved, here are some relevant points about how Kwaak works and its components:\n\n1. **General Functionality**: \n   - Kwaak allows you to run autonomous AI agents locally to work on coding tasks such as documenting, testing, and improving code quality.\n   - It provides a terminal user interface (TUI) for interaction with the agents.\n\n2. **Backend and Frontend**:\n   - It has a lightweight frontend based on `ratatui` that communicates with a backend via commands, and a command pattern is used to handle backend functionalities asynchronously. [Reference: ARCHITECTURE.md]\n\n3. **Indexing**:\n   - Upon initial setup, it indexes the codebase using \"Swiftide\" for Retrieval-Augmented Generation (RAG). This indexing is stored using `duckdb` and is cached with `redb`. [Reference: README.md]\n\n4. **Execution Environment**:\n   - Kwaak uses Docker containers to create safe execution environments for agents to run code. This ensures that the agents' execution doesn't affect the local system environment. [Reference: README.md]\n\n5. **Feedback Loop and Sessions**:\n   - Agents operate in a session, usually involving continuous feedback with an LLM until their assigned task is completed.\n\nUnfortunately, the provided context does not contain enough specific details about the architecture to further elaborate with a high-level diagram illustrative of all components in Mermaid or any other format. Additionally, any graphical architecture diagrams referred to in the content (e.g., `architecture.svg`) are not included as text, and hence such visual information cannot be reproduced here.\n\nFor a more detailed exploration of the architecture diagram or component breakdown, a look at the referenced architecture image or further documentation beyond the provided context would be necessary.",
         "0.9131479059128615",
         "0.8333333333333334",
         "1.0",
         "0.03846153845769231",
         "default"
        ],
        [
         "4",
         "There are multiple uses of channels in the app. Explore how the channels work, interact, relate and explain it in simpel terms from a users perspective.",
         "['Kwaak provides a chat interface similar to other LLM chat applications. You can type messages to the agent, and the agent will try to accomplish the task and respond.\\n\\nWhen starting a chat, the code of the current branch is copied into an on-the-fly created docker container. This container is then used to run the code and execute the commands.\\n\\nAfter each chat completion, kwaak will lint, commit, and push the code to the remote repository if any code changes have been made. Kwaak can also create a pull request. Pull requests include an issue link to #48. This helps us identify the success rate of the agents, and also enforces transparency for code reviewers.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '# Architecture\\n\\nKwaak has a lightweight, ratatui based frontend that interacts with a backend through dispatched commands. A command includes a channel to feed back responses into.\\n\\nWhen kwaak starts, by default it will index the repository using Swiftide (for RAG). After indexation is done, the TUI is started.\\n\\nWhen starting the initial chat, a docker container is built, initial context is generated (RAG), the environment is configured, and then the agent is started. A chat corresponds to a session in the backend. Chats are sessions, a session does not have to be a chat.\\n\\nAgents run in a continuous feedback loop with an LLM until their task is completed.\\n\\n<img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/architecture.svg\" alt=\"Architecture\">', 'Kwaak is free and open-source. You can bring your own API keys, or your own models via Ollama.\\n\\n<p align=\"center\">\\n\\n![demo](./images/demo.gif)\\n\\n</p>\\n\\nKwaak is aware of your codebase and can answer questions about your code, find examples, write and execute code, create pull requests, and more. Unlike other tools, Kwaak is focussed on autonomous agents, and can run multiple agents at the same time.\\n\\n> [!CAUTION]\\n> Kwaak can be considered alpha software. The project is under active development; expect breaking changes. Contributions, feedback, and bug reports are very welcome.\\n\\nKwaak is part of the [bosun.ai](https://bosun.ai) project. An upcoming platform for autonomous code improvement.\\n\\nPowered by [Swiftide](https://github.com/bosun-ai/swiftide)\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '## Sessions\\n\\nSessions in Kwaak represent the abstract state of an ongoing agent interaction. Each chat in the UI corresponds to a session in the backend, but the concept of a session is more general and could potentially be used for non-chat interactions in the future.', '<!-- PROJECT LOGO -->\\n<br />\\n<div align=\"center\">\\n  <a href=\"https://github.com/bosun-ai/kwaak\">\\n    <img src=\"https://github.com/bosun-ai/kwaak/blob/master/images/logo.webp\" alt=\"Logo\" width=\"250\" height=\"250\">\\n  </a>\\n\\n  <h3 align=\"center\">Kwaak</h3>\\n\\n  <p align=\"center\">\\nBurn through tech debt with AI agents!<br />\\n    <br />\\n    <br />\\n    <!-- <a href=\"https://github.com/bosun-ai/swiftide\">View Demo</a> -->\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=bug&template=bug_report.md\">Report Bug</a>\\n    ·\\n    <a href=\"https://github.com/bosun-ai/kwaak/issues/new?labels=enhancement&template=feature_request.md\">Request Feature</a>\\n    ·\\n    <a href=\"https://discord.gg/3jjXYen9UY\">Discord</a>\\n  </p>\\n</div>\\n\\n <!-- ABOUT THE PROJECT -->', '### Running Kwaak\\n\\nYou can then run `kwaak` in the root of your project. On initial bootup, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed, subsequent startups will be faster.\\n\\nKeybindings:\\n\\n- **_ctrl-s_**: Send the current message to the agent\\n- **_ctrl-x_**: Exit the agent\\n- **_ctrl-q_**: Exit kwaak\\n- **_ctrl-n_**: Create a new agent\\n- **_Page Up_**: Scroll chat up\\n- **_Page Down_**: Scroll chat down\\n- **_tab_**: Switch between agents\\n\\nAdditionally, kwaak provides a number of slash commands, `/help` will show all available commands.\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '### Session Management\\n\\nKwaak supports running multiple sessions in parallel, with each session having its own:\\n- Docker container for sandboxed code execution\\n- Agent state and configuration\\n- Communication channels\\n- Cancellation tokens for managing lifecycle\\n\\nUsers can create new agents (sessions) with `Ctrl-n` and switch between them using the `Tab` key.\\n\\n### Session Architecture\\n\\nSessions are implemented using the following key components:\\n\\n- `Session`: Core struct representing an ongoing agent interaction\\n- `RunningSession`: Manages the active state of a session, including the agent, tools, and environment\\n- `SessionMessage`: Communication mechanism for inter-session messaging\\n\\nThe core idea is that sessions can have different configurations of agents (and tools!), such that new configurations can be experimented with without impacting existing users.\\n\\nThe session configuration is provided in the config.', 'pub mod agent;\\npub mod chat;\\npub mod chat_message;\\npub mod cli;\\npub mod commands;\\npub mod config;\\n#[cfg(feature = \"evaluations\")]\\npub mod evaluations;\\npub mod frontend;\\npub mod git;\\npub mod indexing;\\npub mod kwaak_tracing;\\npub mod onboarding;\\npub mod repository;\\npub mod runtime_settings;\\npub mod storage;\\npub mod templates;\\npub mod util;\\n\\n#[cfg(debug_assertions)]\\npub mod test_utils;', '## What is Kwaak?\\n\\n <!-- [![Product Name Screen Shot][product-screenshot]](https://example.com) -->\\n\\nAlways wanted to run a team of AI agents locally from your own machine? Write code, improve test coverage, update documentation, or improve code quality, while you focus on building the cool stuff? Kwaak enables you to run a team of autonomous AI agents right from your terminal, **in parallel**. You interact with Kwaak in a chat-like terminal interface.', '- [What is Kwaak?](#what-is-kwaak)\\n- [High level features](#high-level-features)\\n- [How is Kwaak different from other tools?](#how-is-kwaak-different-from-other-tools)', '### How does it work?\\n\\nOn initial boot up, Kwaak will index your codebase. This can take a while, depending on the size. Once indexing has been completed once, subsequent startups will be faster. Indexes are stored with [duckdb](https://duckdb.org), and indexing is cached with [redb](https://github.com/cberner/redb).', 'use std::collections::HashSet;\\n\\nuse ratatui::widgets::ScrollbarState;\\n\\nuse crate::{chat_message::ChatMessage, repository::Repository};\\n\\n#[derive(Debug, Clone)]\\npub struct Chat {\\n    /// Display name of the chat\\n    pub name: String,\\n    /// Identifier used to match responses\\n    pub uuid: uuid::Uuid,\\n    pub branch_name: Option<String>,\\n    pub messages: Vec<ChatMessage>,\\n    pub state: ChatState,\\n    pub new_message_count: usize,\\n    pub completed_tool_call_ids: HashSet<String>,\\n\\n    // Scrolling is per chat\\n    // but handled in the ui\\n    pub vertical_scroll_state: ScrollbarState,\\n    pub vertical_scroll: usize,\\n    pub num_lines: usize,\\n\\n    // Whether to auto-tail the chat on new messages\\n    pub auto_tail: bool,\\n\\n    pub repository: Option<Repository>,\\n}\\n\\nimpl Chat {\\n    pub fn add_message(&mut self, message: ChatMessage) {\\n        if !message.role().is_user() {\\n            self.new_message_count += 1;\\n        }\\n\\n        // If it\\'s a completed tool call, just register it is done and do not add the message\\n        // The state is updated when rendering on the initial tool call\\n        if message.role().is_tool() {\\n            let Some(tool_call) = message.maybe_completed_tool_call() else {\\n                tracing::error!(\\n                    \"Received a tool message without a tool call ID: {:?}\",\\n                    message\\n                );\\n                return;\\n            };\\n\\n            self.completed_tool_call_ids\\n                .insert(tool_call.id().to_string());\\n\\n            return;\\n        }\\n        self.messages.push(message);\\n    }\\n\\n    pub fn transition(&mut self, state: ChatState) {\\n        self.state = state;\\n    }\\n\\n    #[must_use]\\n    pub fn is_loading(&self) -> bool {\\n        matches!(\\n            self.state,\\n            ChatState::Loading | ChatState::LoadingWithMessage(_)\\n        )\\n    }\\n\\n    #[must_use]\\n    pub fn is_tool_call_completed(&self, tool_call_id: &str) -> bool {\\n        self.completed_tool_call_ids.contains(tool_call_id)\\n    }\\n}', 'pub struct App<\\'a> {\\n    pub splash: splash::Splash<\\'a>,\\n    pub has_indexed_on_boot: bool,\\n    // /// The chat input\\n    // pub input: String,\\n    pub text_input: TextArea<\\'a>,\\n\\n    /// All known chats\\n    pub chats: Vec<Chat>,\\n\\n    /// UUID of the current chat\\n    pub current_chat_uuid: uuid::Uuid,\\n\\n    /// Holds the sender of UI events for later cloning if needed\\n    pub ui_tx: mpsc::UnboundedSender<UIEvent>,\\n\\n    /// Receives UI events (key presses, commands, etc)\\n    pub ui_rx: mpsc::UnboundedReceiver<UIEvent>,\\n\\n    /// Sends commands to the backend\\n    pub command_tx: Option<mpsc::UnboundedSender<CommandEvent>>,\\n\\n    /// Responds to commands from the backend\\n    /// And maps them to ui events\\n    pub command_responder: AppCommandResponder,\\n\\n    /// Mode the app is in, manages the which layout is rendered and if it should quit\\n    pub mode: AppMode,\\n\\n    /// Tracks the current selected state in the UI\\n    pub chats_state: ListState,\\n\\n    /// Tab names\\n    pub tab_names: Vec<&\\'static str>,\\n\\n    /// Index of selected tab\\n    pub selected_tab: usize,\\n\\n    /// States when viewing logs\\n    pub log_state: TuiWidgetState,\\n\\n    /// Commands that relate to boot, and not a chat\\n    pub boot_uuid: Uuid,\\n\\n    /// Skip indexing on boot\\n    pub skip_indexing: bool,\\n\\n    /// Override the working directory if it is not \".\"\\n    pub workdir: PathBuf,\\n\\n    /// Hack to get line wrapping on input into the textarea\\n    pub input_width: Option<u16>,\\n\\n    /// Max lines we can render in the chat messages\\n    pub chat_messages_max_lines: u16,\\n\\n    /// User configuration for the UI\\n    pub ui_config: UIConfig,\\n\\n    /// Informs the user if there is an update available\\n    pub update_available: Option<update_informer::Version>,\\n}\\n\\n#[derive(Debug, Clone, Copy, Default, PartialEq)]\\npub enum AppMode {\\n    #[default]\\n    Chat,\\n    Logs,\\n    Quit,\\n}', '- [Latest updates on our blog :fire:](#latest-updates-on-our-blog-fire)\\n- [Getting started](#getting-started)\\n  - [Requirements](#requirements)\\n    - [Docker](#docker)\\n    - [Api keys](#api-keys)\\n  - [Installation and setup](#installation-and-setup)\\n    - [Homebrew](#homebrew)\\n    - [Linux and MacOS (using curl)](#linux-and-macos-using-curl)\\n    - [Cargo](#cargo)\\n    - [Setup](#setup)\\n  - [Running Kwaak](#running-kwaak)\\n  - [How does it work?](#how-does-it-work)\\n  - [Configuration](#configuration)\\n    - [General Configuration](#general-configuration)\\n    - [Command Configuration](#command-configuration)\\n    - [API Key Management](#api-key-management)\\n    - [Docker and GitHub Configuration](#docker-and-github-configuration)\\n    - [LLM Configuration](#llm-configuration)\\n    - [Backoff Configuration](#backoff-configuration)\\n    - [Other configuration](#other-configuration)', 'mod chat_list_widget;\\nmod chat_messages_widget;\\nmod help_section_widget;\\nmod input_bar_widget;\\nmod message_formatting;\\nmod on_key;\\nmod ui;\\n\\npub use on_key::on_key;\\npub use ui::ui;', '//! Agents defines various agents that can be used inside kwaak\\n//!\\n//! Agents are run in a session, and depending on the session, multiple agents can be used.\\npub mod coding;\\npub mod delegate;', '## Community\\n\\nIf you want to get more involved with `kwaak`, have questions or want to chat, you can find us on [discord](https://discord.gg/3jjXYen9UY).\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', '\\n    async fn test_add_chat() {\\n        let mut app = App::default();\\n        let initial_chat_count = app.chats.len();\\n\\n        app.add_chat(Chat::default());\\n\\n        assert_eq!(app.chats.len(), initial_chat_count + 1);\\n        assert_eq!(\\n            app.chats.last().unwrap().name,\\n            format!(\"Chat #{}\", initial_chat_count + 1)\\n        );\\n    }\\n\\n    #[tokio::test]\\n    async fn test_next_chat() {\\n        let mut app = App::default();\\n        let first_uuid = app.current_chat_uuid;\\n\\n        app.add_chat(Chat::default());\\n        let second_uuid = app.current_chat_uuid;\\n\\n        app.next_chat();\\n        assert_eq!(app.current_chat_uuid, first_uuid);\\n\\n        app.next_chat();\\n        assert_eq!(app.current_chat_uuid, second_uuid);\\n    }\\n\\n    #[tokio::test]\\n    async fn test_find_chat() {\\n        let mut app = App::default();\\n        let chat = Chat::default();\\n        let uuid = chat.uuid;\\n\\n        app.add_chat(chat);\\n\\n        assert!(app.find_chat(uuid).is_some());\\n        assert!(app.find_chat(Uuid::new_v4()).is_none());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_find_chat_mut() {\\n        let mut app = App::default();\\n        let chat = Chat::default();\\n        let uuid = chat.uuid;\\n\\n        app.add_chat(chat);\\n\\n        assert!(app.find_chat_mut(uuid).is_some());\\n        assert!(app.find_chat_mut(Uuid::new_v4()).is_none());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_current_chat() {\\n        let app = App::default();\\n        assert!(app.current_chat().is_some());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_current_chat_mut() {\\n        let mut app = App::default();\\n        assert!(app.current_chat_mut().is_some());\\n    }\\n\\n    #[tokio::test]\\n    async fn test_add_chat_message() {\\n        let mut app = App::default();\\n        let message = ChatMessage::new_system(\"Test message\");\\n\\n        app.add_chat_message(app.current_chat_uuid, message.clone());\\n\\n        let chat = app.current_chat().unwrap();\\n        assert!(chat.messages.contains(&message));\\n    }\\n}', '//! Kwaak uses a command pattern to handle the backend asynchroniously.\\nmod command;\\nmod handler;\\nmod responder;\\n\\npub use command::{Command, CommandEvent};\\npub use handler::CommandHandler;\\npub use responder::{CommandResponse, DebugResponder, Responder};\\n\\n#[cfg(test)]\\npub use responder::MockResponder;', 'use crate::frontend::App;\\n\\npub fn scroll_up(app: &mut App) {\\n    let Some(current_chat) = app.current_chat_mut() else {\\n        return;\\n    };\\n    current_chat.vertical_scroll = current_chat.vertical_scroll.saturating_sub(2);\\n    current_chat.vertical_scroll_state = current_chat\\n        .vertical_scroll_state\\n        .position(current_chat.vertical_scroll);\\n    current_chat.auto_tail = false;\\n}\\n\\npub fn scroll_down(app: &mut App) {\\n    let Some(current_chat) = app.current_chat_mut() else {\\n        return;\\n    };\\n    current_chat.vertical_scroll = current_chat.vertical_scroll.saturating_add(2);\\n    current_chat.vertical_scroll_state = current_chat\\n        .vertical_scroll_state\\n        .position(current_chat.vertical_scroll);\\n    // Optional: only disable auto_tail when actually scrolling up\\n    current_chat.auto_tail = false;\\n}\\n\\npub fn scroll_end(app: &mut App) {\\n    let max_lines_in_area = app.chat_messages_max_lines.saturating_sub(2);\\n\\n    let Some(current_chat) = app.current_chat_mut() else {\\n        tracing::error!(\"No current chat to scroll to end\");\\n        return;\\n    };\\n    let scroll_position = current_chat\\n        .num_lines\\n        .saturating_sub(max_lines_in_area as usize);\\n\\n    current_chat.vertical_scroll = scroll_position;\\n    current_chat.vertical_scroll_state =\\n        current_chat.vertical_scroll_state.position(scroll_position);\\n    current_chat.auto_tail = true;\\n}', '## How is Kwaak different from other tools?\\n\\nKwaak focuses on out-of-your-way autonomous agents. There are great tools available to utilize AI in your own coding workflow, Kwaak does the opposite. Throw your backlog at Kwaak, so you can work on the cool stuff.', 'use ratatui::text::Text;\\n\\n/// Represents a chat message that can be stored in a [`Chat`]\\n///\\n/// Messages are expected to be formatted strings and are displayed as-is. Markdown is rendered\\n/// using `tui-markdown`.\\n///\\n/// TODO: All should be Cows\\n#[derive(Clone, Default, PartialEq)]\\npub struct ChatMessage {\\n    role: ChatRole,\\n    content: String,\\n    /// Owned rendered text\\n    rendered: Option<Text<\\'static>>,\\n    original: Option<swiftide::chat_completion::ChatMessage>,\\n}\\n\\n// Debug with truncated content\\nimpl std::fmt::Debug for ChatMessage {\\n    fn fmt(&self, f: &mut std::fmt::Formatter<\\'_>) -> std::fmt::Result {\\n        f.debug_struct(\"ChatMessage\")\\n            .field(\"role\", &self.role)\\n            .field(\"content\", &self.content)\\n            .field(\"original\", &self.original)\\n            .field(\"rendered\", &self.rendered.is_some())\\n            .finish()\\n    }\\n}\\n\\n#[derive(\\n    Debug,\\n    Clone,\\n    Copy,\\n    Default,\\n    strum::EnumString,\\n    strum::Display,\\n    strum::AsRefStr,\\n    strum::EnumIs,\\n    PartialEq,\\n)]\\npub enum ChatRole {\\n    User,\\n    #[default]\\n    System,\\n    Command,\\n    Assistant,\\n    Tool,\\n}\\n\\nimpl ChatMessage {\\n    pub fn new_user(msg: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::User)\\n            .with_content(msg.into())\\n            .to_owned()\\n    }\\n\\n    pub fn new_system(msg: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::System)\\n            .with_content(msg.into())\\n            .to_owned()\\n    }\\n\\n    pub fn new_command(cmd: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::Command)\\n            .with_content(cmd.into().to_string())\\n            .to_owned()\\n    }\\n\\n    pub fn new_assistant(msg: impl Into<String>) -> ChatMessage {\\n        ChatMessage::default()\\n            .with_role(ChatRole::Assistant)\\n            .with_content(msg.into())\\n            .to_owned()\\n    }', '## High level features\\n\\n- Run multiple agents in parallel\\n- Quacking terminal interface\\n- As fast as it gets; written in Rust, powered by Swiftide\\n- Agents operate on code, use tools, and can be interacted with\\n- View and pull code changes from an agent; or have it create a pull request\\n- Sandboxed execution in docker\\n- OpenAI, Ollama, Anthropic, Azure, and many other models via [OpenRouter](https://openrouter.ai)\\n- Python, TypeScript/Javascript, Go, Java, Ruby, Solidity, C, C++, and Rust\\n\\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>', 'You can use the following slash commands to interact with kwaak and the agent:\\n\\n{% for command, description in commands -%}\\n**/{{command}}** - {{description}}\\n{% endfor %}', \"### Installation and setup\\n\\nPre-built binaries are available from the [releases page](https://github.com/bosun-ai/kwaak/releases).\\n\\n#### Homebrew\\n\\n```shell\\nbrew install bosun-ai/tap/kwaak\\n```\\n\\n#### Linux and MacOS (using curl)\\n\\n```shell\\n curl --proto '=https' --tlsv1.2 -LsSf https://github.com/bosun-ai/kwaak/releases/latest/download/kwaak-installer.sh | sh\\n```\\n\\n#### Cargo\\n\\nInstall the binary directly with [binstall](https://github.com/cargo-bins/cargo-binstall)\\n\\n```shell\\ncargo binstall kwaak\\n```\\n\\nOr compile from source with Cargo:\\n\\n```shell\\ncargo install kwaak\\n```\", '**Q:** So why docker? How does it work? Does it affect local LLM performance?\\n\\n**A**: Docker is only used to provide a save execution environment for the agents. It does not affect the performance of the LLMs. The LLMs are running either locally or in the cloud, and the docker container is only used to run the code. This is done to ensure that the agents cannot access your local system. Kwaak itself runs locally.', '\\n\\n#[derive(Debug, Clone, Default, strum::EnumIs, PartialEq)]\\npub enum ChatState {\\n    Loading,\\n    LoadingWithMessage(String),\\n    #[default]\\n    Ready,\\n}\\n\\nimpl Default for Chat {\\n    fn default() -> Self {\\n        Self {\\n            name: \"Chat\".to_string(),\\n            uuid: uuid::Uuid::new_v4(),\\n            branch_name: None,\\n            messages: Vec::new(),\\n            state: ChatState::default(),\\n            new_message_count: 0,\\n            completed_tool_call_ids: HashSet::new(),\\n            vertical_scroll_state: ScrollbarState::default(),\\n            vertical_scroll: 0,\\n            num_lines: 0,\\n            auto_tail: true,\\n            repository: None,\\n        }\\n    }\\n}\\n\\n#[cfg(test)]', 'use kwaak::commands::Command;\\nuse kwaak::frontend::{ui, UIEvent, UserInputCommand};\\nuse kwaak::test_utils::{setup_integration, IntegrationContext};\\nuse kwaak::{assert_agent_responded, assert_command_done};\\n\\n#[test_log::test(tokio::test(flavor = \"multi_thread\"))]\\nasync fn retry_chat() {\\n    let IntegrationContext {\\n        mut app,\\n        uuid,\\n        mut terminal,\\n\\n        handler_guard,\\n        repository_guard: _repository_guard,\\n        ..\\n    } = setup_integration().await.unwrap();\\n\\n    // First, let\\'s start a noop agent so an environment is running\\n    app.dispatch_command(\\n        uuid,\\n        Command::Chat {\\n            message: \"hello\".to_string(),\\n        },\\n    );\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"before_retry\", terminal.backend());\\n\\n    // Let\\'s retry the chat\\n    app.send_ui_event(UIEvent::UserInputCommand(uuid, UserInputCommand::Retry));\\n\\n    assert_agent_responded!(app, uuid);\\n    assert_command_done!(app, uuid);\\n\\n    // It should now show 2 messages\\n\\n    terminal.draw(|f| ui(f, f.area(), &mut app)).unwrap();\\n    insta::assert_snapshot!(\"after_retry\", terminal.backend());\\n\\n    // Force dropping it, for some reason it\\'s not being dropped\\n    drop(handler_guard);\\n}', \"#### Command Configuration\\n\\nKwaak uses tests, coverages, and lints as an additional opportunity to steer the agent. Configuring these will (significantly) improve the agents' performance.\\n\\n- **`test`**: Command to run tests, e.g., `cargo test`.\\n- **`coverage`**: Command for running coverage checks, e.g., `cargo llvm-cov --summary-only`. Expects coverage results as output. Currently handled unparsed via an LLM call. A friendly output is preferred\\n- **`lint_and_fix`**: Optional command to lint and fix project issues, e.g., `cargo clippy --fix --allow-dirty; cargo fmt` in Rust.\", '**Q**: What is the github token used for?\\n\\n**A**: The github token is used to create pull requests, search code, and push code to a remote repository. It is not used for anything else.\\n\\n**Q**: In my project, different contributors have different setups. How can I make sure kwaak works for everyone?\\n\\n**A**: You can use a `kwaak.local.toml` and add it to your `.gitignore`. Alternatively, all configuration can be overridden by environment variables, prefixed with `KWAAK` and separated by double underscores. For instance, `KWAAK__COMMAND_TEST=cargo nextest run`. Overwriting via environment currently does not work for the `llm` configuration.']",
         "The context provided does not contain specific information explaining how channels work, interact, or relate in the app from a user's perspective. It only mentions that a \"command includes a channel to feed back responses into\" but does not provide further details on how this is implemented or functions within the app. \n\nTherefore, I cannot provide a comprehensive explanation based on the given context. More detailed documentation or code regarding the implementation of channels would be necessary to answer this question fully.",
         "The provided context does not contain sufficient information to fully explain how channels work within the app from a user's perspective. It mentions that commands include a \"channel to feed back responses\" into, but it does not elaborate further on how these channels interact, relate, or are utilized from a user's perspective. Additionally, there is no detailed description or explanation about user interaction with these channels within the retrieved content. Therefore, the question cannot be answered based on the current context. \n\nIf further details are needed, exploring the files or code sections mentioning \"channels\" specifically within the `commands` or `frontend` modules might be a good starting point, as these modules seem to deal with command patterns and user interaction.",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "default"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I add a tool for an agent?</td>\n",
       "      <td>[Kwaak is free and open-source. You can bring ...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>The provided context does not contain specific...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are tools used by an agent?</td>\n",
       "      <td>[## How is Kwaak different from other tools?\\n...</td>\n",
       "      <td>The tools used by an agent in the context prov...</td>\n",
       "      <td>The provided context does not specifically exp...</td>\n",
       "      <td>0.963323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.901089</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'd like to be able to configure a session in ...</td>\n",
       "      <td>[### Arch Linux\\n\\nThe package is available in...</td>\n",
       "      <td>Based on the provided context, here is a step-...</td>\n",
       "      <td>To configure a session in a file such that use...</td>\n",
       "      <td>0.869238</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.927719</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain kwaak works and explain the architectu...</td>\n",
       "      <td>[Kwaak is free and open-source. You can bring ...</td>\n",
       "      <td>Based on the provided context, here is an expl...</td>\n",
       "      <td>The context provided does not offer detailed i...</td>\n",
       "      <td>0.913148</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are multiple uses of channels in the app...</td>\n",
       "      <td>[Kwaak provides a chat interface similar to ot...</td>\n",
       "      <td>The context provided does not contain specific...</td>\n",
       "      <td>The provided context does not contain sufficie...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                 How can I add a tool for an agent?   \n",
       "1                    How are tools used by an agent?   \n",
       "2  I'd like to be able to configure a session in ...   \n",
       "3  Explain kwaak works and explain the architectu...   \n",
       "4  There are multiple uses of channels in the app...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Kwaak is free and open-source. You can bring ...   \n",
       "1  [## How is Kwaak different from other tools?\\n...   \n",
       "2  [### Arch Linux\\n\\nThe package is available in...   \n",
       "3  [Kwaak is free and open-source. You can bring ...   \n",
       "4  [Kwaak provides a chat interface similar to ot...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The provided context does not contain specific...   \n",
       "1  The tools used by an agent in the context prov...   \n",
       "2  Based on the provided context, here is a step-...   \n",
       "3  Based on the provided context, here is an expl...   \n",
       "4  The context provided does not contain specific...   \n",
       "\n",
       "                                           reference  answer_relevancy  \\\n",
       "0  The provided context does not contain specific...          0.000000   \n",
       "1  The provided context does not specifically exp...          0.963323   \n",
       "2  To configure a session in a file such that use...          0.869238   \n",
       "3  The context provided does not offer detailed i...          0.913148   \n",
       "4  The provided context does not contain sufficie...          0.000000   \n",
       "\n",
       "   faithfulness  context_recall  context_precision features  \n",
       "0      1.000000        1.000000           1.000000  default  \n",
       "1      1.000000        0.923077           0.901089  default  \n",
       "2      0.692308        0.818182           0.927719  default  \n",
       "3      0.833333        1.000000           0.038462  default  \n",
       "4      1.000000        1.000000           0.000000  default  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge all results into a single dataframe\n",
    "merged_results = pd.concat(all_results, ignore_index=True)\n",
    "merged_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of the visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Convert the merged_results dataframe to long format for easier plotting\n",
    "metrics_long = pd.melt(merged_results, id_vars=[\"user_input\", \"features\"], \n",
    "                       value_vars=[\"answer_relevancy\", \"faithfulness\", \"context_recall\", \"context_precision\"],\n",
    "                       var_name=\"metric\", value_name=\"value\")\n",
    "\n",
    "# Create a bar plot for the evaluation metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"metric\", y=\"value\", hue=\"features\", data=metrics_long)\n",
    "plt.title(\"Evaluation Metrics by Feature\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.legend(title=\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a heatmap so we can see how the data moves\n",
    "heatmap_data = metrics_long.pivot_table(index='metric', columns='features', values='value')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', cbar=True)\n",
    "plt.title(\"Heatmap of Evaluation Metrics by Feature\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
